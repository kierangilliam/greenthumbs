{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GreenThumbs (faster_rcnn_R_50_C4_3x).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII",
        "colab_type": "text"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab_type": "code",
        "outputId": "58ecf4ae-62b3-4597-d8ac-4500abf458b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install -U torch==1.4 torchvision==0.5 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n",
        "\n",
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Requirement already up-to-date: torch==1.4 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already up-to-date: torchvision==0.5 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5) (1.18.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.17)\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-zmbmg296\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-zmbmg296\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.17)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275269 sha256=4b772492c888105851cb6476fe84d84c675e49195d8b3b107fc30f73d7f65c15\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oknpkk_7/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed pycocotools-2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pycocotools"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.4.0 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.1.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.dev200502)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.38.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.18.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore->detectron2) (5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore->detectron2) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwa4cRN3aAS9",
        "colab_type": "text"
      },
      "source": [
        "# download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuL0LBwdCaqS",
        "colab_type": "code",
        "outputId": "3a880f74-2879-479d-bfe2-a5ac6fe2b53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!rm -rf greenthumbs\n",
        "!git clone https://github.com/kierangilliam/greenthumbs.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'greenthumbs'...\n",
            "remote: Enumerating objects: 250, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 3116 (delta 126), reused 245 (delta 125), pack-reused 2866\u001b[K\n",
            "Receiving objects: 100% (3116/3116), 497.29 MiB | 39.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1457/1457), done.\n",
            "Checking out files: 100% (2759/2759), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDYWKgfatVj",
        "colab_type": "code",
        "outputId": "df7907f8-3394-4e88-90e6-96e3955dadc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Overall goal\n",
        "1. Hyper parameter selection - Pick best model hyperparameters from train test \n",
        "  splits of 65%, 75%, 85% on two versions of data: augmented and not augmented\n",
        "2. Find the best data augmentation method with those given hyperparameters\n",
        "  that boosts model accuracry\n",
        "3. Test if false positives are removed by adding an additional check after\n",
        "  our detectron model gives us better results\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nOverall goal\\n1. Hyper parameter selection - Pick best model hyperparameters from train test \\n  splits of 65%, 75%, 85% with the following \\n2. Find the best data augmentation method with those given hyperparameters\\n  that boosts model accuracry\\n3. Test if false positives are removed by adding an additional check after\\n  our detectron model gives us better results\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7OiDEW2mZuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "                                      Imports\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "import detectron2\n",
        "# detectron2 utilities\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# common libs\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import json\n",
        "\n",
        "# colab\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "                                      Constants \n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "BASE_DIR = 'greenthumbs/data'\n",
        "NUM_CLASSES = 15\n",
        "DRIVE = '/content/drive/My Drive/Green Thumbs'\n",
        "CLASSES = ['tomato_fruit_unripe', 'tomato_fruit', 'tomato_seedling', 'tomato_young_plant', 'tomato_flower', 'bell_pepper_fruit', 'bell_pepper_young_plant', 'bell_pepper_flower', 'bell_pepper_fruit_unripe', 'bell_pepper_seedling', 'cucumber_flower', 'cucumber_plant', 'cucumber_seedling', 'cucumber_fruit', 'cucumber_fruit_unripe']\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "                               Hyper parameter selection\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "# Versions contain different amounts of data\n",
        "# or different data augmentation methods\n",
        "versions = [\"v01\", \"v02\"]\n",
        "test_train_splits = [\"65%\", \"75%\", \"85%\"]\n",
        "iters = [4001]\n",
        "lrs = [.002 , .001, .0005]\n",
        "batch_sizes_per_img = [64, 128] \n",
        "models = [ \n",
        "  \"faster_rcnn_R_101_FPN_3x.yaml\",   \n",
        "  \"faster_rcnn_R_50_C4_3x.yaml\",\n",
        "  \"faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "                               Lib\n",
        "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
        "\"\"\"\n",
        "ds: 65%, 75%, 85%... Describes the dataset split\n",
        "\"\"\"\n",
        "def get_train_test_coco_files(v, ds):\n",
        "  train_coco_file = BASE_DIR + f'/{v}/train_{ds}_coco.json'\n",
        "  test_coco_file  = BASE_DIR + f'/{v}/test_{ds}_coco.json'\n",
        "  return train_coco_file, test_coco_file\n",
        "\n",
        "\n",
        "def save_results(name, result):\n",
        "  print('Saving results...')\n",
        "  filename = f'{DRIVE}/{name}.json'\n",
        "  contents = json.dumps(result)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "    f.write(contents)\n",
        "\n",
        "  print(f'Saved {filename}')\n",
        "\n",
        "\n",
        "def save_test_imgs(instance, cfg, version, ds, predictor):\n",
        "  print('Saving images...')\n",
        "\n",
        "  img_dir  = BASE_DIR + f'/{version}/ds/'\n",
        "  _, test_coco_file = get_train_test_coco_files(version, ds)\n",
        "\n",
        "  with open(test_coco_file, 'r') as f:\n",
        "    data = json.loads(f.read())\n",
        "\n",
        "  i = 1\n",
        "  for d in random.sample(data['images'], 2):\n",
        "      img = cv2.imread(img_dir + d[\"file_name\"])\n",
        "\n",
        "      outputs = predictor(img)\n",
        "\n",
        "      v = Visualizer(\n",
        "          img[:,:,::-1], \n",
        "          MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), \n",
        "          scale=0.5\n",
        "      )\n",
        "      v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "      \n",
        "      output = f'{DRIVE}/out_imgs/{version}/{instance}___{i}.png'\n",
        "      cv2.imwrite(output, v.get_image()[:, :, ::-1])\n",
        "      # cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "      print(f'Saved {i} image {output}')\n",
        "      \n",
        "      i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA",
        "colab_type": "text"
      },
      "source": [
        "# Train & Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd",
        "colab_type": "code",
        "outputId": "80974c5a-bdea-4381-a43c-ea779d354413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def train(instance, v, ds, model, iterations, lr, batch_size, dry_run=False):\n",
        "  img_dir  = BASE_DIR + f'/{v}/ds/'\n",
        "  model_path = f'COCO-Detection/{model}'\n",
        "\n",
        "  train_instance = f'train/{instance}'\n",
        "  test_instance  = f'test/{instance}'\n",
        "\n",
        "  train_coco_file, test_coco_file = get_train_test_coco_files(v, ds)\n",
        "\n",
        "  register_coco_instances(train_instance, {}, train_coco_file, img_dir)\n",
        "  register_coco_instances(test_instance, {}, test_coco_file, img_dir)\n",
        "  MetadataCatalog.get(train_instance).set(thing_classes=CLASSES)\n",
        "  MetadataCatalog.get(test_instance).set(thing_classes=CLASSES)\n",
        "\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(model_path))\n",
        "  cfg.DATASETS.TRAIN = (train_instance,)\n",
        "  cfg.DATASETS.TEST = ()\n",
        "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "  cfg.DATALOADER.NUM_WORKERS = 2\n",
        "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "  cfg.OUTPUT_DIR = f'./outputs/{instance}'  \n",
        "\n",
        "  # Hyperparameter seleciton  \n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_path) # TODO What is checkpoint url?\n",
        "  cfg.SOLVER.MAX_ITER = iterations\n",
        "  cfg.SOLVER.BASE_LR = lr\n",
        "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batch_size\n",
        "\n",
        "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "  trainer = DefaultTrainer(cfg) \n",
        "  trainer.resume_or_load(resume=False)\n",
        "\n",
        "  if not dry_run:\n",
        "    print(f'**********************************************')\n",
        "    print(f'\\t\\t Begin train {instance}'                 )\n",
        "    print(f'**********************************************')\n",
        "    trainer.train()\n",
        "\n",
        "  return cfg, trainer, train_instance, test_instance\n",
        "\n",
        "\n",
        "\n",
        "def test(instance, cfg, trainer, test_instance):  \n",
        "  print(f'**********************************************')\n",
        "  print(f'\\t\\t Test {instance}'                          )\n",
        "  print(f'**********************************************')\n",
        "  cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75 # threshold of 75% certainty at which we’ll consider the predictions as correct\n",
        "  cfg.DATASETS.TEST = (test_instance, )  \n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  evaluator = COCOEvaluator(test_instance, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "  test_loader = build_detection_test_loader(cfg, test_instance)\n",
        "  result = inference_on_dataset(trainer.model, test_loader, evaluator)  \n",
        "  \n",
        "  return result, predictor\n",
        "\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m-%d-%Y_%H:%M\")\n",
        "\n",
        "\n",
        "for v in versions:\n",
        "  for ds in test_train_splits:\n",
        "    for model in models:\n",
        "\n",
        "      results = {}\n",
        "\n",
        "      for iterations in iters:\n",
        "\n",
        "        results[iterations] = {}\n",
        "\n",
        "        for lr in lrs:\n",
        "\n",
        "          results[iterations][lr] = {}\n",
        "\n",
        "          for batch_size in batch_sizes_per_img:\n",
        "            \n",
        "            instance = f'{v}_{ds}_{model}_{iterations}_{lr}_{batch_size}'\n",
        "\n",
        "            cfg, trainer, train_instance, test_instance = train(\n",
        "                instance, v, ds, model, iterations, lr, batch_size\n",
        "            )\n",
        "\n",
        "            result, predictor = test(instance, cfg, trainer, test_instance)\n",
        "\n",
        "            save_test_imgs(instance, cfg, v, ds, predictor)\n",
        "\n",
        "            results[iterations][lr][batch_size] = result\n",
        "\n",
        "          save_results(f'{v}_{ds}_{model}_{date_time}', results)\n",
        "\n",
        "                       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 00:07:50 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 00:07:50 d2.data.datasets.coco]: \u001b[0mLoaded 1029 images in COCO format from greenthumbs/data/v01/train_75%_coco.json\n",
            "\u001b[32m[05/04 00:07:50 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1029 images left.\n",
            "\u001b[32m[05/04 00:07:50 d2.data.common]: \u001b[0mSerializing 1029 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 00:07:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.31 MiB\n",
            "\u001b[32m[05/04 00:07:50 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 00:07:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128\n",
            "**********************************************\n",
            "\u001b[32m[05/04 00:07:50 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 00:07:57 d2.utils.events]: \u001b[0m eta: 0:21:58  iter: 19  total_loss: 3.705  loss_cls: 2.721  loss_box_reg: 0.728  loss_rpn_cls: 0.208  loss_rpn_loc: 0.040  time: 0.3298  data_time: 0.0120  lr: 0.000020  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:03 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 39  total_loss: 3.114  loss_cls: 2.136  loss_box_reg: 0.789  loss_rpn_cls: 0.197  loss_rpn_loc: 0.041  time: 0.3285  data_time: 0.0063  lr: 0.000040  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:10 d2.utils.events]: \u001b[0m eta: 0:21:41  iter: 59  total_loss: 2.252  loss_cls: 1.116  loss_box_reg: 0.725  loss_rpn_cls: 0.159  loss_rpn_loc: 0.070  time: 0.3271  data_time: 0.0096  lr: 0.000060  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:16 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 79  total_loss: 2.028  loss_cls: 1.005  loss_box_reg: 0.788  loss_rpn_cls: 0.151  loss_rpn_loc: 0.059  time: 0.3278  data_time: 0.0066  lr: 0.000080  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:23 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 99  total_loss: 2.001  loss_cls: 0.931  loss_box_reg: 0.809  loss_rpn_cls: 0.179  loss_rpn_loc: 0.086  time: 0.3281  data_time: 0.0065  lr: 0.000100  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:29 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 119  total_loss: 1.646  loss_cls: 0.734  loss_box_reg: 0.712  loss_rpn_cls: 0.135  loss_rpn_loc: 0.038  time: 0.3272  data_time: 0.0062  lr: 0.000120  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:36 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 139  total_loss: 2.089  loss_cls: 0.845  loss_box_reg: 0.829  loss_rpn_cls: 0.182  loss_rpn_loc: 0.068  time: 0.3268  data_time: 0.0063  lr: 0.000140  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:43 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 159  total_loss: 1.903  loss_cls: 0.780  loss_box_reg: 0.781  loss_rpn_cls: 0.184  loss_rpn_loc: 0.043  time: 0.3272  data_time: 0.0135  lr: 0.000160  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:49 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 179  total_loss: 1.654  loss_cls: 0.711  loss_box_reg: 0.717  loss_rpn_cls: 0.148  loss_rpn_loc: 0.042  time: 0.3266  data_time: 0.0056  lr: 0.000180  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:08:56 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 199  total_loss: 1.738  loss_cls: 0.729  loss_box_reg: 0.840  loss_rpn_cls: 0.140  loss_rpn_loc: 0.049  time: 0.3273  data_time: 0.0206  lr: 0.000200  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:02 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 219  total_loss: 1.847  loss_cls: 0.781  loss_box_reg: 0.790  loss_rpn_cls: 0.133  loss_rpn_loc: 0.045  time: 0.3269  data_time: 0.0063  lr: 0.000220  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:09 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 239  total_loss: 1.865  loss_cls: 0.786  loss_box_reg: 0.853  loss_rpn_cls: 0.153  loss_rpn_loc: 0.066  time: 0.3268  data_time: 0.0066  lr: 0.000240  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:15 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 259  total_loss: 1.563  loss_cls: 0.618  loss_box_reg: 0.730  loss_rpn_cls: 0.147  loss_rpn_loc: 0.042  time: 0.3270  data_time: 0.0083  lr: 0.000260  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:22 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 279  total_loss: 1.578  loss_cls: 0.627  loss_box_reg: 0.795  loss_rpn_cls: 0.119  loss_rpn_loc: 0.048  time: 0.3268  data_time: 0.0055  lr: 0.000280  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:28 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 299  total_loss: 1.613  loss_cls: 0.601  loss_box_reg: 0.799  loss_rpn_cls: 0.129  loss_rpn_loc: 0.039  time: 0.3268  data_time: 0.0061  lr: 0.000300  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:35 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 319  total_loss: 1.285  loss_cls: 0.464  loss_box_reg: 0.680  loss_rpn_cls: 0.097  loss_rpn_loc: 0.060  time: 0.3268  data_time: 0.0064  lr: 0.000320  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:41 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 339  total_loss: 1.439  loss_cls: 0.550  loss_box_reg: 0.754  loss_rpn_cls: 0.103  loss_rpn_loc: 0.026  time: 0.3266  data_time: 0.0101  lr: 0.000340  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:48 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 359  total_loss: 1.458  loss_cls: 0.554  loss_box_reg: 0.674  loss_rpn_cls: 0.125  loss_rpn_loc: 0.067  time: 0.3265  data_time: 0.0059  lr: 0.000360  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:09:54 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 379  total_loss: 1.209  loss_cls: 0.427  loss_box_reg: 0.609  loss_rpn_cls: 0.102  loss_rpn_loc: 0.054  time: 0.3261  data_time: 0.0063  lr: 0.000380  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:01 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 399  total_loss: 1.263  loss_cls: 0.460  loss_box_reg: 0.599  loss_rpn_cls: 0.103  loss_rpn_loc: 0.041  time: 0.3258  data_time: 0.0060  lr: 0.000400  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:07 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 419  total_loss: 1.422  loss_cls: 0.457  loss_box_reg: 0.628  loss_rpn_cls: 0.164  loss_rpn_loc: 0.061  time: 0.3260  data_time: 0.0069  lr: 0.000420  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:14 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 439  total_loss: 1.307  loss_cls: 0.479  loss_box_reg: 0.576  loss_rpn_cls: 0.150  loss_rpn_loc: 0.059  time: 0.3259  data_time: 0.0060  lr: 0.000440  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:20 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 459  total_loss: 1.189  loss_cls: 0.429  loss_box_reg: 0.623  loss_rpn_cls: 0.090  loss_rpn_loc: 0.041  time: 0.3256  data_time: 0.0056  lr: 0.000460  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:27 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 479  total_loss: 0.992  loss_cls: 0.358  loss_box_reg: 0.534  loss_rpn_cls: 0.083  loss_rpn_loc: 0.030  time: 0.3255  data_time: 0.0057  lr: 0.000480  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:33 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 499  total_loss: 1.035  loss_cls: 0.413  loss_box_reg: 0.493  loss_rpn_cls: 0.097  loss_rpn_loc: 0.025  time: 0.3254  data_time: 0.0090  lr: 0.000500  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:40 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 519  total_loss: 1.095  loss_cls: 0.417  loss_box_reg: 0.448  loss_rpn_cls: 0.094  loss_rpn_loc: 0.039  time: 0.3253  data_time: 0.0061  lr: 0.000519  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:46 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 539  total_loss: 1.074  loss_cls: 0.425  loss_box_reg: 0.503  loss_rpn_cls: 0.084  loss_rpn_loc: 0.025  time: 0.3253  data_time: 0.0062  lr: 0.000539  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:53 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 559  total_loss: 1.093  loss_cls: 0.394  loss_box_reg: 0.493  loss_rpn_cls: 0.088  loss_rpn_loc: 0.052  time: 0.3253  data_time: 0.0065  lr: 0.000559  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:10:59 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 579  total_loss: 1.028  loss_cls: 0.357  loss_box_reg: 0.439  loss_rpn_cls: 0.089  loss_rpn_loc: 0.069  time: 0.3252  data_time: 0.0136  lr: 0.000579  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:06 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 599  total_loss: 1.097  loss_cls: 0.399  loss_box_reg: 0.527  loss_rpn_cls: 0.106  loss_rpn_loc: 0.060  time: 0.3250  data_time: 0.0092  lr: 0.000599  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:12 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 619  total_loss: 1.089  loss_cls: 0.308  loss_box_reg: 0.509  loss_rpn_cls: 0.105  loss_rpn_loc: 0.040  time: 0.3251  data_time: 0.0062  lr: 0.000619  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:19 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 639  total_loss: 0.992  loss_cls: 0.349  loss_box_reg: 0.414  loss_rpn_cls: 0.100  loss_rpn_loc: 0.046  time: 0.3251  data_time: 0.0066  lr: 0.000639  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:25 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 659  total_loss: 0.953  loss_cls: 0.379  loss_box_reg: 0.407  loss_rpn_cls: 0.097  loss_rpn_loc: 0.042  time: 0.3250  data_time: 0.0061  lr: 0.000659  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:32 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 679  total_loss: 0.923  loss_cls: 0.313  loss_box_reg: 0.452  loss_rpn_cls: 0.076  loss_rpn_loc: 0.044  time: 0.3250  data_time: 0.0064  lr: 0.000679  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:38 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 699  total_loss: 1.043  loss_cls: 0.370  loss_box_reg: 0.478  loss_rpn_cls: 0.119  loss_rpn_loc: 0.049  time: 0.3253  data_time: 0.0245  lr: 0.000699  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:45 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 719  total_loss: 0.996  loss_cls: 0.448  loss_box_reg: 0.449  loss_rpn_cls: 0.061  loss_rpn_loc: 0.026  time: 0.3253  data_time: 0.0060  lr: 0.000719  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:51 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 739  total_loss: 1.034  loss_cls: 0.392  loss_box_reg: 0.460  loss_rpn_cls: 0.086  loss_rpn_loc: 0.033  time: 0.3253  data_time: 0.0072  lr: 0.000739  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:11:58 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 759  total_loss: 0.862  loss_cls: 0.326  loss_box_reg: 0.380  loss_rpn_cls: 0.104  loss_rpn_loc: 0.040  time: 0.3251  data_time: 0.0063  lr: 0.000759  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:04 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 779  total_loss: 0.899  loss_cls: 0.266  loss_box_reg: 0.387  loss_rpn_cls: 0.089  loss_rpn_loc: 0.040  time: 0.3253  data_time: 0.0149  lr: 0.000779  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:11 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 799  total_loss: 0.953  loss_cls: 0.305  loss_box_reg: 0.462  loss_rpn_cls: 0.080  loss_rpn_loc: 0.036  time: 0.3252  data_time: 0.0057  lr: 0.000799  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:18 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 819  total_loss: 0.926  loss_cls: 0.270  loss_box_reg: 0.442  loss_rpn_cls: 0.091  loss_rpn_loc: 0.052  time: 0.3253  data_time: 0.0143  lr: 0.000819  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:24 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 839  total_loss: 0.895  loss_cls: 0.313  loss_box_reg: 0.416  loss_rpn_cls: 0.085  loss_rpn_loc: 0.049  time: 0.3253  data_time: 0.0063  lr: 0.000839  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:31 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 859  total_loss: 0.945  loss_cls: 0.334  loss_box_reg: 0.408  loss_rpn_cls: 0.059  loss_rpn_loc: 0.035  time: 0.3253  data_time: 0.0057  lr: 0.000859  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:37 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 879  total_loss: 0.908  loss_cls: 0.282  loss_box_reg: 0.422  loss_rpn_cls: 0.068  loss_rpn_loc: 0.042  time: 0.3252  data_time: 0.0059  lr: 0.000879  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:44 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 899  total_loss: 1.019  loss_cls: 0.358  loss_box_reg: 0.444  loss_rpn_cls: 0.100  loss_rpn_loc: 0.056  time: 0.3253  data_time: 0.0061  lr: 0.000899  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:50 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 919  total_loss: 0.654  loss_cls: 0.268  loss_box_reg: 0.363  loss_rpn_cls: 0.070  loss_rpn_loc: 0.040  time: 0.3251  data_time: 0.0056  lr: 0.000919  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:12:56 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 939  total_loss: 1.169  loss_cls: 0.417  loss_box_reg: 0.443  loss_rpn_cls: 0.135  loss_rpn_loc: 0.071  time: 0.3249  data_time: 0.0067  lr: 0.000939  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:03 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 959  total_loss: 0.932  loss_cls: 0.313  loss_box_reg: 0.479  loss_rpn_cls: 0.068  loss_rpn_loc: 0.058  time: 0.3251  data_time: 0.0151  lr: 0.000959  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:10 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 979  total_loss: 0.981  loss_cls: 0.363  loss_box_reg: 0.426  loss_rpn_cls: 0.101  loss_rpn_loc: 0.052  time: 0.3252  data_time: 0.0064  lr: 0.000979  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:16 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 999  total_loss: 0.864  loss_cls: 0.289  loss_box_reg: 0.370  loss_rpn_cls: 0.084  loss_rpn_loc: 0.057  time: 0.3253  data_time: 0.0066  lr: 0.000999  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:23 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 1019  total_loss: 0.925  loss_cls: 0.287  loss_box_reg: 0.362  loss_rpn_cls: 0.102  loss_rpn_loc: 0.062  time: 0.3253  data_time: 0.0068  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:29 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 1039  total_loss: 0.870  loss_cls: 0.286  loss_box_reg: 0.421  loss_rpn_cls: 0.082  loss_rpn_loc: 0.036  time: 0.3254  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:36 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 1059  total_loss: 0.798  loss_cls: 0.307  loss_box_reg: 0.398  loss_rpn_cls: 0.071  loss_rpn_loc: 0.055  time: 0.3251  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:42 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 1079  total_loss: 0.784  loss_cls: 0.246  loss_box_reg: 0.391  loss_rpn_cls: 0.072  loss_rpn_loc: 0.034  time: 0.3250  data_time: 0.0087  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:48 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 1099  total_loss: 0.946  loss_cls: 0.304  loss_box_reg: 0.415  loss_rpn_cls: 0.067  loss_rpn_loc: 0.026  time: 0.3249  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:13:55 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 1119  total_loss: 0.740  loss_cls: 0.248  loss_box_reg: 0.398  loss_rpn_cls: 0.082  loss_rpn_loc: 0.052  time: 0.3250  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:01 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 1139  total_loss: 0.847  loss_cls: 0.251  loss_box_reg: 0.374  loss_rpn_cls: 0.084  loss_rpn_loc: 0.034  time: 0.3249  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:08 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 1159  total_loss: 0.691  loss_cls: 0.205  loss_box_reg: 0.339  loss_rpn_cls: 0.058  loss_rpn_loc: 0.055  time: 0.3248  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:14 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 1179  total_loss: 0.850  loss_cls: 0.233  loss_box_reg: 0.394  loss_rpn_cls: 0.069  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:21 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 1199  total_loss: 0.902  loss_cls: 0.317  loss_box_reg: 0.377  loss_rpn_cls: 0.079  loss_rpn_loc: 0.057  time: 0.3247  data_time: 0.0067  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:27 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 1219  total_loss: 0.697  loss_cls: 0.166  loss_box_reg: 0.397  loss_rpn_cls: 0.055  loss_rpn_loc: 0.033  time: 0.3247  data_time: 0.0057  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:34 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 1239  total_loss: 0.678  loss_cls: 0.175  loss_box_reg: 0.342  loss_rpn_cls: 0.054  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:40 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 1259  total_loss: 0.731  loss_cls: 0.224  loss_box_reg: 0.399  loss_rpn_cls: 0.067  loss_rpn_loc: 0.035  time: 0.3247  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:47 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 1279  total_loss: 0.654  loss_cls: 0.167  loss_box_reg: 0.390  loss_rpn_cls: 0.084  loss_rpn_loc: 0.042  time: 0.3248  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:14:53 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1299  total_loss: 0.783  loss_cls: 0.263  loss_box_reg: 0.349  loss_rpn_cls: 0.076  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:00 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 1319  total_loss: 0.749  loss_cls: 0.243  loss_box_reg: 0.363  loss_rpn_cls: 0.067  loss_rpn_loc: 0.043  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:06 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 1339  total_loss: 0.702  loss_cls: 0.197  loss_box_reg: 0.383  loss_rpn_cls: 0.066  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0119  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:13 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 1359  total_loss: 0.892  loss_cls: 0.281  loss_box_reg: 0.364  loss_rpn_cls: 0.078  loss_rpn_loc: 0.065  time: 0.3249  data_time: 0.0147  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:19 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 1379  total_loss: 0.967  loss_cls: 0.350  loss_box_reg: 0.387  loss_rpn_cls: 0.105  loss_rpn_loc: 0.053  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:26 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 1399  total_loss: 0.810  loss_cls: 0.309  loss_box_reg: 0.377  loss_rpn_cls: 0.103  loss_rpn_loc: 0.063  time: 0.3248  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:33 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 1419  total_loss: 0.742  loss_cls: 0.205  loss_box_reg: 0.363  loss_rpn_cls: 0.096  loss_rpn_loc: 0.045  time: 0.3249  data_time: 0.0067  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:39 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 1439  total_loss: 0.819  loss_cls: 0.272  loss_box_reg: 0.429  loss_rpn_cls: 0.055  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0057  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:46 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 1459  total_loss: 0.756  loss_cls: 0.251  loss_box_reg: 0.367  loss_rpn_cls: 0.063  loss_rpn_loc: 0.031  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:52 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 1479  total_loss: 0.970  loss_cls: 0.355  loss_box_reg: 0.448  loss_rpn_cls: 0.076  loss_rpn_loc: 0.040  time: 0.3247  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:15:58 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 1499  total_loss: 0.772  loss_cls: 0.230  loss_box_reg: 0.389  loss_rpn_cls: 0.076  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:05 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 1519  total_loss: 0.718  loss_cls: 0.198  loss_box_reg: 0.355  loss_rpn_cls: 0.061  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:11 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 1539  total_loss: 0.700  loss_cls: 0.167  loss_box_reg: 0.373  loss_rpn_cls: 0.062  loss_rpn_loc: 0.038  time: 0.3247  data_time: 0.0086  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:18 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 1559  total_loss: 0.660  loss_cls: 0.220  loss_box_reg: 0.353  loss_rpn_cls: 0.068  loss_rpn_loc: 0.047  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:24 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 1579  total_loss: 0.798  loss_cls: 0.236  loss_box_reg: 0.346  loss_rpn_cls: 0.066  loss_rpn_loc: 0.035  time: 0.3248  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:31 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 1599  total_loss: 0.673  loss_cls: 0.256  loss_box_reg: 0.288  loss_rpn_cls: 0.053  loss_rpn_loc: 0.033  time: 0.3247  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:37 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 1619  total_loss: 0.626  loss_cls: 0.173  loss_box_reg: 0.325  loss_rpn_cls: 0.047  loss_rpn_loc: 0.058  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:44 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 1639  total_loss: 0.813  loss_cls: 0.265  loss_box_reg: 0.390  loss_rpn_cls: 0.063  loss_rpn_loc: 0.047  time: 0.3248  data_time: 0.0150  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:50 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 1659  total_loss: 0.658  loss_cls: 0.219  loss_box_reg: 0.359  loss_rpn_cls: 0.055  loss_rpn_loc: 0.038  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:16:57 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 1679  total_loss: 0.627  loss_cls: 0.245  loss_box_reg: 0.311  loss_rpn_cls: 0.053  loss_rpn_loc: 0.053  time: 0.3247  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:04 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1699  total_loss: 0.888  loss_cls: 0.293  loss_box_reg: 0.381  loss_rpn_cls: 0.067  loss_rpn_loc: 0.032  time: 0.3247  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:10 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 1719  total_loss: 0.648  loss_cls: 0.233  loss_box_reg: 0.318  loss_rpn_cls: 0.055  loss_rpn_loc: 0.037  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:16 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 1739  total_loss: 0.784  loss_cls: 0.206  loss_box_reg: 0.407  loss_rpn_cls: 0.065  loss_rpn_loc: 0.058  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:23 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1759  total_loss: 0.560  loss_cls: 0.156  loss_box_reg: 0.299  loss_rpn_cls: 0.048  loss_rpn_loc: 0.029  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:29 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1779  total_loss: 0.731  loss_cls: 0.229  loss_box_reg: 0.338  loss_rpn_cls: 0.063  loss_rpn_loc: 0.044  time: 0.3246  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:36 d2.utils.events]: \u001b[0m eta: 0:11:54  iter: 1799  total_loss: 0.598  loss_cls: 0.165  loss_box_reg: 0.311  loss_rpn_cls: 0.063  loss_rpn_loc: 0.036  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:42 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 1819  total_loss: 0.710  loss_cls: 0.233  loss_box_reg: 0.386  loss_rpn_cls: 0.058  loss_rpn_loc: 0.027  time: 0.3245  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:49 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 1839  total_loss: 0.691  loss_cls: 0.192  loss_box_reg: 0.340  loss_rpn_cls: 0.055  loss_rpn_loc: 0.033  time: 0.3244  data_time: 0.0069  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:17:55 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 1859  total_loss: 0.691  loss_cls: 0.234  loss_box_reg: 0.409  loss_rpn_cls: 0.060  loss_rpn_loc: 0.045  time: 0.3245  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:01 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 1879  total_loss: 0.837  loss_cls: 0.250  loss_box_reg: 0.350  loss_rpn_cls: 0.069  loss_rpn_loc: 0.043  time: 0.3244  data_time: 0.0067  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:08 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 1899  total_loss: 0.632  loss_cls: 0.210  loss_box_reg: 0.347  loss_rpn_cls: 0.054  loss_rpn_loc: 0.024  time: 0.3244  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:14 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 1919  total_loss: 0.648  loss_cls: 0.147  loss_box_reg: 0.331  loss_rpn_cls: 0.061  loss_rpn_loc: 0.054  time: 0.3243  data_time: 0.0132  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:21 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 1939  total_loss: 0.796  loss_cls: 0.248  loss_box_reg: 0.344  loss_rpn_cls: 0.071  loss_rpn_loc: 0.064  time: 0.3243  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:27 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1959  total_loss: 0.700  loss_cls: 0.210  loss_box_reg: 0.301  loss_rpn_cls: 0.071  loss_rpn_loc: 0.058  time: 0.3243  data_time: 0.0071  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:34 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 1979  total_loss: 0.685  loss_cls: 0.200  loss_box_reg: 0.319  loss_rpn_cls: 0.058  loss_rpn_loc: 0.037  time: 0.3243  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:40 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 1999  total_loss: 0.580  loss_cls: 0.157  loss_box_reg: 0.310  loss_rpn_cls: 0.034  loss_rpn_loc: 0.028  time: 0.3244  data_time: 0.0109  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:47 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 2019  total_loss: 0.650  loss_cls: 0.152  loss_box_reg: 0.332  loss_rpn_cls: 0.043  loss_rpn_loc: 0.048  time: 0.3243  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:18:54 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 2039  total_loss: 0.609  loss_cls: 0.152  loss_box_reg: 0.281  loss_rpn_cls: 0.066  loss_rpn_loc: 0.046  time: 0.3244  data_time: 0.0143  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:00 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 2059  total_loss: 0.683  loss_cls: 0.229  loss_box_reg: 0.334  loss_rpn_cls: 0.069  loss_rpn_loc: 0.033  time: 0.3245  data_time: 0.0237  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:07 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 2079  total_loss: 0.588  loss_cls: 0.179  loss_box_reg: 0.278  loss_rpn_cls: 0.040  loss_rpn_loc: 0.045  time: 0.3246  data_time: 0.0138  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:13 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 2099  total_loss: 0.651  loss_cls: 0.184  loss_box_reg: 0.362  loss_rpn_cls: 0.045  loss_rpn_loc: 0.036  time: 0.3245  data_time: 0.0101  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:20 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 2119  total_loss: 0.625  loss_cls: 0.169  loss_box_reg: 0.311  loss_rpn_cls: 0.085  loss_rpn_loc: 0.055  time: 0.3246  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:26 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 2139  total_loss: 0.669  loss_cls: 0.219  loss_box_reg: 0.327  loss_rpn_cls: 0.045  loss_rpn_loc: 0.033  time: 0.3245  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:33 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 2159  total_loss: 0.596  loss_cls: 0.182  loss_box_reg: 0.314  loss_rpn_cls: 0.043  loss_rpn_loc: 0.030  time: 0.3246  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:39 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 2179  total_loss: 0.529  loss_cls: 0.152  loss_box_reg: 0.292  loss_rpn_cls: 0.054  loss_rpn_loc: 0.024  time: 0.3246  data_time: 0.0053  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:46 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 2199  total_loss: 0.641  loss_cls: 0.105  loss_box_reg: 0.355  loss_rpn_cls: 0.056  loss_rpn_loc: 0.042  time: 0.3246  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:53 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 2219  total_loss: 0.643  loss_cls: 0.181  loss_box_reg: 0.319  loss_rpn_cls: 0.055  loss_rpn_loc: 0.036  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:19:59 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 2239  total_loss: 0.630  loss_cls: 0.195  loss_box_reg: 0.326  loss_rpn_cls: 0.046  loss_rpn_loc: 0.033  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:06 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 2259  total_loss: 0.628  loss_cls: 0.191  loss_box_reg: 0.336  loss_rpn_cls: 0.052  loss_rpn_loc: 0.044  time: 0.3249  data_time: 0.0291  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:13 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 2279  total_loss: 0.576  loss_cls: 0.166  loss_box_reg: 0.303  loss_rpn_cls: 0.039  loss_rpn_loc: 0.049  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:19 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 2299  total_loss: 0.523  loss_cls: 0.145  loss_box_reg: 0.304  loss_rpn_cls: 0.055  loss_rpn_loc: 0.032  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:25 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 2319  total_loss: 0.541  loss_cls: 0.133  loss_box_reg: 0.354  loss_rpn_cls: 0.031  loss_rpn_loc: 0.030  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:32 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 2339  total_loss: 0.783  loss_cls: 0.258  loss_box_reg: 0.362  loss_rpn_cls: 0.055  loss_rpn_loc: 0.060  time: 0.3248  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:39 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 2359  total_loss: 0.531  loss_cls: 0.122  loss_box_reg: 0.327  loss_rpn_cls: 0.046  loss_rpn_loc: 0.035  time: 0.3248  data_time: 0.0158  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:45 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 2379  total_loss: 0.716  loss_cls: 0.189  loss_box_reg: 0.336  loss_rpn_cls: 0.058  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:52 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 2399  total_loss: 0.524  loss_cls: 0.148  loss_box_reg: 0.251  loss_rpn_cls: 0.043  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0204  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:20:58 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 2419  total_loss: 0.605  loss_cls: 0.168  loss_box_reg: 0.296  loss_rpn_cls: 0.091  loss_rpn_loc: 0.069  time: 0.3249  data_time: 0.0083  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:05 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 2439  total_loss: 0.699  loss_cls: 0.230  loss_box_reg: 0.338  loss_rpn_cls: 0.044  loss_rpn_loc: 0.035  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:11 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 2459  total_loss: 0.518  loss_cls: 0.149  loss_box_reg: 0.289  loss_rpn_cls: 0.038  loss_rpn_loc: 0.039  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:18 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 2479  total_loss: 0.555  loss_cls: 0.155  loss_box_reg: 0.317  loss_rpn_cls: 0.046  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:24 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 2499  total_loss: 0.629  loss_cls: 0.215  loss_box_reg: 0.322  loss_rpn_cls: 0.049  loss_rpn_loc: 0.028  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:31 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 2519  total_loss: 0.707  loss_cls: 0.246  loss_box_reg: 0.313  loss_rpn_cls: 0.056  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0071  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:37 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 2539  total_loss: 0.620  loss_cls: 0.152  loss_box_reg: 0.296  loss_rpn_cls: 0.047  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:44 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 2559  total_loss: 0.641  loss_cls: 0.147  loss_box_reg: 0.309  loss_rpn_cls: 0.079  loss_rpn_loc: 0.064  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:50 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 2579  total_loss: 0.563  loss_cls: 0.126  loss_box_reg: 0.280  loss_rpn_cls: 0.052  loss_rpn_loc: 0.051  time: 0.3248  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:21:57 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 2599  total_loss: 0.536  loss_cls: 0.127  loss_box_reg: 0.290  loss_rpn_cls: 0.043  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:03 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 2619  total_loss: 0.647  loss_cls: 0.235  loss_box_reg: 0.309  loss_rpn_cls: 0.051  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0093  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:10 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 2639  total_loss: 0.675  loss_cls: 0.172  loss_box_reg: 0.343  loss_rpn_cls: 0.059  loss_rpn_loc: 0.046  time: 0.3248  data_time: 0.0070  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:16 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 2659  total_loss: 0.603  loss_cls: 0.187  loss_box_reg: 0.285  loss_rpn_cls: 0.051  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0070  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:22 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 2679  total_loss: 0.522  loss_cls: 0.116  loss_box_reg: 0.307  loss_rpn_cls: 0.073  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0082  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:29 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 2699  total_loss: 0.667  loss_cls: 0.167  loss_box_reg: 0.342  loss_rpn_cls: 0.053  loss_rpn_loc: 0.057  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:35 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 2719  total_loss: 0.511  loss_cls: 0.120  loss_box_reg: 0.303  loss_rpn_cls: 0.041  loss_rpn_loc: 0.026  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:42 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 2739  total_loss: 0.619  loss_cls: 0.141  loss_box_reg: 0.334  loss_rpn_cls: 0.050  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0074  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:49 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 2759  total_loss: 0.556  loss_cls: 0.112  loss_box_reg: 0.317  loss_rpn_cls: 0.046  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0225  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:22:55 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 2779  total_loss: 0.613  loss_cls: 0.170  loss_box_reg: 0.327  loss_rpn_cls: 0.052  loss_rpn_loc: 0.072  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:02 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 2799  total_loss: 0.490  loss_cls: 0.108  loss_box_reg: 0.292  loss_rpn_cls: 0.044  loss_rpn_loc: 0.041  time: 0.3249  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:09 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 2819  total_loss: 0.505  loss_cls: 0.144  loss_box_reg: 0.299  loss_rpn_cls: 0.029  loss_rpn_loc: 0.040  time: 0.3249  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:15 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 2839  total_loss: 0.508  loss_cls: 0.107  loss_box_reg: 0.281  loss_rpn_cls: 0.026  loss_rpn_loc: 0.053  time: 0.3249  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:22 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2859  total_loss: 0.491  loss_cls: 0.114  loss_box_reg: 0.279  loss_rpn_cls: 0.028  loss_rpn_loc: 0.041  time: 0.3250  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:28 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2879  total_loss: 0.432  loss_cls: 0.072  loss_box_reg: 0.296  loss_rpn_cls: 0.026  loss_rpn_loc: 0.020  time: 0.3249  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:35 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 2899  total_loss: 0.691  loss_cls: 0.161  loss_box_reg: 0.325  loss_rpn_cls: 0.055  loss_rpn_loc: 0.080  time: 0.3250  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:41 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 2919  total_loss: 0.584  loss_cls: 0.170  loss_box_reg: 0.317  loss_rpn_cls: 0.061  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:48 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 2939  total_loss: 0.572  loss_cls: 0.180  loss_box_reg: 0.281  loss_rpn_cls: 0.039  loss_rpn_loc: 0.058  time: 0.3249  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:23:54 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 2959  total_loss: 0.608  loss_cls: 0.133  loss_box_reg: 0.282  loss_rpn_cls: 0.045  loss_rpn_loc: 0.028  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:00 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2979  total_loss: 0.515  loss_cls: 0.120  loss_box_reg: 0.271  loss_rpn_cls: 0.034  loss_rpn_loc: 0.029  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:07 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 2999  total_loss: 0.477  loss_cls: 0.141  loss_box_reg: 0.292  loss_rpn_cls: 0.027  loss_rpn_loc: 0.025  time: 0.3248  data_time: 0.0107  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:13 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 3019  total_loss: 0.564  loss_cls: 0.149  loss_box_reg: 0.285  loss_rpn_cls: 0.032  loss_rpn_loc: 0.028  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:20 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 3039  total_loss: 0.596  loss_cls: 0.165  loss_box_reg: 0.315  loss_rpn_cls: 0.062  loss_rpn_loc: 0.043  time: 0.3248  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:26 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 3059  total_loss: 0.676  loss_cls: 0.221  loss_box_reg: 0.336  loss_rpn_cls: 0.073  loss_rpn_loc: 0.048  time: 0.3247  data_time: 0.0056  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:33 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 3079  total_loss: 0.468  loss_cls: 0.129  loss_box_reg: 0.264  loss_rpn_cls: 0.054  loss_rpn_loc: 0.025  time: 0.3249  data_time: 0.0212  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:39 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 3099  total_loss: 0.504  loss_cls: 0.121  loss_box_reg: 0.276  loss_rpn_cls: 0.047  loss_rpn_loc: 0.046  time: 0.3248  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:46 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 3119  total_loss: 0.495  loss_cls: 0.104  loss_box_reg: 0.257  loss_rpn_cls: 0.049  loss_rpn_loc: 0.040  time: 0.3248  data_time: 0.0057  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:52 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 3139  total_loss: 0.493  loss_cls: 0.101  loss_box_reg: 0.270  loss_rpn_cls: 0.032  loss_rpn_loc: 0.025  time: 0.3248  data_time: 0.0081  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:24:59 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 3159  total_loss: 0.555  loss_cls: 0.119  loss_box_reg: 0.298  loss_rpn_cls: 0.039  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:06 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 3179  total_loss: 0.509  loss_cls: 0.125  loss_box_reg: 0.249  loss_rpn_cls: 0.047  loss_rpn_loc: 0.032  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:12 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 3199  total_loss: 0.429  loss_cls: 0.124  loss_box_reg: 0.254  loss_rpn_cls: 0.033  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0067  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:19 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 3219  total_loss: 0.498  loss_cls: 0.110  loss_box_reg: 0.275  loss_rpn_cls: 0.049  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0073  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:25 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 3239  total_loss: 0.533  loss_cls: 0.099  loss_box_reg: 0.294  loss_rpn_cls: 0.036  loss_rpn_loc: 0.028  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:31 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 3259  total_loss: 0.450  loss_cls: 0.107  loss_box_reg: 0.235  loss_rpn_cls: 0.037  loss_rpn_loc: 0.043  time: 0.3248  data_time: 0.0064  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:38 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 3279  total_loss: 0.607  loss_cls: 0.150  loss_box_reg: 0.319  loss_rpn_cls: 0.050  loss_rpn_loc: 0.048  time: 0.3247  data_time: 0.0059  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:44 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3299  total_loss: 0.539  loss_cls: 0.129  loss_box_reg: 0.285  loss_rpn_cls: 0.041  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0068  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:51 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3319  total_loss: 0.540  loss_cls: 0.163  loss_box_reg: 0.310  loss_rpn_cls: 0.041  loss_rpn_loc: 0.032  time: 0.3248  data_time: 0.0100  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:25:58 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3339  total_loss: 0.579  loss_cls: 0.158  loss_box_reg: 0.285  loss_rpn_cls: 0.047  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0086  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:04 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 3359  total_loss: 0.495  loss_cls: 0.116  loss_box_reg: 0.299  loss_rpn_cls: 0.047  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:10 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 3379  total_loss: 0.534  loss_cls: 0.134  loss_box_reg: 0.287  loss_rpn_cls: 0.038  loss_rpn_loc: 0.028  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:17 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 3399  total_loss: 0.474  loss_cls: 0.115  loss_box_reg: 0.260  loss_rpn_cls: 0.020  loss_rpn_loc: 0.032  time: 0.3247  data_time: 0.0057  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:23 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 3419  total_loss: 0.683  loss_cls: 0.174  loss_box_reg: 0.352  loss_rpn_cls: 0.055  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0078  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:30 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 3439  total_loss: 0.583  loss_cls: 0.140  loss_box_reg: 0.305  loss_rpn_cls: 0.052  loss_rpn_loc: 0.050  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:36 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3459  total_loss: 0.653  loss_cls: 0.203  loss_box_reg: 0.292  loss_rpn_cls: 0.047  loss_rpn_loc: 0.039  time: 0.3247  data_time: 0.0068  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:43 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 3479  total_loss: 0.595  loss_cls: 0.160  loss_box_reg: 0.308  loss_rpn_cls: 0.058  loss_rpn_loc: 0.050  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:49 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 3499  total_loss: 0.565  loss_cls: 0.127  loss_box_reg: 0.282  loss_rpn_cls: 0.043  loss_rpn_loc: 0.040  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:26:56 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 3519  total_loss: 0.602  loss_cls: 0.184  loss_box_reg: 0.264  loss_rpn_cls: 0.038  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:02 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3539  total_loss: 0.595  loss_cls: 0.149  loss_box_reg: 0.281  loss_rpn_cls: 0.058  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:09 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 3559  total_loss: 0.470  loss_cls: 0.122  loss_box_reg: 0.259  loss_rpn_cls: 0.038  loss_rpn_loc: 0.027  time: 0.3247  data_time: 0.0068  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:16 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3579  total_loss: 0.518  loss_cls: 0.127  loss_box_reg: 0.253  loss_rpn_cls: 0.042  loss_rpn_loc: 0.049  time: 0.3248  data_time: 0.0181  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:22 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3599  total_loss: 0.484  loss_cls: 0.101  loss_box_reg: 0.265  loss_rpn_cls: 0.031  loss_rpn_loc: 0.029  time: 0.3248  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:28 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3619  total_loss: 0.490  loss_cls: 0.125  loss_box_reg: 0.256  loss_rpn_cls: 0.041  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:35 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 3639  total_loss: 0.432  loss_cls: 0.091  loss_box_reg: 0.243  loss_rpn_cls: 0.031  loss_rpn_loc: 0.031  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:41 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3659  total_loss: 0.493  loss_cls: 0.139  loss_box_reg: 0.238  loss_rpn_cls: 0.041  loss_rpn_loc: 0.029  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:48 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 3679  total_loss: 0.508  loss_cls: 0.117  loss_box_reg: 0.280  loss_rpn_cls: 0.048  loss_rpn_loc: 0.057  time: 0.3247  data_time: 0.0066  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:27:54 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3699  total_loss: 0.514  loss_cls: 0.126  loss_box_reg: 0.275  loss_rpn_cls: 0.030  loss_rpn_loc: 0.027  time: 0.3247  data_time: 0.0225  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:01 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 3719  total_loss: 0.463  loss_cls: 0.102  loss_box_reg: 0.258  loss_rpn_cls: 0.026  loss_rpn_loc: 0.024  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:08 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3739  total_loss: 0.464  loss_cls: 0.119  loss_box_reg: 0.274  loss_rpn_cls: 0.016  loss_rpn_loc: 0.030  time: 0.3247  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:14 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 3759  total_loss: 0.454  loss_cls: 0.109  loss_box_reg: 0.233  loss_rpn_cls: 0.027  loss_rpn_loc: 0.040  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:21 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 3779  total_loss: 0.453  loss_cls: 0.114  loss_box_reg: 0.263  loss_rpn_cls: 0.036  loss_rpn_loc: 0.043  time: 0.3248  data_time: 0.0240  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:27 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3799  total_loss: 0.517  loss_cls: 0.117  loss_box_reg: 0.280  loss_rpn_cls: 0.032  loss_rpn_loc: 0.045  time: 0.3248  data_time: 0.0057  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:34 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 3819  total_loss: 0.504  loss_cls: 0.088  loss_box_reg: 0.268  loss_rpn_cls: 0.031  loss_rpn_loc: 0.039  time: 0.3248  data_time: 0.0063  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:40 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3839  total_loss: 0.502  loss_cls: 0.114  loss_box_reg: 0.287  loss_rpn_cls: 0.058  loss_rpn_loc: 0.026  time: 0.3248  data_time: 0.0068  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:47 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3859  total_loss: 0.632  loss_cls: 0.123  loss_box_reg: 0.317  loss_rpn_cls: 0.042  loss_rpn_loc: 0.026  time: 0.3248  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:28:53 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 3879  total_loss: 0.566  loss_cls: 0.197  loss_box_reg: 0.238  loss_rpn_cls: 0.042  loss_rpn_loc: 0.054  time: 0.3248  data_time: 0.0104  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:00 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 3899  total_loss: 0.473  loss_cls: 0.081  loss_box_reg: 0.263  loss_rpn_cls: 0.034  loss_rpn_loc: 0.051  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:06 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 3919  total_loss: 0.550  loss_cls: 0.097  loss_box_reg: 0.270  loss_rpn_cls: 0.055  loss_rpn_loc: 0.052  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:13 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3939  total_loss: 0.510  loss_cls: 0.121  loss_box_reg: 0.250  loss_rpn_cls: 0.040  loss_rpn_loc: 0.031  time: 0.3248  data_time: 0.0065  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:19 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 3959  total_loss: 0.461  loss_cls: 0.109  loss_box_reg: 0.228  loss_rpn_cls: 0.051  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0060  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:26 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 3979  total_loss: 0.520  loss_cls: 0.114  loss_box_reg: 0.308  loss_rpn_cls: 0.043  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0095  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.491  loss_cls: 0.116  loss_box_reg: 0.280  loss_rpn_cls: 0.038  loss_rpn_loc: 0.045  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.528  loss_cls: 0.138  loss_box_reg: 0.280  loss_rpn_cls: 0.039  loss_rpn_loc: 0.045  time: 0.3247  data_time: 0.0061  lr: 0.001000  max_mem: 2687M\n",
            "\u001b[32m[05/04 00:29:33 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:21:38 (0.3248 s / it)\n",
            "\u001b[32m[05/04 00:29:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:42 (0:00:03 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 00:29:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 00:29:34 d2.data.datasets.coco]: \u001b[0mLoaded 343 images in COCO format from greenthumbs/data/v01/test_75%_coco.json\n",
            "\u001b[32m[05/04 00:29:34 d2.data.common]: \u001b[0mSerializing 343 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 00:29:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
            "\u001b[32m[05/04 00:29:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 343 images\n",
            "\u001b[32m[05/04 00:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/343. 0.1521 s / img. ETA=0:00:50\n",
            "\u001b[32m[05/04 00:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 37/343. 0.1819 s / img. ETA=0:00:58\n",
            "\u001b[32m[05/04 00:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 68/343. 0.1664 s / img. ETA=0:00:49\n",
            "\u001b[32m[05/04 00:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 99/343. 0.1645 s / img. ETA=0:00:42\n",
            "\u001b[32m[05/04 00:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 131/343. 0.1609 s / img. ETA=0:00:36\n",
            "\u001b[32m[05/04 00:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 160/343. 0.1636 s / img. ETA=0:00:31\n",
            "\u001b[32m[05/04 00:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 192/343. 0.1622 s / img. ETA=0:00:25\n",
            "\u001b[32m[05/04 00:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 225/343. 0.1606 s / img. ETA=0:00:19\n",
            "\u001b[32m[05/04 00:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 255/343. 0.1608 s / img. ETA=0:00:14\n",
            "\u001b[32m[05/04 00:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 284/343. 0.1619 s / img. ETA=0:00:09\n",
            "\u001b[32m[05/04 00:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 319/343. 0.1598 s / img. ETA=0:00:03\n",
            "\u001b[32m[05/04 00:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:56.044315 (0.165812 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 00:30:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:54 (0.160377 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 00:30:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 00:30:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128/coco_instances_results.json\n",
            "\u001b[32m[05/04 00:30:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.22s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.28s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.605\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.416\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "\u001b[32m[05/04 00:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 37.673 | 60.465 | 41.577 | 15.884 | 29.846 | 45.498 |\n",
            "\u001b[32m[05/04 00:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 56.236 | tomato_fruit       | 38.601 | tomato_seedling          | 22.158 |\n",
            "| tomato_young_plant      | 35.699 | tomato_flower      | 36.851 | bell_pepper_fruit        | 54.379 |\n",
            "| bell_pepper_young_plant | 41.357 | bell_pepper_flower | 45.240 | bell_pepper_fruit_unripe | 27.705 |\n",
            "| bell_pepper_seedling    | 14.084 | cucumber_flower    | 60.185 | cucumber_plant           | 6.103  |\n",
            "| cucumber_seedling       | 26.913 | cucumber_fruit     | 70.988 | cucumber_fruit_unripe    | 28.590 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128___2.png\n",
            "Saving results...\n",
            "Saved /content/drive/My Drive/Green Thumbs/v01_75%_faster_rcnn_R_50_C4_3x.yaml_05-03-2020_21:04.json\n",
            "\u001b[32m[05/04 00:30:34 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 00:30:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 00:30:34 d2.data.datasets.coco]: \u001b[0mLoaded 1029 images in COCO format from greenthumbs/data/v01/train_75%_coco.json\n",
            "\u001b[32m[05/04 00:30:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1029 images left.\n",
            "\u001b[32m[05/04 00:30:34 d2.data.common]: \u001b[0mSerializing 1029 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 00:30:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.31 MiB\n",
            "\u001b[32m[05/04 00:30:34 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 00:30:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64\n",
            "**********************************************\n",
            "\u001b[32m[05/04 00:30:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 00:30:40 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 19  total_loss: 3.838  loss_cls: 2.705  loss_box_reg: 0.884  loss_rpn_cls: 0.209  loss_rpn_loc: 0.056  time: 0.2523  data_time: 0.0182  lr: 0.000010  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:30:45 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 39  total_loss: 3.622  loss_cls: 2.442  loss_box_reg: 0.880  loss_rpn_cls: 0.203  loss_rpn_loc: 0.068  time: 0.2594  data_time: 0.0250  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:30:50 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 59  total_loss: 3.159  loss_cls: 1.896  loss_box_reg: 0.954  loss_rpn_cls: 0.224  loss_rpn_loc: 0.052  time: 0.2538  data_time: 0.0056  lr: 0.000030  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:30:55 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 79  total_loss: 2.500  loss_cls: 1.314  loss_box_reg: 0.888  loss_rpn_cls: 0.158  loss_rpn_loc: 0.059  time: 0.2575  data_time: 0.0258  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:00 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 99  total_loss: 2.258  loss_cls: 1.152  loss_box_reg: 0.907  loss_rpn_cls: 0.162  loss_rpn_loc: 0.032  time: 0.2565  data_time: 0.0056  lr: 0.000050  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:05 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 119  total_loss: 2.228  loss_cls: 1.064  loss_box_reg: 0.924  loss_rpn_cls: 0.188  loss_rpn_loc: 0.039  time: 0.2549  data_time: 0.0097  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:10 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 139  total_loss: 2.274  loss_cls: 1.035  loss_box_reg: 0.910  loss_rpn_cls: 0.167  loss_rpn_loc: 0.091  time: 0.2553  data_time: 0.0150  lr: 0.000070  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:15 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 159  total_loss: 2.274  loss_cls: 1.027  loss_box_reg: 0.934  loss_rpn_cls: 0.187  loss_rpn_loc: 0.057  time: 0.2542  data_time: 0.0064  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:20 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 179  total_loss: 2.037  loss_cls: 0.933  loss_box_reg: 0.879  loss_rpn_cls: 0.174  loss_rpn_loc: 0.055  time: 0.2538  data_time: 0.0065  lr: 0.000090  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:25 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 199  total_loss: 2.051  loss_cls: 0.892  loss_box_reg: 0.931  loss_rpn_cls: 0.157  loss_rpn_loc: 0.063  time: 0.2536  data_time: 0.0058  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:31 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 219  total_loss: 1.990  loss_cls: 0.850  loss_box_reg: 0.917  loss_rpn_cls: 0.156  loss_rpn_loc: 0.045  time: 0.2535  data_time: 0.0062  lr: 0.000110  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:36 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 239  total_loss: 1.888  loss_cls: 0.772  loss_box_reg: 0.910  loss_rpn_cls: 0.148  loss_rpn_loc: 0.073  time: 0.2539  data_time: 0.0066  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:41 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 259  total_loss: 1.819  loss_cls: 0.728  loss_box_reg: 0.914  loss_rpn_cls: 0.138  loss_rpn_loc: 0.047  time: 0.2544  data_time: 0.0146  lr: 0.000130  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:46 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 279  total_loss: 1.865  loss_cls: 0.720  loss_box_reg: 0.935  loss_rpn_cls: 0.111  loss_rpn_loc: 0.046  time: 0.2537  data_time: 0.0058  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:51 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 299  total_loss: 1.793  loss_cls: 0.727  loss_box_reg: 0.845  loss_rpn_cls: 0.119  loss_rpn_loc: 0.064  time: 0.2537  data_time: 0.0057  lr: 0.000150  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:31:56 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 319  total_loss: 1.761  loss_cls: 0.641  loss_box_reg: 0.911  loss_rpn_cls: 0.122  loss_rpn_loc: 0.042  time: 0.2549  data_time: 0.0271  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:01 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 339  total_loss: 1.811  loss_cls: 0.719  loss_box_reg: 0.899  loss_rpn_cls: 0.113  loss_rpn_loc: 0.045  time: 0.2543  data_time: 0.0084  lr: 0.000170  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:06 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 359  total_loss: 1.871  loss_cls: 0.745  loss_box_reg: 0.880  loss_rpn_cls: 0.128  loss_rpn_loc: 0.033  time: 0.2542  data_time: 0.0057  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:11 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 379  total_loss: 1.759  loss_cls: 0.706  loss_box_reg: 0.820  loss_rpn_cls: 0.108  loss_rpn_loc: 0.035  time: 0.2536  data_time: 0.0061  lr: 0.000190  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:16 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 399  total_loss: 1.638  loss_cls: 0.574  loss_box_reg: 0.847  loss_rpn_cls: 0.141  loss_rpn_loc: 0.055  time: 0.2531  data_time: 0.0065  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:21 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 419  total_loss: 1.531  loss_cls: 0.491  loss_box_reg: 0.802  loss_rpn_cls: 0.123  loss_rpn_loc: 0.047  time: 0.2532  data_time: 0.0064  lr: 0.000210  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:26 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 439  total_loss: 1.536  loss_cls: 0.590  loss_box_reg: 0.790  loss_rpn_cls: 0.114  loss_rpn_loc: 0.053  time: 0.2529  data_time: 0.0058  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:31 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 459  total_loss: 1.484  loss_cls: 0.541  loss_box_reg: 0.783  loss_rpn_cls: 0.103  loss_rpn_loc: 0.031  time: 0.2532  data_time: 0.0175  lr: 0.000230  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:36 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 479  total_loss: 1.433  loss_cls: 0.527  loss_box_reg: 0.774  loss_rpn_cls: 0.110  loss_rpn_loc: 0.036  time: 0.2528  data_time: 0.0066  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:41 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 499  total_loss: 1.409  loss_cls: 0.490  loss_box_reg: 0.779  loss_rpn_cls: 0.098  loss_rpn_loc: 0.040  time: 0.2527  data_time: 0.0068  lr: 0.000250  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:46 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 519  total_loss: 1.286  loss_cls: 0.468  loss_box_reg: 0.626  loss_rpn_cls: 0.101  loss_rpn_loc: 0.046  time: 0.2524  data_time: 0.0074  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:51 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 539  total_loss: 1.453  loss_cls: 0.593  loss_box_reg: 0.663  loss_rpn_cls: 0.131  loss_rpn_loc: 0.052  time: 0.2525  data_time: 0.0156  lr: 0.000270  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:32:56 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 559  total_loss: 1.406  loss_cls: 0.557  loss_box_reg: 0.707  loss_rpn_cls: 0.113  loss_rpn_loc: 0.039  time: 0.2522  data_time: 0.0062  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:01 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 579  total_loss: 1.334  loss_cls: 0.462  loss_box_reg: 0.705  loss_rpn_cls: 0.104  loss_rpn_loc: 0.051  time: 0.2523  data_time: 0.0065  lr: 0.000290  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:06 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 599  total_loss: 1.322  loss_cls: 0.508  loss_box_reg: 0.664  loss_rpn_cls: 0.101  loss_rpn_loc: 0.055  time: 0.2522  data_time: 0.0062  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:11 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 619  total_loss: 1.204  loss_cls: 0.460  loss_box_reg: 0.634  loss_rpn_cls: 0.111  loss_rpn_loc: 0.074  time: 0.2522  data_time: 0.0058  lr: 0.000310  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:17 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 639  total_loss: 1.124  loss_cls: 0.370  loss_box_reg: 0.583  loss_rpn_cls: 0.096  loss_rpn_loc: 0.033  time: 0.2524  data_time: 0.0200  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:22 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 659  total_loss: 1.227  loss_cls: 0.414  loss_box_reg: 0.630  loss_rpn_cls: 0.108  loss_rpn_loc: 0.050  time: 0.2525  data_time: 0.0065  lr: 0.000330  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:27 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 679  total_loss: 1.198  loss_cls: 0.490  loss_box_reg: 0.548  loss_rpn_cls: 0.111  loss_rpn_loc: 0.062  time: 0.2526  data_time: 0.0114  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:32 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 699  total_loss: 1.164  loss_cls: 0.410  loss_box_reg: 0.578  loss_rpn_cls: 0.087  loss_rpn_loc: 0.040  time: 0.2523  data_time: 0.0060  lr: 0.000350  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:37 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 719  total_loss: 1.287  loss_cls: 0.435  loss_box_reg: 0.585  loss_rpn_cls: 0.117  loss_rpn_loc: 0.054  time: 0.2522  data_time: 0.0057  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:42 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 739  total_loss: 0.932  loss_cls: 0.264  loss_box_reg: 0.505  loss_rpn_cls: 0.105  loss_rpn_loc: 0.039  time: 0.2520  data_time: 0.0072  lr: 0.000370  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:47 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 759  total_loss: 1.139  loss_cls: 0.451  loss_box_reg: 0.558  loss_rpn_cls: 0.115  loss_rpn_loc: 0.041  time: 0.2518  data_time: 0.0062  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:52 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 779  total_loss: 0.972  loss_cls: 0.358  loss_box_reg: 0.464  loss_rpn_cls: 0.087  loss_rpn_loc: 0.044  time: 0.2519  data_time: 0.0138  lr: 0.000390  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:33:57 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 799  total_loss: 1.133  loss_cls: 0.342  loss_box_reg: 0.461  loss_rpn_cls: 0.105  loss_rpn_loc: 0.051  time: 0.2518  data_time: 0.0059  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:02 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 819  total_loss: 1.209  loss_cls: 0.478  loss_box_reg: 0.599  loss_rpn_cls: 0.101  loss_rpn_loc: 0.081  time: 0.2519  data_time: 0.0063  lr: 0.000410  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:07 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 839  total_loss: 0.980  loss_cls: 0.342  loss_box_reg: 0.467  loss_rpn_cls: 0.087  loss_rpn_loc: 0.032  time: 0.2520  data_time: 0.0207  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:12 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 859  total_loss: 1.066  loss_cls: 0.404  loss_box_reg: 0.547  loss_rpn_cls: 0.085  loss_rpn_loc: 0.042  time: 0.2519  data_time: 0.0058  lr: 0.000430  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:17 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 879  total_loss: 1.109  loss_cls: 0.329  loss_box_reg: 0.572  loss_rpn_cls: 0.068  loss_rpn_loc: 0.039  time: 0.2517  data_time: 0.0066  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:22 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 899  total_loss: 1.083  loss_cls: 0.389  loss_box_reg: 0.533  loss_rpn_cls: 0.068  loss_rpn_loc: 0.032  time: 0.2517  data_time: 0.0065  lr: 0.000450  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:27 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 919  total_loss: 0.995  loss_cls: 0.300  loss_box_reg: 0.504  loss_rpn_cls: 0.067  loss_rpn_loc: 0.027  time: 0.2516  data_time: 0.0059  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:32 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 939  total_loss: 1.010  loss_cls: 0.286  loss_box_reg: 0.479  loss_rpn_cls: 0.081  loss_rpn_loc: 0.040  time: 0.2517  data_time: 0.0062  lr: 0.000470  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:37 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 959  total_loss: 0.773  loss_cls: 0.233  loss_box_reg: 0.448  loss_rpn_cls: 0.084  loss_rpn_loc: 0.028  time: 0.2517  data_time: 0.0059  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:42 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 979  total_loss: 0.998  loss_cls: 0.403  loss_box_reg: 0.540  loss_rpn_cls: 0.073  loss_rpn_loc: 0.042  time: 0.2517  data_time: 0.0060  lr: 0.000490  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:48 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 999  total_loss: 1.136  loss_cls: 0.470  loss_box_reg: 0.524  loss_rpn_cls: 0.078  loss_rpn_loc: 0.045  time: 0.2521  data_time: 0.0326  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:53 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1019  total_loss: 0.942  loss_cls: 0.282  loss_box_reg: 0.448  loss_rpn_cls: 0.091  loss_rpn_loc: 0.033  time: 0.2521  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:34:58 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 1039  total_loss: 0.877  loss_cls: 0.308  loss_box_reg: 0.428  loss_rpn_cls: 0.074  loss_rpn_loc: 0.058  time: 0.2520  data_time: 0.0073  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:02 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 1059  total_loss: 1.156  loss_cls: 0.422  loss_box_reg: 0.506  loss_rpn_cls: 0.103  loss_rpn_loc: 0.058  time: 0.2519  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:08 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1079  total_loss: 0.785  loss_cls: 0.247  loss_box_reg: 0.434  loss_rpn_cls: 0.046  loss_rpn_loc: 0.020  time: 0.2519  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:13 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 1099  total_loss: 0.961  loss_cls: 0.306  loss_box_reg: 0.454  loss_rpn_cls: 0.076  loss_rpn_loc: 0.043  time: 0.2521  data_time: 0.0250  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:18 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1119  total_loss: 0.957  loss_cls: 0.332  loss_box_reg: 0.473  loss_rpn_cls: 0.075  loss_rpn_loc: 0.052  time: 0.2523  data_time: 0.0191  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:23 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 1139  total_loss: 0.874  loss_cls: 0.321  loss_box_reg: 0.439  loss_rpn_cls: 0.070  loss_rpn_loc: 0.034  time: 0.2522  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:28 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 1159  total_loss: 0.781  loss_cls: 0.239  loss_box_reg: 0.425  loss_rpn_cls: 0.076  loss_rpn_loc: 0.059  time: 0.2521  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:33 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 1179  total_loss: 1.003  loss_cls: 0.280  loss_box_reg: 0.476  loss_rpn_cls: 0.099  loss_rpn_loc: 0.079  time: 0.2521  data_time: 0.0109  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:38 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 1199  total_loss: 0.852  loss_cls: 0.278  loss_box_reg: 0.458  loss_rpn_cls: 0.078  loss_rpn_loc: 0.035  time: 0.2521  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:43 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 1219  total_loss: 1.009  loss_cls: 0.359  loss_box_reg: 0.487  loss_rpn_cls: 0.081  loss_rpn_loc: 0.043  time: 0.2521  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:48 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 1239  total_loss: 1.222  loss_cls: 0.369  loss_box_reg: 0.573  loss_rpn_cls: 0.100  loss_rpn_loc: 0.069  time: 0.2519  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:53 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 1259  total_loss: 0.721  loss_cls: 0.188  loss_box_reg: 0.393  loss_rpn_cls: 0.066  loss_rpn_loc: 0.031  time: 0.2519  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:35:58 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1279  total_loss: 0.972  loss_cls: 0.331  loss_box_reg: 0.456  loss_rpn_cls: 0.091  loss_rpn_loc: 0.034  time: 0.2519  data_time: 0.0083  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:03 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 1299  total_loss: 0.889  loss_cls: 0.278  loss_box_reg: 0.462  loss_rpn_cls: 0.080  loss_rpn_loc: 0.059  time: 0.2518  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:08 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 1319  total_loss: 0.891  loss_cls: 0.258  loss_box_reg: 0.467  loss_rpn_cls: 0.103  loss_rpn_loc: 0.058  time: 0.2519  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:13 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1339  total_loss: 0.783  loss_cls: 0.245  loss_box_reg: 0.420  loss_rpn_cls: 0.067  loss_rpn_loc: 0.050  time: 0.2519  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:18 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 1359  total_loss: 0.790  loss_cls: 0.255  loss_box_reg: 0.387  loss_rpn_cls: 0.059  loss_rpn_loc: 0.055  time: 0.2519  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:23 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1379  total_loss: 0.792  loss_cls: 0.282  loss_box_reg: 0.403  loss_rpn_cls: 0.066  loss_rpn_loc: 0.034  time: 0.2519  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:28 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 1399  total_loss: 1.093  loss_cls: 0.306  loss_box_reg: 0.501  loss_rpn_cls: 0.081  loss_rpn_loc: 0.049  time: 0.2518  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:34 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 1419  total_loss: 0.780  loss_cls: 0.240  loss_box_reg: 0.458  loss_rpn_cls: 0.071  loss_rpn_loc: 0.037  time: 0.2520  data_time: 0.0183  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:39 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 1439  total_loss: 0.859  loss_cls: 0.318  loss_box_reg: 0.371  loss_rpn_cls: 0.063  loss_rpn_loc: 0.044  time: 0.2519  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:43 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1459  total_loss: 0.887  loss_cls: 0.325  loss_box_reg: 0.433  loss_rpn_cls: 0.087  loss_rpn_loc: 0.050  time: 0.2519  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:49 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 1479  total_loss: 0.894  loss_cls: 0.313  loss_box_reg: 0.428  loss_rpn_cls: 0.062  loss_rpn_loc: 0.040  time: 0.2520  data_time: 0.0201  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:54 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 1499  total_loss: 0.696  loss_cls: 0.240  loss_box_reg: 0.352  loss_rpn_cls: 0.084  loss_rpn_loc: 0.030  time: 0.2519  data_time: 0.0122  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:36:59 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 1519  total_loss: 0.779  loss_cls: 0.225  loss_box_reg: 0.428  loss_rpn_cls: 0.051  loss_rpn_loc: 0.033  time: 0.2518  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:03 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 1539  total_loss: 0.841  loss_cls: 0.257  loss_box_reg: 0.396  loss_rpn_cls: 0.068  loss_rpn_loc: 0.042  time: 0.2517  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:09 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 1559  total_loss: 0.773  loss_cls: 0.239  loss_box_reg: 0.426  loss_rpn_cls: 0.067  loss_rpn_loc: 0.041  time: 0.2517  data_time: 0.0145  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:14 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 1579  total_loss: 0.809  loss_cls: 0.227  loss_box_reg: 0.393  loss_rpn_cls: 0.051  loss_rpn_loc: 0.045  time: 0.2518  data_time: 0.0135  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:19 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 1599  total_loss: 0.743  loss_cls: 0.257  loss_box_reg: 0.374  loss_rpn_cls: 0.083  loss_rpn_loc: 0.040  time: 0.2518  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:24 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 1619  total_loss: 0.645  loss_cls: 0.226  loss_box_reg: 0.325  loss_rpn_cls: 0.048  loss_rpn_loc: 0.029  time: 0.2517  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:29 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 1639  total_loss: 0.702  loss_cls: 0.209  loss_box_reg: 0.379  loss_rpn_cls: 0.053  loss_rpn_loc: 0.025  time: 0.2517  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:34 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 1659  total_loss: 0.631  loss_cls: 0.179  loss_box_reg: 0.372  loss_rpn_cls: 0.054  loss_rpn_loc: 0.045  time: 0.2517  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:39 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 1679  total_loss: 0.734  loss_cls: 0.286  loss_box_reg: 0.360  loss_rpn_cls: 0.044  loss_rpn_loc: 0.046  time: 0.2518  data_time: 0.0105  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:44 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 1699  total_loss: 0.906  loss_cls: 0.309  loss_box_reg: 0.412  loss_rpn_cls: 0.087  loss_rpn_loc: 0.061  time: 0.2518  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:49 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 1719  total_loss: 0.728  loss_cls: 0.195  loss_box_reg: 0.363  loss_rpn_cls: 0.065  loss_rpn_loc: 0.037  time: 0.2517  data_time: 0.0078  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:37:54 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 1739  total_loss: 0.753  loss_cls: 0.229  loss_box_reg: 0.333  loss_rpn_cls: 0.064  loss_rpn_loc: 0.042  time: 0.2520  data_time: 0.0377  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:00 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 1759  total_loss: 0.826  loss_cls: 0.215  loss_box_reg: 0.413  loss_rpn_cls: 0.063  loss_rpn_loc: 0.045  time: 0.2521  data_time: 0.0211  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:05 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 1779  total_loss: 0.676  loss_cls: 0.206  loss_box_reg: 0.381  loss_rpn_cls: 0.049  loss_rpn_loc: 0.049  time: 0.2520  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:10 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1799  total_loss: 0.689  loss_cls: 0.209  loss_box_reg: 0.382  loss_rpn_cls: 0.052  loss_rpn_loc: 0.039  time: 0.2520  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:15 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1819  total_loss: 0.855  loss_cls: 0.271  loss_box_reg: 0.422  loss_rpn_cls: 0.059  loss_rpn_loc: 0.049  time: 0.2519  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:19 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 1839  total_loss: 0.795  loss_cls: 0.314  loss_box_reg: 0.383  loss_rpn_cls: 0.080  loss_rpn_loc: 0.069  time: 0.2518  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:24 d2.utils.events]: \u001b[0m eta: 0:08:55  iter: 1859  total_loss: 0.671  loss_cls: 0.200  loss_box_reg: 0.353  loss_rpn_cls: 0.071  loss_rpn_loc: 0.034  time: 0.2518  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:30 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 1879  total_loss: 0.771  loss_cls: 0.221  loss_box_reg: 0.431  loss_rpn_cls: 0.092  loss_rpn_loc: 0.044  time: 0.2518  data_time: 0.0177  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:34 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1899  total_loss: 0.749  loss_cls: 0.211  loss_box_reg: 0.362  loss_rpn_cls: 0.064  loss_rpn_loc: 0.036  time: 0.2518  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:40 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 1919  total_loss: 0.772  loss_cls: 0.236  loss_box_reg: 0.399  loss_rpn_cls: 0.056  loss_rpn_loc: 0.052  time: 0.2518  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:45 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 1939  total_loss: 0.685  loss_cls: 0.234  loss_box_reg: 0.369  loss_rpn_cls: 0.071  loss_rpn_loc: 0.047  time: 0.2518  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:50 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 1959  total_loss: 0.866  loss_cls: 0.254  loss_box_reg: 0.385  loss_rpn_cls: 0.074  loss_rpn_loc: 0.037  time: 0.2518  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:38:55 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 1979  total_loss: 0.807  loss_cls: 0.196  loss_box_reg: 0.409  loss_rpn_cls: 0.055  loss_rpn_loc: 0.030  time: 0.2518  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:00 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 1999  total_loss: 0.648  loss_cls: 0.209  loss_box_reg: 0.365  loss_rpn_cls: 0.055  loss_rpn_loc: 0.021  time: 0.2517  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:04 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 2019  total_loss: 0.749  loss_cls: 0.229  loss_box_reg: 0.358  loss_rpn_cls: 0.078  loss_rpn_loc: 0.065  time: 0.2516  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:10 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 2039  total_loss: 0.724  loss_cls: 0.171  loss_box_reg: 0.381  loss_rpn_cls: 0.070  loss_rpn_loc: 0.036  time: 0.2517  data_time: 0.0159  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:15 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 2059  total_loss: 0.714  loss_cls: 0.168  loss_box_reg: 0.360  loss_rpn_cls: 0.058  loss_rpn_loc: 0.052  time: 0.2517  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:20 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 2079  total_loss: 0.563  loss_cls: 0.124  loss_box_reg: 0.338  loss_rpn_cls: 0.045  loss_rpn_loc: 0.025  time: 0.2517  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:25 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 2099  total_loss: 0.587  loss_cls: 0.156  loss_box_reg: 0.318  loss_rpn_cls: 0.048  loss_rpn_loc: 0.047  time: 0.2517  data_time: 0.0154  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:30 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 2119  total_loss: 0.717  loss_cls: 0.215  loss_box_reg: 0.381  loss_rpn_cls: 0.056  loss_rpn_loc: 0.047  time: 0.2516  data_time: 0.0055  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:35 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 2139  total_loss: 0.707  loss_cls: 0.216  loss_box_reg: 0.385  loss_rpn_cls: 0.044  loss_rpn_loc: 0.041  time: 0.2516  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:40 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 2159  total_loss: 0.752  loss_cls: 0.190  loss_box_reg: 0.386  loss_rpn_cls: 0.055  loss_rpn_loc: 0.044  time: 0.2516  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:45 d2.utils.events]: \u001b[0m eta: 0:07:34  iter: 2179  total_loss: 0.609  loss_cls: 0.150  loss_box_reg: 0.332  loss_rpn_cls: 0.064  loss_rpn_loc: 0.046  time: 0.2516  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:50 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 2199  total_loss: 0.672  loss_cls: 0.213  loss_box_reg: 0.362  loss_rpn_cls: 0.055  loss_rpn_loc: 0.022  time: 0.2516  data_time: 0.0169  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:39:55 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 2219  total_loss: 0.685  loss_cls: 0.152  loss_box_reg: 0.345  loss_rpn_cls: 0.042  loss_rpn_loc: 0.059  time: 0.2516  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:00 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 2239  total_loss: 0.734  loss_cls: 0.177  loss_box_reg: 0.420  loss_rpn_cls: 0.054  loss_rpn_loc: 0.029  time: 0.2517  data_time: 0.0197  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:05 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 2259  total_loss: 0.674  loss_cls: 0.196  loss_box_reg: 0.335  loss_rpn_cls: 0.056  loss_rpn_loc: 0.049  time: 0.2517  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:10 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 2279  total_loss: 0.649  loss_cls: 0.178  loss_box_reg: 0.325  loss_rpn_cls: 0.057  loss_rpn_loc: 0.031  time: 0.2517  data_time: 0.0078  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:15 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 2299  total_loss: 0.654  loss_cls: 0.172  loss_box_reg: 0.351  loss_rpn_cls: 0.052  loss_rpn_loc: 0.037  time: 0.2517  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:20 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 2319  total_loss: 0.688  loss_cls: 0.222  loss_box_reg: 0.358  loss_rpn_cls: 0.066  loss_rpn_loc: 0.042  time: 0.2517  data_time: 0.0096  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:25 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 2339  total_loss: 0.680  loss_cls: 0.172  loss_box_reg: 0.359  loss_rpn_cls: 0.053  loss_rpn_loc: 0.049  time: 0.2517  data_time: 0.0123  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:30 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 2359  total_loss: 0.675  loss_cls: 0.225  loss_box_reg: 0.353  loss_rpn_cls: 0.046  loss_rpn_loc: 0.022  time: 0.2517  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:36 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 2379  total_loss: 0.761  loss_cls: 0.249  loss_box_reg: 0.380  loss_rpn_cls: 0.073  loss_rpn_loc: 0.048  time: 0.2518  data_time: 0.0219  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:41 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 2399  total_loss: 0.786  loss_cls: 0.261  loss_box_reg: 0.370  loss_rpn_cls: 0.060  loss_rpn_loc: 0.052  time: 0.2518  data_time: 0.0226  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:46 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 2419  total_loss: 0.727  loss_cls: 0.209  loss_box_reg: 0.401  loss_rpn_cls: 0.058  loss_rpn_loc: 0.031  time: 0.2518  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:51 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 2439  total_loss: 0.755  loss_cls: 0.187  loss_box_reg: 0.386  loss_rpn_cls: 0.088  loss_rpn_loc: 0.054  time: 0.2518  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:40:56 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 2459  total_loss: 0.679  loss_cls: 0.178  loss_box_reg: 0.367  loss_rpn_cls: 0.045  loss_rpn_loc: 0.032  time: 0.2519  data_time: 0.0180  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:01 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 2479  total_loss: 0.636  loss_cls: 0.181  loss_box_reg: 0.356  loss_rpn_cls: 0.047  loss_rpn_loc: 0.028  time: 0.2518  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:06 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 2499  total_loss: 0.762  loss_cls: 0.216  loss_box_reg: 0.354  loss_rpn_cls: 0.076  loss_rpn_loc: 0.032  time: 0.2517  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:11 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 2519  total_loss: 0.713  loss_cls: 0.155  loss_box_reg: 0.369  loss_rpn_cls: 0.060  loss_rpn_loc: 0.041  time: 0.2517  data_time: 0.0073  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:16 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2539  total_loss: 0.578  loss_cls: 0.178  loss_box_reg: 0.321  loss_rpn_cls: 0.041  loss_rpn_loc: 0.037  time: 0.2516  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:21 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 2559  total_loss: 0.443  loss_cls: 0.106  loss_box_reg: 0.323  loss_rpn_cls: 0.035  loss_rpn_loc: 0.029  time: 0.2516  data_time: 0.0055  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:26 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 2579  total_loss: 0.656  loss_cls: 0.166  loss_box_reg: 0.332  loss_rpn_cls: 0.064  loss_rpn_loc: 0.053  time: 0.2516  data_time: 0.0085  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:31 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 2599  total_loss: 0.632  loss_cls: 0.190  loss_box_reg: 0.317  loss_rpn_cls: 0.032  loss_rpn_loc: 0.057  time: 0.2515  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:36 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 2619  total_loss: 0.699  loss_cls: 0.151  loss_box_reg: 0.311  loss_rpn_cls: 0.057  loss_rpn_loc: 0.043  time: 0.2515  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:41 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 2639  total_loss: 0.643  loss_cls: 0.175  loss_box_reg: 0.375  loss_rpn_cls: 0.055  loss_rpn_loc: 0.040  time: 0.2515  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:46 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 2659  total_loss: 0.703  loss_cls: 0.242  loss_box_reg: 0.375  loss_rpn_cls: 0.049  loss_rpn_loc: 0.026  time: 0.2515  data_time: 0.0114  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:51 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 2679  total_loss: 0.631  loss_cls: 0.166  loss_box_reg: 0.300  loss_rpn_cls: 0.065  loss_rpn_loc: 0.051  time: 0.2515  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:41:56 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 2699  total_loss: 0.612  loss_cls: 0.159  loss_box_reg: 0.334  loss_rpn_cls: 0.041  loss_rpn_loc: 0.032  time: 0.2514  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:00 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 2719  total_loss: 0.713  loss_cls: 0.226  loss_box_reg: 0.344  loss_rpn_cls: 0.052  loss_rpn_loc: 0.044  time: 0.2514  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:05 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2739  total_loss: 0.634  loss_cls: 0.203  loss_box_reg: 0.342  loss_rpn_cls: 0.042  loss_rpn_loc: 0.037  time: 0.2513  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:11 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 2759  total_loss: 0.701  loss_cls: 0.197  loss_box_reg: 0.356  loss_rpn_cls: 0.065  loss_rpn_loc: 0.048  time: 0.2514  data_time: 0.0187  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:16 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 2779  total_loss: 0.713  loss_cls: 0.162  loss_box_reg: 0.349  loss_rpn_cls: 0.039  loss_rpn_loc: 0.049  time: 0.2514  data_time: 0.0074  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:21 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 2799  total_loss: 0.615  loss_cls: 0.117  loss_box_reg: 0.333  loss_rpn_cls: 0.050  loss_rpn_loc: 0.048  time: 0.2514  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:26 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 2819  total_loss: 0.538  loss_cls: 0.125  loss_box_reg: 0.330  loss_rpn_cls: 0.036  loss_rpn_loc: 0.022  time: 0.2514  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:31 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 2839  total_loss: 0.606  loss_cls: 0.165  loss_box_reg: 0.298  loss_rpn_cls: 0.037  loss_rpn_loc: 0.033  time: 0.2514  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:36 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 2859  total_loss: 0.673  loss_cls: 0.119  loss_box_reg: 0.354  loss_rpn_cls: 0.055  loss_rpn_loc: 0.025  time: 0.2515  data_time: 0.0160  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:41 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 2879  total_loss: 0.529  loss_cls: 0.173  loss_box_reg: 0.297  loss_rpn_cls: 0.055  loss_rpn_loc: 0.029  time: 0.2515  data_time: 0.0122  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:46 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 2899  total_loss: 0.594  loss_cls: 0.141  loss_box_reg: 0.328  loss_rpn_cls: 0.055  loss_rpn_loc: 0.044  time: 0.2515  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:51 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2919  total_loss: 0.622  loss_cls: 0.149  loss_box_reg: 0.313  loss_rpn_cls: 0.057  loss_rpn_loc: 0.039  time: 0.2515  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:42:56 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 2939  total_loss: 0.438  loss_cls: 0.111  loss_box_reg: 0.282  loss_rpn_cls: 0.040  loss_rpn_loc: 0.025  time: 0.2515  data_time: 0.0177  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:02 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 2959  total_loss: 0.724  loss_cls: 0.209  loss_box_reg: 0.410  loss_rpn_cls: 0.057  loss_rpn_loc: 0.043  time: 0.2516  data_time: 0.0343  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:07 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 2979  total_loss: 0.612  loss_cls: 0.203  loss_box_reg: 0.294  loss_rpn_cls: 0.057  loss_rpn_loc: 0.035  time: 0.2516  data_time: 0.0054  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:12 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 2999  total_loss: 0.650  loss_cls: 0.140  loss_box_reg: 0.395  loss_rpn_cls: 0.041  loss_rpn_loc: 0.042  time: 0.2516  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:17 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 3019  total_loss: 0.663  loss_cls: 0.151  loss_box_reg: 0.367  loss_rpn_cls: 0.049  loss_rpn_loc: 0.040  time: 0.2516  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:22 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 3039  total_loss: 0.627  loss_cls: 0.219  loss_box_reg: 0.359  loss_rpn_cls: 0.055  loss_rpn_loc: 0.032  time: 0.2516  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:27 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 3059  total_loss: 0.620  loss_cls: 0.138  loss_box_reg: 0.329  loss_rpn_cls: 0.062  loss_rpn_loc: 0.032  time: 0.2516  data_time: 0.0113  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:32 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 3079  total_loss: 0.616  loss_cls: 0.152  loss_box_reg: 0.373  loss_rpn_cls: 0.050  loss_rpn_loc: 0.036  time: 0.2516  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:37 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 3099  total_loss: 0.558  loss_cls: 0.151  loss_box_reg: 0.285  loss_rpn_cls: 0.061  loss_rpn_loc: 0.029  time: 0.2516  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:42 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3119  total_loss: 0.595  loss_cls: 0.125  loss_box_reg: 0.303  loss_rpn_cls: 0.052  loss_rpn_loc: 0.041  time: 0.2515  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:47 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 3139  total_loss: 0.579  loss_cls: 0.174  loss_box_reg: 0.345  loss_rpn_cls: 0.046  loss_rpn_loc: 0.028  time: 0.2515  data_time: 0.0105  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:52 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 3159  total_loss: 0.629  loss_cls: 0.220  loss_box_reg: 0.339  loss_rpn_cls: 0.056  loss_rpn_loc: 0.038  time: 0.2516  data_time: 0.0227  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:43:57 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 3179  total_loss: 0.655  loss_cls: 0.189  loss_box_reg: 0.338  loss_rpn_cls: 0.044  loss_rpn_loc: 0.057  time: 0.2516  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:02 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 3199  total_loss: 0.595  loss_cls: 0.155  loss_box_reg: 0.293  loss_rpn_cls: 0.057  loss_rpn_loc: 0.037  time: 0.2516  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:07 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 3219  total_loss: 0.646  loss_cls: 0.183  loss_box_reg: 0.334  loss_rpn_cls: 0.073  loss_rpn_loc: 0.044  time: 0.2515  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:12 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 3239  total_loss: 0.549  loss_cls: 0.123  loss_box_reg: 0.329  loss_rpn_cls: 0.030  loss_rpn_loc: 0.024  time: 0.2515  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:17 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 3259  total_loss: 0.616  loss_cls: 0.172  loss_box_reg: 0.333  loss_rpn_cls: 0.028  loss_rpn_loc: 0.040  time: 0.2515  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:22 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 3279  total_loss: 0.603  loss_cls: 0.176  loss_box_reg: 0.295  loss_rpn_cls: 0.064  loss_rpn_loc: 0.051  time: 0.2515  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:27 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 3299  total_loss: 0.615  loss_cls: 0.149  loss_box_reg: 0.355  loss_rpn_cls: 0.068  loss_rpn_loc: 0.046  time: 0.2515  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:32 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 3319  total_loss: 0.575  loss_cls: 0.150  loss_box_reg: 0.333  loss_rpn_cls: 0.033  loss_rpn_loc: 0.023  time: 0.2515  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:37 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 3339  total_loss: 0.620  loss_cls: 0.155  loss_box_reg: 0.351  loss_rpn_cls: 0.061  loss_rpn_loc: 0.042  time: 0.2515  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:42 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 3359  total_loss: 0.563  loss_cls: 0.173  loss_box_reg: 0.318  loss_rpn_cls: 0.036  loss_rpn_loc: 0.025  time: 0.2514  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:47 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 3379  total_loss: 0.572  loss_cls: 0.146  loss_box_reg: 0.323  loss_rpn_cls: 0.048  loss_rpn_loc: 0.041  time: 0.2514  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:52 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3399  total_loss: 0.549  loss_cls: 0.119  loss_box_reg: 0.303  loss_rpn_cls: 0.050  loss_rpn_loc: 0.026  time: 0.2515  data_time: 0.0237  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:44:58 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 3419  total_loss: 0.668  loss_cls: 0.256  loss_box_reg: 0.323  loss_rpn_cls: 0.045  loss_rpn_loc: 0.031  time: 0.2515  data_time: 0.0155  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:02 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 3439  total_loss: 0.537  loss_cls: 0.123  loss_box_reg: 0.341  loss_rpn_cls: 0.046  loss_rpn_loc: 0.031  time: 0.2515  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:08 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 3459  total_loss: 0.596  loss_cls: 0.117  loss_box_reg: 0.289  loss_rpn_cls: 0.044  loss_rpn_loc: 0.033  time: 0.2515  data_time: 0.0112  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:13 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3479  total_loss: 0.525  loss_cls: 0.123  loss_box_reg: 0.312  loss_rpn_cls: 0.027  loss_rpn_loc: 0.036  time: 0.2515  data_time: 0.0053  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:18 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 3499  total_loss: 0.570  loss_cls: 0.151  loss_box_reg: 0.321  loss_rpn_cls: 0.034  loss_rpn_loc: 0.033  time: 0.2515  data_time: 0.0093  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:23 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 3519  total_loss: 0.494  loss_cls: 0.139  loss_box_reg: 0.289  loss_rpn_cls: 0.039  loss_rpn_loc: 0.034  time: 0.2515  data_time: 0.0112  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:28 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 3539  total_loss: 0.591  loss_cls: 0.123  loss_box_reg: 0.342  loss_rpn_cls: 0.056  loss_rpn_loc: 0.035  time: 0.2516  data_time: 0.0132  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:33 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3559  total_loss: 0.688  loss_cls: 0.146  loss_box_reg: 0.317  loss_rpn_cls: 0.052  loss_rpn_loc: 0.063  time: 0.2516  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:38 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 3579  total_loss: 0.592  loss_cls: 0.134  loss_box_reg: 0.335  loss_rpn_cls: 0.048  loss_rpn_loc: 0.052  time: 0.2516  data_time: 0.0116  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:43 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 3599  total_loss: 0.484  loss_cls: 0.127  loss_box_reg: 0.291  loss_rpn_cls: 0.039  loss_rpn_loc: 0.029  time: 0.2516  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:48 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 3619  total_loss: 0.486  loss_cls: 0.147  loss_box_reg: 0.300  loss_rpn_cls: 0.035  loss_rpn_loc: 0.029  time: 0.2515  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:53 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3639  total_loss: 0.518  loss_cls: 0.117  loss_box_reg: 0.333  loss_rpn_cls: 0.029  loss_rpn_loc: 0.033  time: 0.2515  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:45:58 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 3659  total_loss: 0.476  loss_cls: 0.123  loss_box_reg: 0.305  loss_rpn_cls: 0.029  loss_rpn_loc: 0.025  time: 0.2515  data_time: 0.0089  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:03 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3679  total_loss: 0.577  loss_cls: 0.134  loss_box_reg: 0.297  loss_rpn_cls: 0.046  loss_rpn_loc: 0.044  time: 0.2515  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:08 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 3699  total_loss: 0.649  loss_cls: 0.168  loss_box_reg: 0.317  loss_rpn_cls: 0.053  loss_rpn_loc: 0.024  time: 0.2515  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:13 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 3719  total_loss: 0.600  loss_cls: 0.135  loss_box_reg: 0.342  loss_rpn_cls: 0.028  loss_rpn_loc: 0.036  time: 0.2515  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:18 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3739  total_loss: 0.481  loss_cls: 0.100  loss_box_reg: 0.293  loss_rpn_cls: 0.034  loss_rpn_loc: 0.038  time: 0.2515  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:23 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 3759  total_loss: 0.517  loss_cls: 0.124  loss_box_reg: 0.279  loss_rpn_cls: 0.036  loss_rpn_loc: 0.060  time: 0.2515  data_time: 0.0127  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:28 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 3779  total_loss: 0.578  loss_cls: 0.175  loss_box_reg: 0.282  loss_rpn_cls: 0.056  loss_rpn_loc: 0.046  time: 0.2515  data_time: 0.0055  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:33 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 3799  total_loss: 0.487  loss_cls: 0.085  loss_box_reg: 0.324  loss_rpn_cls: 0.030  loss_rpn_loc: 0.038  time: 0.2515  data_time: 0.0239  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:38 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3819  total_loss: 0.549  loss_cls: 0.154  loss_box_reg: 0.327  loss_rpn_cls: 0.053  loss_rpn_loc: 0.032  time: 0.2515  data_time: 0.0055  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:44 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 3839  total_loss: 0.504  loss_cls: 0.079  loss_box_reg: 0.283  loss_rpn_cls: 0.032  loss_rpn_loc: 0.036  time: 0.2516  data_time: 0.0195  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:49 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 3859  total_loss: 0.546  loss_cls: 0.119  loss_box_reg: 0.316  loss_rpn_cls: 0.039  loss_rpn_loc: 0.032  time: 0.2515  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:54 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 3879  total_loss: 0.589  loss_cls: 0.137  loss_box_reg: 0.312  loss_rpn_cls: 0.036  loss_rpn_loc: 0.048  time: 0.2515  data_time: 0.0145  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:46:59 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 3899  total_loss: 0.635  loss_cls: 0.169  loss_box_reg: 0.349  loss_rpn_cls: 0.046  loss_rpn_loc: 0.033  time: 0.2516  data_time: 0.0282  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:04 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3919  total_loss: 0.610  loss_cls: 0.156  loss_box_reg: 0.309  loss_rpn_cls: 0.044  loss_rpn_loc: 0.039  time: 0.2516  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:09 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 3939  total_loss: 0.618  loss_cls: 0.148  loss_box_reg: 0.327  loss_rpn_cls: 0.036  loss_rpn_loc: 0.028  time: 0.2516  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:14 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 3959  total_loss: 0.576  loss_cls: 0.168  loss_box_reg: 0.320  loss_rpn_cls: 0.036  loss_rpn_loc: 0.039  time: 0.2516  data_time: 0.0086  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:19 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 3979  total_loss: 0.658  loss_cls: 0.155  loss_box_reg: 0.381  loss_rpn_cls: 0.051  loss_rpn_loc: 0.035  time: 0.2515  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.473  loss_cls: 0.121  loss_box_reg: 0.280  loss_rpn_cls: 0.033  loss_rpn_loc: 0.024  time: 0.2515  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.473  loss_cls: 0.112  loss_box_reg: 0.280  loss_rpn_cls: 0.033  loss_rpn_loc: 0.028  time: 0.2515  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:47:25 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:16:45 (0.2516 s / it)\n",
            "\u001b[32m[05/04 00:47:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:49 (0:00:04 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 00:47:26 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 00:47:26 d2.data.datasets.coco]: \u001b[0mLoaded 343 images in COCO format from greenthumbs/data/v01/test_75%_coco.json\n",
            "\u001b[32m[05/04 00:47:26 d2.data.common]: \u001b[0mSerializing 343 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 00:47:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
            "\u001b[32m[05/04 00:47:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 343 images\n",
            "\u001b[32m[05/04 00:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/343. 0.1392 s / img. ETA=0:00:46\n",
            "\u001b[32m[05/04 00:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 37/343. 0.1711 s / img. ETA=0:00:56\n",
            "\u001b[32m[05/04 00:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 68/343. 0.1600 s / img. ETA=0:00:48\n",
            "\u001b[32m[05/04 00:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 100/343. 0.1591 s / img. ETA=0:00:41\n",
            "\u001b[32m[05/04 00:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 132/343. 0.1565 s / img. ETA=0:00:35\n",
            "\u001b[32m[05/04 00:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 163/343. 0.1571 s / img. ETA=0:00:29\n",
            "\u001b[32m[05/04 00:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 196/343. 0.1558 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 00:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 230/343. 0.1545 s / img. ETA=0:00:18\n",
            "\u001b[32m[05/04 00:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 262/343. 0.1546 s / img. ETA=0:00:13\n",
            "\u001b[32m[05/04 00:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 296/343. 0.1539 s / img. ETA=0:00:07\n",
            "\u001b[32m[05/04 00:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 329/343. 0.1536 s / img. ETA=0:00:02\n",
            "\u001b[32m[05/04 00:48:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.778197 (0.159107 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 00:48:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:51 (0.153765 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 00:48:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 00:48:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64/coco_instances_results.json\n",
            "\u001b[32m[05/04 00:48:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.29s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.590\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.543\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "\u001b[32m[05/04 00:48:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 36.710 | 58.964 | 41.690 | 16.632 | 28.922 | 47.157 |\n",
            "\u001b[32m[05/04 00:48:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 55.128 | tomato_fruit       | 36.716 | tomato_seedling          | 22.217 |\n",
            "| tomato_young_plant      | 35.288 | tomato_flower      | 37.065 | bell_pepper_fruit        | 54.712 |\n",
            "| bell_pepper_young_plant | 35.401 | bell_pepper_flower | 44.247 | bell_pepper_fruit_unripe | 23.786 |\n",
            "| bell_pepper_seedling    | 12.698 | cucumber_flower    | 58.872 | cucumber_plant           | 1.109  |\n",
            "| cucumber_seedling       | 29.623 | cucumber_fruit     | 68.655 | cucumber_fruit_unripe    | 35.137 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64___2.png\n",
            "\u001b[32m[05/04 00:48:24 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 00:48:24 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 00:48:24 d2.data.datasets.coco]: \u001b[0mLoaded 1029 images in COCO format from greenthumbs/data/v01/train_75%_coco.json\n",
            "\u001b[32m[05/04 00:48:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1029 images left.\n",
            "\u001b[32m[05/04 00:48:24 d2.data.common]: \u001b[0mSerializing 1029 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 00:48:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.31 MiB\n",
            "\u001b[32m[05/04 00:48:24 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 00:48:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128\n",
            "**********************************************\n",
            "\u001b[32m[05/04 00:48:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 00:48:31 d2.utils.events]: \u001b[0m eta: 0:21:40  iter: 19  total_loss: 3.560  loss_cls: 2.654  loss_box_reg: 0.638  loss_rpn_cls: 0.201  loss_rpn_loc: 0.033  time: 0.3277  data_time: 0.0152  lr: 0.000010  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:48:37 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 39  total_loss: 3.491  loss_cls: 2.322  loss_box_reg: 0.726  loss_rpn_cls: 0.251  loss_rpn_loc: 0.040  time: 0.3305  data_time: 0.0207  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:48:44 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 59  total_loss: 2.721  loss_cls: 1.657  loss_box_reg: 0.791  loss_rpn_cls: 0.193  loss_rpn_loc: 0.041  time: 0.3313  data_time: 0.0072  lr: 0.000030  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:48:50 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 79  total_loss: 2.115  loss_cls: 1.077  loss_box_reg: 0.722  loss_rpn_cls: 0.164  loss_rpn_loc: 0.054  time: 0.3304  data_time: 0.0060  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:48:57 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 99  total_loss: 1.889  loss_cls: 0.943  loss_box_reg: 0.678  loss_rpn_cls: 0.161  loss_rpn_loc: 0.047  time: 0.3289  data_time: 0.0065  lr: 0.000050  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:03 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 119  total_loss: 2.158  loss_cls: 1.015  loss_box_reg: 0.904  loss_rpn_cls: 0.156  loss_rpn_loc: 0.061  time: 0.3268  data_time: 0.0062  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:10 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 139  total_loss: 1.953  loss_cls: 0.856  loss_box_reg: 0.789  loss_rpn_cls: 0.217  loss_rpn_loc: 0.069  time: 0.3269  data_time: 0.0155  lr: 0.000070  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:16 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 159  total_loss: 1.830  loss_cls: 0.782  loss_box_reg: 0.739  loss_rpn_cls: 0.178  loss_rpn_loc: 0.080  time: 0.3267  data_time: 0.0075  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:23 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 179  total_loss: 2.085  loss_cls: 0.834  loss_box_reg: 0.861  loss_rpn_cls: 0.185  loss_rpn_loc: 0.099  time: 0.3268  data_time: 0.0068  lr: 0.000090  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:30 d2.utils.events]: \u001b[0m eta: 0:20:38  iter: 199  total_loss: 1.919  loss_cls: 0.805  loss_box_reg: 0.860  loss_rpn_cls: 0.148  loss_rpn_loc: 0.046  time: 0.3288  data_time: 0.0244  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:36 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 219  total_loss: 1.711  loss_cls: 0.764  loss_box_reg: 0.703  loss_rpn_cls: 0.152  loss_rpn_loc: 0.061  time: 0.3279  data_time: 0.0061  lr: 0.000110  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:43 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 239  total_loss: 1.800  loss_cls: 0.815  loss_box_reg: 0.777  loss_rpn_cls: 0.174  loss_rpn_loc: 0.039  time: 0.3274  data_time: 0.0062  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:49 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 259  total_loss: 1.648  loss_cls: 0.658  loss_box_reg: 0.752  loss_rpn_cls: 0.140  loss_rpn_loc: 0.043  time: 0.3271  data_time: 0.0063  lr: 0.000130  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:49:56 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 279  total_loss: 1.797  loss_cls: 0.769  loss_box_reg: 0.798  loss_rpn_cls: 0.131  loss_rpn_loc: 0.052  time: 0.3265  data_time: 0.0063  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:02 d2.utils.events]: \u001b[0m eta: 0:20:03  iter: 299  total_loss: 1.670  loss_cls: 0.669  loss_box_reg: 0.851  loss_rpn_cls: 0.116  loss_rpn_loc: 0.037  time: 0.3266  data_time: 0.0065  lr: 0.000150  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:09 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 319  total_loss: 1.650  loss_cls: 0.652  loss_box_reg: 0.779  loss_rpn_cls: 0.101  loss_rpn_loc: 0.021  time: 0.3265  data_time: 0.0061  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:15 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 339  total_loss: 1.499  loss_cls: 0.575  loss_box_reg: 0.728  loss_rpn_cls: 0.125  loss_rpn_loc: 0.031  time: 0.3263  data_time: 0.0077  lr: 0.000170  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:22 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 359  total_loss: 1.718  loss_cls: 0.622  loss_box_reg: 0.858  loss_rpn_cls: 0.130  loss_rpn_loc: 0.035  time: 0.3259  data_time: 0.0060  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:28 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 379  total_loss: 1.352  loss_cls: 0.503  loss_box_reg: 0.730  loss_rpn_cls: 0.114  loss_rpn_loc: 0.042  time: 0.3256  data_time: 0.0060  lr: 0.000190  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:35 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 399  total_loss: 1.535  loss_cls: 0.618  loss_box_reg: 0.752  loss_rpn_cls: 0.127  loss_rpn_loc: 0.041  time: 0.3257  data_time: 0.0061  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:41 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 419  total_loss: 1.344  loss_cls: 0.459  loss_box_reg: 0.715  loss_rpn_cls: 0.126  loss_rpn_loc: 0.026  time: 0.3253  data_time: 0.0086  lr: 0.000210  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:48 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 439  total_loss: 1.394  loss_cls: 0.464  loss_box_reg: 0.718  loss_rpn_cls: 0.116  loss_rpn_loc: 0.077  time: 0.3254  data_time: 0.0058  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:50:54 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 459  total_loss: 1.532  loss_cls: 0.539  loss_box_reg: 0.677  loss_rpn_cls: 0.144  loss_rpn_loc: 0.053  time: 0.3252  data_time: 0.0064  lr: 0.000230  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:00 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 479  total_loss: 1.309  loss_cls: 0.469  loss_box_reg: 0.640  loss_rpn_cls: 0.130  loss_rpn_loc: 0.051  time: 0.3251  data_time: 0.0059  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:07 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 499  total_loss: 1.136  loss_cls: 0.394  loss_box_reg: 0.625  loss_rpn_cls: 0.096  loss_rpn_loc: 0.064  time: 0.3250  data_time: 0.0062  lr: 0.000250  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:13 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 519  total_loss: 1.439  loss_cls: 0.527  loss_box_reg: 0.692  loss_rpn_cls: 0.106  loss_rpn_loc: 0.065  time: 0.3251  data_time: 0.0107  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:20 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 539  total_loss: 1.222  loss_cls: 0.397  loss_box_reg: 0.633  loss_rpn_cls: 0.092  loss_rpn_loc: 0.038  time: 0.3250  data_time: 0.0067  lr: 0.000270  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:26 d2.utils.events]: \u001b[0m eta: 0:18:36  iter: 559  total_loss: 1.201  loss_cls: 0.413  loss_box_reg: 0.630  loss_rpn_cls: 0.114  loss_rpn_loc: 0.052  time: 0.3250  data_time: 0.0063  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:33 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 579  total_loss: 1.329  loss_cls: 0.448  loss_box_reg: 0.630  loss_rpn_cls: 0.134  loss_rpn_loc: 0.064  time: 0.3250  data_time: 0.0057  lr: 0.000290  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:40 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 599  total_loss: 1.060  loss_cls: 0.372  loss_box_reg: 0.503  loss_rpn_cls: 0.097  loss_rpn_loc: 0.037  time: 0.3251  data_time: 0.0064  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:46 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 619  total_loss: 1.180  loss_cls: 0.412  loss_box_reg: 0.577  loss_rpn_cls: 0.085  loss_rpn_loc: 0.046  time: 0.3251  data_time: 0.0060  lr: 0.000310  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:53 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 639  total_loss: 1.134  loss_cls: 0.445  loss_box_reg: 0.525  loss_rpn_cls: 0.102  loss_rpn_loc: 0.044  time: 0.3252  data_time: 0.0063  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:51:59 d2.utils.events]: \u001b[0m eta: 0:18:04  iter: 659  total_loss: 1.065  loss_cls: 0.437  loss_box_reg: 0.540  loss_rpn_cls: 0.094  loss_rpn_loc: 0.031  time: 0.3252  data_time: 0.0060  lr: 0.000330  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:06 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 679  total_loss: 1.043  loss_cls: 0.345  loss_box_reg: 0.508  loss_rpn_cls: 0.107  loss_rpn_loc: 0.060  time: 0.3255  data_time: 0.0058  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:12 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 699  total_loss: 1.110  loss_cls: 0.389  loss_box_reg: 0.494  loss_rpn_cls: 0.095  loss_rpn_loc: 0.032  time: 0.3256  data_time: 0.0068  lr: 0.000350  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:19 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 719  total_loss: 0.883  loss_cls: 0.323  loss_box_reg: 0.402  loss_rpn_cls: 0.087  loss_rpn_loc: 0.025  time: 0.3255  data_time: 0.0058  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:25 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 739  total_loss: 0.924  loss_cls: 0.331  loss_box_reg: 0.439  loss_rpn_cls: 0.101  loss_rpn_loc: 0.056  time: 0.3254  data_time: 0.0098  lr: 0.000370  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:32 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 759  total_loss: 0.937  loss_cls: 0.349  loss_box_reg: 0.458  loss_rpn_cls: 0.071  loss_rpn_loc: 0.039  time: 0.3253  data_time: 0.0062  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:39 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 779  total_loss: 1.003  loss_cls: 0.355  loss_box_reg: 0.497  loss_rpn_cls: 0.072  loss_rpn_loc: 0.036  time: 0.3255  data_time: 0.0166  lr: 0.000390  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:45 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 799  total_loss: 1.192  loss_cls: 0.381  loss_box_reg: 0.418  loss_rpn_cls: 0.119  loss_rpn_loc: 0.048  time: 0.3254  data_time: 0.0065  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:51 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 819  total_loss: 0.929  loss_cls: 0.398  loss_box_reg: 0.444  loss_rpn_cls: 0.071  loss_rpn_loc: 0.041  time: 0.3253  data_time: 0.0063  lr: 0.000410  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:52:58 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 839  total_loss: 0.881  loss_cls: 0.345  loss_box_reg: 0.387  loss_rpn_cls: 0.065  loss_rpn_loc: 0.025  time: 0.3254  data_time: 0.0062  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:05 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 859  total_loss: 0.946  loss_cls: 0.329  loss_box_reg: 0.461  loss_rpn_cls: 0.091  loss_rpn_loc: 0.053  time: 0.3254  data_time: 0.0061  lr: 0.000430  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:11 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 879  total_loss: 0.800  loss_cls: 0.247  loss_box_reg: 0.423  loss_rpn_cls: 0.098  loss_rpn_loc: 0.062  time: 0.3253  data_time: 0.0060  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:17 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 899  total_loss: 1.071  loss_cls: 0.340  loss_box_reg: 0.472  loss_rpn_cls: 0.069  loss_rpn_loc: 0.049  time: 0.3251  data_time: 0.0074  lr: 0.000450  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:24 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 919  total_loss: 1.030  loss_cls: 0.335  loss_box_reg: 0.411  loss_rpn_cls: 0.091  loss_rpn_loc: 0.052  time: 0.3251  data_time: 0.0167  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:30 d2.utils.events]: \u001b[0m eta: 0:16:33  iter: 939  total_loss: 0.909  loss_cls: 0.311  loss_box_reg: 0.459  loss_rpn_cls: 0.082  loss_rpn_loc: 0.033  time: 0.3250  data_time: 0.0064  lr: 0.000470  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:37 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 959  total_loss: 0.961  loss_cls: 0.302  loss_box_reg: 0.379  loss_rpn_cls: 0.101  loss_rpn_loc: 0.048  time: 0.3249  data_time: 0.0060  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:43 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 979  total_loss: 1.292  loss_cls: 0.597  loss_box_reg: 0.514  loss_rpn_cls: 0.095  loss_rpn_loc: 0.038  time: 0.3248  data_time: 0.0084  lr: 0.000490  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:50 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 999  total_loss: 1.004  loss_cls: 0.346  loss_box_reg: 0.491  loss_rpn_cls: 0.113  loss_rpn_loc: 0.060  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:53:56 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 1019  total_loss: 0.835  loss_cls: 0.269  loss_box_reg: 0.435  loss_rpn_cls: 0.087  loss_rpn_loc: 0.033  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:03 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 1039  total_loss: 0.706  loss_cls: 0.281  loss_box_reg: 0.366  loss_rpn_cls: 0.056  loss_rpn_loc: 0.043  time: 0.3249  data_time: 0.0114  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:09 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 1059  total_loss: 0.790  loss_cls: 0.293  loss_box_reg: 0.398  loss_rpn_cls: 0.094  loss_rpn_loc: 0.058  time: 0.3251  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:16 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 1079  total_loss: 0.759  loss_cls: 0.259  loss_box_reg: 0.404  loss_rpn_cls: 0.074  loss_rpn_loc: 0.049  time: 0.3250  data_time: 0.0085  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:22 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 1099  total_loss: 0.606  loss_cls: 0.208  loss_box_reg: 0.296  loss_rpn_cls: 0.067  loss_rpn_loc: 0.028  time: 0.3249  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:29 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 1119  total_loss: 0.657  loss_cls: 0.240  loss_box_reg: 0.320  loss_rpn_cls: 0.067  loss_rpn_loc: 0.031  time: 0.3250  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:35 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 1139  total_loss: 0.773  loss_cls: 0.293  loss_box_reg: 0.387  loss_rpn_cls: 0.071  loss_rpn_loc: 0.036  time: 0.3250  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:42 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 1159  total_loss: 0.774  loss_cls: 0.238  loss_box_reg: 0.418  loss_rpn_cls: 0.067  loss_rpn_loc: 0.040  time: 0.3250  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:49 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 1179  total_loss: 0.849  loss_cls: 0.294  loss_box_reg: 0.425  loss_rpn_cls: 0.085  loss_rpn_loc: 0.052  time: 0.3253  data_time: 0.0312  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:54:55 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 1199  total_loss: 0.907  loss_cls: 0.320  loss_box_reg: 0.460  loss_rpn_cls: 0.105  loss_rpn_loc: 0.041  time: 0.3251  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:02 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 1219  total_loss: 0.731  loss_cls: 0.202  loss_box_reg: 0.380  loss_rpn_cls: 0.078  loss_rpn_loc: 0.054  time: 0.3251  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:08 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 1239  total_loss: 0.927  loss_cls: 0.278  loss_box_reg: 0.432  loss_rpn_cls: 0.082  loss_rpn_loc: 0.033  time: 0.3249  data_time: 0.0052  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:14 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 1259  total_loss: 0.581  loss_cls: 0.168  loss_box_reg: 0.325  loss_rpn_cls: 0.042  loss_rpn_loc: 0.033  time: 0.3249  data_time: 0.0104  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:21 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 1279  total_loss: 0.796  loss_cls: 0.258  loss_box_reg: 0.379  loss_rpn_cls: 0.096  loss_rpn_loc: 0.064  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:27 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 1299  total_loss: 0.616  loss_cls: 0.228  loss_box_reg: 0.360  loss_rpn_cls: 0.059  loss_rpn_loc: 0.043  time: 0.3249  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:34 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 1319  total_loss: 0.963  loss_cls: 0.321  loss_box_reg: 0.367  loss_rpn_cls: 0.079  loss_rpn_loc: 0.040  time: 0.3249  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:40 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 1339  total_loss: 0.863  loss_cls: 0.345  loss_box_reg: 0.352  loss_rpn_cls: 0.080  loss_rpn_loc: 0.038  time: 0.3249  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:47 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 1359  total_loss: 0.882  loss_cls: 0.295  loss_box_reg: 0.392  loss_rpn_cls: 0.073  loss_rpn_loc: 0.046  time: 0.3248  data_time: 0.0074  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:55:53 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 1379  total_loss: 0.754  loss_cls: 0.244  loss_box_reg: 0.384  loss_rpn_cls: 0.076  loss_rpn_loc: 0.054  time: 0.3249  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:00 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 1399  total_loss: 0.787  loss_cls: 0.307  loss_box_reg: 0.367  loss_rpn_cls: 0.075  loss_rpn_loc: 0.032  time: 0.3247  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:06 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 1419  total_loss: 0.753  loss_cls: 0.256  loss_box_reg: 0.418  loss_rpn_cls: 0.056  loss_rpn_loc: 0.044  time: 0.3248  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:13 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 1439  total_loss: 0.719  loss_cls: 0.213  loss_box_reg: 0.392  loss_rpn_cls: 0.084  loss_rpn_loc: 0.034  time: 0.3248  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:20 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 1459  total_loss: 0.813  loss_cls: 0.240  loss_box_reg: 0.415  loss_rpn_cls: 0.084  loss_rpn_loc: 0.055  time: 0.3250  data_time: 0.0298  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:26 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 1479  total_loss: 0.934  loss_cls: 0.288  loss_box_reg: 0.423  loss_rpn_cls: 0.098  loss_rpn_loc: 0.049  time: 0.3251  data_time: 0.0101  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:33 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 1499  total_loss: 0.680  loss_cls: 0.214  loss_box_reg: 0.347  loss_rpn_cls: 0.068  loss_rpn_loc: 0.027  time: 0.3250  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:39 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 1519  total_loss: 0.683  loss_cls: 0.226  loss_box_reg: 0.332  loss_rpn_cls: 0.071  loss_rpn_loc: 0.038  time: 0.3250  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:46 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 1539  total_loss: 0.812  loss_cls: 0.263  loss_box_reg: 0.336  loss_rpn_cls: 0.076  loss_rpn_loc: 0.054  time: 0.3249  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:52 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 1559  total_loss: 0.604  loss_cls: 0.148  loss_box_reg: 0.322  loss_rpn_cls: 0.065  loss_rpn_loc: 0.030  time: 0.3249  data_time: 0.0054  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:56:59 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 1579  total_loss: 0.604  loss_cls: 0.197  loss_box_reg: 0.329  loss_rpn_cls: 0.046  loss_rpn_loc: 0.039  time: 0.3250  data_time: 0.0095  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:05 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 1599  total_loss: 0.616  loss_cls: 0.208  loss_box_reg: 0.304  loss_rpn_cls: 0.057  loss_rpn_loc: 0.036  time: 0.3252  data_time: 0.0211  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:12 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 1619  total_loss: 0.679  loss_cls: 0.155  loss_box_reg: 0.313  loss_rpn_cls: 0.079  loss_rpn_loc: 0.057  time: 0.3251  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:18 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 1639  total_loss: 0.686  loss_cls: 0.212  loss_box_reg: 0.360  loss_rpn_cls: 0.057  loss_rpn_loc: 0.015  time: 0.3251  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:25 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 1659  total_loss: 0.864  loss_cls: 0.333  loss_box_reg: 0.421  loss_rpn_cls: 0.076  loss_rpn_loc: 0.051  time: 0.3251  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:32 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 1679  total_loss: 0.629  loss_cls: 0.194  loss_box_reg: 0.306  loss_rpn_cls: 0.057  loss_rpn_loc: 0.042  time: 0.3252  data_time: 0.0166  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:38 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 1699  total_loss: 0.649  loss_cls: 0.172  loss_box_reg: 0.261  loss_rpn_cls: 0.087  loss_rpn_loc: 0.051  time: 0.3251  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:44 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 1719  total_loss: 0.761  loss_cls: 0.226  loss_box_reg: 0.336  loss_rpn_cls: 0.072  loss_rpn_loc: 0.058  time: 0.3250  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:51 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1739  total_loss: 0.627  loss_cls: 0.155  loss_box_reg: 0.362  loss_rpn_cls: 0.053  loss_rpn_loc: 0.033  time: 0.3250  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:57:57 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 1759  total_loss: 0.636  loss_cls: 0.164  loss_box_reg: 0.305  loss_rpn_cls: 0.085  loss_rpn_loc: 0.048  time: 0.3250  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:04 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1779  total_loss: 0.678  loss_cls: 0.231  loss_box_reg: 0.271  loss_rpn_cls: 0.064  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:10 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 1799  total_loss: 0.564  loss_cls: 0.128  loss_box_reg: 0.302  loss_rpn_cls: 0.053  loss_rpn_loc: 0.031  time: 0.3249  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:17 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 1819  total_loss: 0.605  loss_cls: 0.148  loss_box_reg: 0.308  loss_rpn_cls: 0.068  loss_rpn_loc: 0.022  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:23 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 1839  total_loss: 0.666  loss_cls: 0.195  loss_box_reg: 0.323  loss_rpn_cls: 0.065  loss_rpn_loc: 0.038  time: 0.3249  data_time: 0.0136  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:30 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 1859  total_loss: 0.643  loss_cls: 0.140  loss_box_reg: 0.345  loss_rpn_cls: 0.067  loss_rpn_loc: 0.041  time: 0.3249  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:36 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 1879  total_loss: 0.649  loss_cls: 0.190  loss_box_reg: 0.349  loss_rpn_cls: 0.055  loss_rpn_loc: 0.044  time: 0.3250  data_time: 0.0085  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:43 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 1899  total_loss: 0.572  loss_cls: 0.162  loss_box_reg: 0.314  loss_rpn_cls: 0.035  loss_rpn_loc: 0.032  time: 0.3250  data_time: 0.0077  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:49 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 1919  total_loss: 0.851  loss_cls: 0.277  loss_box_reg: 0.410  loss_rpn_cls: 0.082  loss_rpn_loc: 0.071  time: 0.3249  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:58:56 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 1939  total_loss: 0.658  loss_cls: 0.150  loss_box_reg: 0.311  loss_rpn_cls: 0.055  loss_rpn_loc: 0.031  time: 0.3249  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:02 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1959  total_loss: 0.638  loss_cls: 0.236  loss_box_reg: 0.342  loss_rpn_cls: 0.056  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:09 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 1979  total_loss: 0.722  loss_cls: 0.258  loss_box_reg: 0.334  loss_rpn_cls: 0.060  loss_rpn_loc: 0.049  time: 0.3248  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:15 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 1999  total_loss: 0.753  loss_cls: 0.224  loss_box_reg: 0.364  loss_rpn_cls: 0.059  loss_rpn_loc: 0.062  time: 0.3249  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:22 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 2019  total_loss: 0.655  loss_cls: 0.247  loss_box_reg: 0.311  loss_rpn_cls: 0.046  loss_rpn_loc: 0.038  time: 0.3249  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:28 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 2039  total_loss: 0.759  loss_cls: 0.227  loss_box_reg: 0.382  loss_rpn_cls: 0.064  loss_rpn_loc: 0.060  time: 0.3248  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:35 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 2059  total_loss: 0.713  loss_cls: 0.217  loss_box_reg: 0.355  loss_rpn_cls: 0.084  loss_rpn_loc: 0.049  time: 0.3248  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:41 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 2079  total_loss: 0.503  loss_cls: 0.161  loss_box_reg: 0.264  loss_rpn_cls: 0.050  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:48 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 2099  total_loss: 0.601  loss_cls: 0.170  loss_box_reg: 0.289  loss_rpn_cls: 0.053  loss_rpn_loc: 0.047  time: 0.3249  data_time: 0.0117  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 00:59:55 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 2119  total_loss: 0.538  loss_cls: 0.138  loss_box_reg: 0.323  loss_rpn_cls: 0.051  loss_rpn_loc: 0.022  time: 0.3249  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:01 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 2139  total_loss: 0.578  loss_cls: 0.166  loss_box_reg: 0.328  loss_rpn_cls: 0.052  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:07 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 2159  total_loss: 0.533  loss_cls: 0.138  loss_box_reg: 0.252  loss_rpn_cls: 0.072  loss_rpn_loc: 0.050  time: 0.3248  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:14 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 2179  total_loss: 0.539  loss_cls: 0.156  loss_box_reg: 0.289  loss_rpn_cls: 0.051  loss_rpn_loc: 0.030  time: 0.3248  data_time: 0.0101  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:20 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 2199  total_loss: 0.704  loss_cls: 0.204  loss_box_reg: 0.345  loss_rpn_cls: 0.047  loss_rpn_loc: 0.032  time: 0.3248  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:27 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 2219  total_loss: 0.624  loss_cls: 0.149  loss_box_reg: 0.337  loss_rpn_cls: 0.058  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:33 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 2239  total_loss: 0.646  loss_cls: 0.204  loss_box_reg: 0.312  loss_rpn_cls: 0.059  loss_rpn_loc: 0.038  time: 0.3248  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:40 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 2259  total_loss: 0.641  loss_cls: 0.181  loss_box_reg: 0.350  loss_rpn_cls: 0.058  loss_rpn_loc: 0.031  time: 0.3248  data_time: 0.0078  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:46 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 2279  total_loss: 0.551  loss_cls: 0.150  loss_box_reg: 0.302  loss_rpn_cls: 0.029  loss_rpn_loc: 0.028  time: 0.3248  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:00:53 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 2299  total_loss: 0.581  loss_cls: 0.127  loss_box_reg: 0.288  loss_rpn_cls: 0.063  loss_rpn_loc: 0.033  time: 0.3248  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:00 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 2319  total_loss: 0.642  loss_cls: 0.183  loss_box_reg: 0.343  loss_rpn_cls: 0.057  loss_rpn_loc: 0.030  time: 0.3249  data_time: 0.0270  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:06 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 2339  total_loss: 0.590  loss_cls: 0.141  loss_box_reg: 0.311  loss_rpn_cls: 0.038  loss_rpn_loc: 0.048  time: 0.3249  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:12 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 2359  total_loss: 0.694  loss_cls: 0.218  loss_box_reg: 0.292  loss_rpn_cls: 0.062  loss_rpn_loc: 0.050  time: 0.3248  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:19 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 2379  total_loss: 0.698  loss_cls: 0.185  loss_box_reg: 0.363  loss_rpn_cls: 0.061  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:25 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 2399  total_loss: 0.594  loss_cls: 0.141  loss_box_reg: 0.311  loss_rpn_cls: 0.058  loss_rpn_loc: 0.053  time: 0.3248  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:32 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 2419  total_loss: 0.719  loss_cls: 0.205  loss_box_reg: 0.343  loss_rpn_cls: 0.047  loss_rpn_loc: 0.058  time: 0.3248  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:38 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 2439  total_loss: 0.694  loss_cls: 0.242  loss_box_reg: 0.351  loss_rpn_cls: 0.072  loss_rpn_loc: 0.049  time: 0.3248  data_time: 0.0099  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:45 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 2459  total_loss: 0.640  loss_cls: 0.194  loss_box_reg: 0.326  loss_rpn_cls: 0.069  loss_rpn_loc: 0.035  time: 0.3247  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:51 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 2479  total_loss: 0.628  loss_cls: 0.134  loss_box_reg: 0.368  loss_rpn_cls: 0.050  loss_rpn_loc: 0.049  time: 0.3247  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:01:58 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 2499  total_loss: 0.634  loss_cls: 0.121  loss_box_reg: 0.318  loss_rpn_cls: 0.071  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:04 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 2519  total_loss: 0.742  loss_cls: 0.198  loss_box_reg: 0.383  loss_rpn_cls: 0.054  loss_rpn_loc: 0.045  time: 0.3247  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:11 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 2539  total_loss: 0.619  loss_cls: 0.193  loss_box_reg: 0.313  loss_rpn_cls: 0.047  loss_rpn_loc: 0.031  time: 0.3248  data_time: 0.0166  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:18 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 2559  total_loss: 0.650  loss_cls: 0.205  loss_box_reg: 0.327  loss_rpn_cls: 0.053  loss_rpn_loc: 0.046  time: 0.3248  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:24 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2579  total_loss: 0.580  loss_cls: 0.141  loss_box_reg: 0.318  loss_rpn_cls: 0.053  loss_rpn_loc: 0.029  time: 0.3248  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:31 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2599  total_loss: 0.647  loss_cls: 0.203  loss_box_reg: 0.309  loss_rpn_cls: 0.045  loss_rpn_loc: 0.050  time: 0.3250  data_time: 0.0319  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:37 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 2619  total_loss: 0.664  loss_cls: 0.189  loss_box_reg: 0.329  loss_rpn_cls: 0.070  loss_rpn_loc: 0.030  time: 0.3250  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:44 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 2639  total_loss: 0.580  loss_cls: 0.171  loss_box_reg: 0.297  loss_rpn_cls: 0.052  loss_rpn_loc: 0.032  time: 0.3249  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:50 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 2659  total_loss: 0.508  loss_cls: 0.143  loss_box_reg: 0.284  loss_rpn_cls: 0.033  loss_rpn_loc: 0.025  time: 0.3249  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:02:57 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 2679  total_loss: 0.688  loss_cls: 0.143  loss_box_reg: 0.333  loss_rpn_cls: 0.048  loss_rpn_loc: 0.034  time: 0.3249  data_time: 0.0079  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:03 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2699  total_loss: 0.651  loss_cls: 0.187  loss_box_reg: 0.306  loss_rpn_cls: 0.097  loss_rpn_loc: 0.042  time: 0.3249  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:10 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 2719  total_loss: 0.560  loss_cls: 0.118  loss_box_reg: 0.287  loss_rpn_cls: 0.058  loss_rpn_loc: 0.034  time: 0.3249  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:16 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2739  total_loss: 0.583  loss_cls: 0.142  loss_box_reg: 0.273  loss_rpn_cls: 0.045  loss_rpn_loc: 0.043  time: 0.3249  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:23 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 2759  total_loss: 0.461  loss_cls: 0.100  loss_box_reg: 0.276  loss_rpn_cls: 0.043  loss_rpn_loc: 0.036  time: 0.3249  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:29 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2779  total_loss: 0.655  loss_cls: 0.153  loss_box_reg: 0.336  loss_rpn_cls: 0.055  loss_rpn_loc: 0.062  time: 0.3249  data_time: 0.0150  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:36 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 2799  total_loss: 0.506  loss_cls: 0.161  loss_box_reg: 0.251  loss_rpn_cls: 0.047  loss_rpn_loc: 0.049  time: 0.3249  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:43 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 2819  total_loss: 0.547  loss_cls: 0.095  loss_box_reg: 0.300  loss_rpn_cls: 0.033  loss_rpn_loc: 0.048  time: 0.3249  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:49 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 2839  total_loss: 0.566  loss_cls: 0.148  loss_box_reg: 0.282  loss_rpn_cls: 0.050  loss_rpn_loc: 0.034  time: 0.3250  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:03:56 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2859  total_loss: 0.547  loss_cls: 0.158  loss_box_reg: 0.314  loss_rpn_cls: 0.050  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:02 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 2879  total_loss: 0.584  loss_cls: 0.174  loss_box_reg: 0.259  loss_rpn_cls: 0.047  loss_rpn_loc: 0.044  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:09 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 2899  total_loss: 0.548  loss_cls: 0.117  loss_box_reg: 0.299  loss_rpn_cls: 0.051  loss_rpn_loc: 0.031  time: 0.3249  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:15 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 2919  total_loss: 0.646  loss_cls: 0.167  loss_box_reg: 0.301  loss_rpn_cls: 0.038  loss_rpn_loc: 0.033  time: 0.3249  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:22 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 2939  total_loss: 0.545  loss_cls: 0.183  loss_box_reg: 0.276  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:28 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 2959  total_loss: 0.533  loss_cls: 0.140  loss_box_reg: 0.274  loss_rpn_cls: 0.037  loss_rpn_loc: 0.035  time: 0.3249  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:35 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2979  total_loss: 0.522  loss_cls: 0.124  loss_box_reg: 0.302  loss_rpn_cls: 0.033  loss_rpn_loc: 0.028  time: 0.3249  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:41 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 2999  total_loss: 0.467  loss_cls: 0.149  loss_box_reg: 0.293  loss_rpn_cls: 0.037  loss_rpn_loc: 0.032  time: 0.3249  data_time: 0.0132  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:47 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 3019  total_loss: 0.451  loss_cls: 0.086  loss_box_reg: 0.228  loss_rpn_cls: 0.041  loss_rpn_loc: 0.025  time: 0.3249  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:04:54 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 3039  total_loss: 0.658  loss_cls: 0.194  loss_box_reg: 0.358  loss_rpn_cls: 0.059  loss_rpn_loc: 0.036  time: 0.3249  data_time: 0.0154  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:01 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 3059  total_loss: 0.600  loss_cls: 0.163  loss_box_reg: 0.290  loss_rpn_cls: 0.063  loss_rpn_loc: 0.031  time: 0.3249  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:07 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 3079  total_loss: 0.612  loss_cls: 0.192  loss_box_reg: 0.326  loss_rpn_cls: 0.052  loss_rpn_loc: 0.035  time: 0.3249  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:13 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 3099  total_loss: 0.586  loss_cls: 0.174  loss_box_reg: 0.352  loss_rpn_cls: 0.051  loss_rpn_loc: 0.034  time: 0.3248  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:20 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 3119  total_loss: 0.529  loss_cls: 0.138  loss_box_reg: 0.291  loss_rpn_cls: 0.041  loss_rpn_loc: 0.053  time: 0.3248  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:26 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 3139  total_loss: 0.563  loss_cls: 0.135  loss_box_reg: 0.319  loss_rpn_cls: 0.049  loss_rpn_loc: 0.031  time: 0.3248  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:33 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 3159  total_loss: 0.508  loss_cls: 0.137  loss_box_reg: 0.292  loss_rpn_cls: 0.027  loss_rpn_loc: 0.021  time: 0.3248  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:39 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 3179  total_loss: 0.516  loss_cls: 0.135  loss_box_reg: 0.284  loss_rpn_cls: 0.056  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0093  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:46 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 3199  total_loss: 0.529  loss_cls: 0.163  loss_box_reg: 0.295  loss_rpn_cls: 0.041  loss_rpn_loc: 0.027  time: 0.3247  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:52 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 3219  total_loss: 0.590  loss_cls: 0.134  loss_box_reg: 0.285  loss_rpn_cls: 0.044  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:05:59 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 3239  total_loss: 0.591  loss_cls: 0.171  loss_box_reg: 0.319  loss_rpn_cls: 0.041  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0086  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:05 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 3259  total_loss: 0.473  loss_cls: 0.113  loss_box_reg: 0.284  loss_rpn_cls: 0.052  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:12 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 3279  total_loss: 0.555  loss_cls: 0.143  loss_box_reg: 0.288  loss_rpn_cls: 0.050  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0153  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:18 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3299  total_loss: 0.532  loss_cls: 0.159  loss_box_reg: 0.259  loss_rpn_cls: 0.043  loss_rpn_loc: 0.032  time: 0.3248  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:25 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3319  total_loss: 0.496  loss_cls: 0.116  loss_box_reg: 0.255  loss_rpn_cls: 0.035  loss_rpn_loc: 0.026  time: 0.3248  data_time: 0.0096  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:31 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3339  total_loss: 0.516  loss_cls: 0.128  loss_box_reg: 0.270  loss_rpn_cls: 0.068  loss_rpn_loc: 0.048  time: 0.3247  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:38 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 3359  total_loss: 0.679  loss_cls: 0.164  loss_box_reg: 0.322  loss_rpn_cls: 0.059  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:44 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 3379  total_loss: 0.479  loss_cls: 0.123  loss_box_reg: 0.263  loss_rpn_cls: 0.039  loss_rpn_loc: 0.030  time: 0.3247  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:51 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 3399  total_loss: 0.612  loss_cls: 0.180  loss_box_reg: 0.296  loss_rpn_cls: 0.047  loss_rpn_loc: 0.054  time: 0.3247  data_time: 0.0192  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:06:57 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 3419  total_loss: 0.496  loss_cls: 0.139  loss_box_reg: 0.246  loss_rpn_cls: 0.051  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:04 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 3439  total_loss: 0.610  loss_cls: 0.160  loss_box_reg: 0.317  loss_rpn_cls: 0.049  loss_rpn_loc: 0.038  time: 0.3247  data_time: 0.0141  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:10 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3459  total_loss: 0.590  loss_cls: 0.187  loss_box_reg: 0.298  loss_rpn_cls: 0.047  loss_rpn_loc: 0.047  time: 0.3247  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:17 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 3479  total_loss: 0.457  loss_cls: 0.116  loss_box_reg: 0.264  loss_rpn_cls: 0.037  loss_rpn_loc: 0.025  time: 0.3247  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:23 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 3499  total_loss: 0.634  loss_cls: 0.171  loss_box_reg: 0.317  loss_rpn_cls: 0.052  loss_rpn_loc: 0.032  time: 0.3246  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:29 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 3519  total_loss: 0.521  loss_cls: 0.122  loss_box_reg: 0.295  loss_rpn_cls: 0.039  loss_rpn_loc: 0.028  time: 0.3246  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:36 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3539  total_loss: 0.525  loss_cls: 0.103  loss_box_reg: 0.299  loss_rpn_cls: 0.051  loss_rpn_loc: 0.039  time: 0.3246  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:42 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 3559  total_loss: 0.649  loss_cls: 0.183  loss_box_reg: 0.277  loss_rpn_cls: 0.061  loss_rpn_loc: 0.041  time: 0.3246  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:49 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3579  total_loss: 0.385  loss_cls: 0.101  loss_box_reg: 0.255  loss_rpn_cls: 0.028  loss_rpn_loc: 0.026  time: 0.3246  data_time: 0.0166  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:07:55 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 3599  total_loss: 0.490  loss_cls: 0.111  loss_box_reg: 0.288  loss_rpn_cls: 0.054  loss_rpn_loc: 0.039  time: 0.3246  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:02 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3619  total_loss: 0.562  loss_cls: 0.119  loss_box_reg: 0.290  loss_rpn_cls: 0.041  loss_rpn_loc: 0.058  time: 0.3245  data_time: 0.0100  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:08 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 3639  total_loss: 0.544  loss_cls: 0.142  loss_box_reg: 0.299  loss_rpn_cls: 0.053  loss_rpn_loc: 0.034  time: 0.3245  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:15 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3659  total_loss: 0.486  loss_cls: 0.114  loss_box_reg: 0.299  loss_rpn_cls: 0.036  loss_rpn_loc: 0.036  time: 0.3245  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:21 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 3679  total_loss: 0.465  loss_cls: 0.126  loss_box_reg: 0.251  loss_rpn_cls: 0.036  loss_rpn_loc: 0.045  time: 0.3245  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:27 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3699  total_loss: 0.525  loss_cls: 0.114  loss_box_reg: 0.303  loss_rpn_cls: 0.054  loss_rpn_loc: 0.040  time: 0.3245  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:34 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3719  total_loss: 0.482  loss_cls: 0.093  loss_box_reg: 0.274  loss_rpn_cls: 0.053  loss_rpn_loc: 0.054  time: 0.3244  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:40 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3739  total_loss: 0.541  loss_cls: 0.169  loss_box_reg: 0.282  loss_rpn_cls: 0.044  loss_rpn_loc: 0.033  time: 0.3245  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:47 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 3759  total_loss: 0.521  loss_cls: 0.146  loss_box_reg: 0.289  loss_rpn_cls: 0.043  loss_rpn_loc: 0.032  time: 0.3244  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:08:53 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 3779  total_loss: 0.594  loss_cls: 0.170  loss_box_reg: 0.309  loss_rpn_cls: 0.038  loss_rpn_loc: 0.030  time: 0.3244  data_time: 0.0165  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:00 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3799  total_loss: 0.371  loss_cls: 0.096  loss_box_reg: 0.231  loss_rpn_cls: 0.028  loss_rpn_loc: 0.019  time: 0.3244  data_time: 0.0138  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:07 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 3819  total_loss: 0.541  loss_cls: 0.172  loss_box_reg: 0.292  loss_rpn_cls: 0.039  loss_rpn_loc: 0.053  time: 0.3245  data_time: 0.0140  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:13 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3839  total_loss: 0.403  loss_cls: 0.084  loss_box_reg: 0.251  loss_rpn_cls: 0.027  loss_rpn_loc: 0.016  time: 0.3245  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:19 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3859  total_loss: 0.608  loss_cls: 0.141  loss_box_reg: 0.305  loss_rpn_cls: 0.055  loss_rpn_loc: 0.062  time: 0.3245  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:26 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 3879  total_loss: 0.453  loss_cls: 0.102  loss_box_reg: 0.281  loss_rpn_cls: 0.039  loss_rpn_loc: 0.022  time: 0.3245  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:32 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 3899  total_loss: 0.469  loss_cls: 0.122  loss_box_reg: 0.286  loss_rpn_cls: 0.047  loss_rpn_loc: 0.026  time: 0.3244  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:39 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 3919  total_loss: 0.463  loss_cls: 0.108  loss_box_reg: 0.267  loss_rpn_cls: 0.029  loss_rpn_loc: 0.046  time: 0.3244  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:46 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 3939  total_loss: 0.512  loss_cls: 0.130  loss_box_reg: 0.280  loss_rpn_cls: 0.036  loss_rpn_loc: 0.042  time: 0.3245  data_time: 0.0191  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:52 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 3959  total_loss: 0.600  loss_cls: 0.160  loss_box_reg: 0.282  loss_rpn_cls: 0.051  loss_rpn_loc: 0.053  time: 0.3245  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:09:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 3979  total_loss: 0.515  loss_cls: 0.144  loss_box_reg: 0.257  loss_rpn_cls: 0.041  loss_rpn_loc: 0.041  time: 0.3245  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:10:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.557  loss_cls: 0.191  loss_box_reg: 0.253  loss_rpn_cls: 0.044  loss_rpn_loc: 0.048  time: 0.3244  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:10:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.563  loss_cls: 0.181  loss_box_reg: 0.258  loss_rpn_cls: 0.044  loss_rpn_loc: 0.048  time: 0.3244  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:10:06 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:21:37 (0.3245 s / it)\n",
            "\u001b[32m[05/04 01:10:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:41 (0:00:04 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:10:07 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:10:07 d2.data.datasets.coco]: \u001b[0mLoaded 343 images in COCO format from greenthumbs/data/v01/test_75%_coco.json\n",
            "\u001b[32m[05/04 01:10:07 d2.data.common]: \u001b[0mSerializing 343 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:10:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
            "\u001b[32m[05/04 01:10:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 343 images\n",
            "\u001b[32m[05/04 01:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/343. 0.1306 s / img. ETA=0:00:43\n",
            "\u001b[32m[05/04 01:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 39/343. 0.1593 s / img. ETA=0:00:52\n",
            "\u001b[32m[05/04 01:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 69/343. 0.1532 s / img. ETA=0:00:46\n",
            "\u001b[32m[05/04 01:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 102/343. 0.1522 s / img. ETA=0:00:39\n",
            "\u001b[32m[05/04 01:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 136/343. 0.1494 s / img. ETA=0:00:33\n",
            "\u001b[32m[05/04 01:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 170/343. 0.1487 s / img. ETA=0:00:27\n",
            "\u001b[32m[05/04 01:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 204/343. 0.1487 s / img. ETA=0:00:21\n",
            "\u001b[32m[05/04 01:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 241/343. 0.1468 s / img. ETA=0:00:15\n",
            "\u001b[32m[05/04 01:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 274/343. 0.1470 s / img. ETA=0:00:10\n",
            "\u001b[32m[05/04 01:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 307/343. 0.1472 s / img. ETA=0:00:05\n",
            "\u001b[32m[05/04 01:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 343/343. 0.1465 s / img. ETA=0:00:00\n",
            "\u001b[32m[05/04 01:10:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.460345 (0.152250 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:10:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:49 (0.146463 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:10:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 01:10:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128/coco_instances_results.json\n",
            "\u001b[32m[05/04 01:11:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.55s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.35s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.552\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
            "\u001b[32m[05/04 01:11:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 32.907 | 55.181 | 35.458 | 14.581 | 26.249 | 44.398 |\n",
            "\u001b[32m[05/04 01:11:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 49.778 | tomato_fruit       | 29.649 | tomato_seedling          | 24.345 |\n",
            "| tomato_young_plant      | 33.288 | tomato_flower      | 20.234 | bell_pepper_fruit        | 46.285 |\n",
            "| bell_pepper_young_plant | 40.885 | bell_pepper_flower | 39.495 | bell_pepper_fruit_unripe | 21.494 |\n",
            "| bell_pepper_seedling    | 9.283  | cucumber_flower    | 52.365 | cucumber_plant           | 1.930  |\n",
            "| cucumber_seedling       | 25.841 | cucumber_fruit     | 67.760 | cucumber_fruit_unripe    | 30.980 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_75%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128___2.png\n",
            "Saving results...\n",
            "Saved /content/drive/My Drive/Green Thumbs/v01_75%_faster_rcnn_R_50_C4_3x.yaml_05-03-2020_21:04.json\n",
            "\u001b[32m[05/04 01:11:03 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:11:03 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:11:03 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 01:11:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 01:11:03 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| tomato_frui.. | 711          | tomato_fruit  | 243          | tomato_seed.. | 422          |\n",
            "| tomato_youn.. | 168          | tomato_flower | 202          | bell_pepper.. | 466          |\n",
            "| bell_pepper.. | 117          | bell_pepper.. | 104          | bell_pepper.. | 143          |\n",
            "| bell_pepper.. | 97           | cucumber_fl.. | 176          | cucumber_pl.. | 33           |\n",
            "| cucumber_se.. | 127          | cucumber_fr.. | 510          | cucumber_fr.. | 116          |\n",
            "|               |              |               |              |               |              |\n",
            "|     total     | 3635         |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[05/04 01:11:03 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:11:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 01:11:03 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 01:11:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_64\n",
            "**********************************************\n",
            "\u001b[32m[05/04 01:11:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 01:11:08 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 19  total_loss: 3.933  loss_cls: 2.669  loss_box_reg: 0.938  loss_rpn_cls: 0.210  loss_rpn_loc: 0.088  time: 0.2495  data_time: 0.0134  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:14 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 39  total_loss: 2.717  loss_cls: 1.664  loss_box_reg: 0.919  loss_rpn_cls: 0.173  loss_rpn_loc: 0.057  time: 0.2645  data_time: 0.0395  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:19 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 59  total_loss: 2.522  loss_cls: 1.223  loss_box_reg: 0.943  loss_rpn_cls: 0.184  loss_rpn_loc: 0.047  time: 0.2639  data_time: 0.0142  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:24 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 79  total_loss: 2.205  loss_cls: 1.009  loss_box_reg: 0.916  loss_rpn_cls: 0.193  loss_rpn_loc: 0.063  time: 0.2612  data_time: 0.0068  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:29 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 99  total_loss: 2.194  loss_cls: 0.968  loss_box_reg: 0.916  loss_rpn_cls: 0.185  loss_rpn_loc: 0.051  time: 0.2590  data_time: 0.0063  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:34 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 119  total_loss: 2.037  loss_cls: 0.913  loss_box_reg: 0.890  loss_rpn_cls: 0.144  loss_rpn_loc: 0.055  time: 0.2621  data_time: 0.0302  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:40 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 139  total_loss: 2.060  loss_cls: 0.928  loss_box_reg: 0.961  loss_rpn_cls: 0.159  loss_rpn_loc: 0.060  time: 0.2629  data_time: 0.0256  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:45 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 159  total_loss: 1.889  loss_cls: 0.817  loss_box_reg: 0.899  loss_rpn_cls: 0.131  loss_rpn_loc: 0.047  time: 0.2617  data_time: 0.0060  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:50 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 179  total_loss: 1.882  loss_cls: 0.754  loss_box_reg: 0.861  loss_rpn_cls: 0.131  loss_rpn_loc: 0.059  time: 0.2597  data_time: 0.0063  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:11:55 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 199  total_loss: 1.830  loss_cls: 0.713  loss_box_reg: 0.866  loss_rpn_cls: 0.147  loss_rpn_loc: 0.066  time: 0.2608  data_time: 0.0292  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:00 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 219  total_loss: 1.695  loss_cls: 0.679  loss_box_reg: 0.844  loss_rpn_cls: 0.143  loss_rpn_loc: 0.052  time: 0.2600  data_time: 0.0109  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:05 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 239  total_loss: 1.659  loss_cls: 0.658  loss_box_reg: 0.785  loss_rpn_cls: 0.134  loss_rpn_loc: 0.046  time: 0.2596  data_time: 0.0134  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:10 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 259  total_loss: 1.545  loss_cls: 0.653  loss_box_reg: 0.714  loss_rpn_cls: 0.116  loss_rpn_loc: 0.051  time: 0.2585  data_time: 0.0058  lr: 0.000519  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:15 d2.utils.events]: \u001b[0m eta: 0:15:39  iter: 279  total_loss: 1.641  loss_cls: 0.634  loss_box_reg: 0.774  loss_rpn_cls: 0.110  loss_rpn_loc: 0.048  time: 0.2576  data_time: 0.0059  lr: 0.000559  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:20 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 299  total_loss: 1.487  loss_cls: 0.552  loss_box_reg: 0.684  loss_rpn_cls: 0.092  loss_rpn_loc: 0.034  time: 0.2574  data_time: 0.0069  lr: 0.000599  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:25 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 319  total_loss: 1.501  loss_cls: 0.586  loss_box_reg: 0.684  loss_rpn_cls: 0.101  loss_rpn_loc: 0.053  time: 0.2565  data_time: 0.0069  lr: 0.000639  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:30 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 339  total_loss: 1.420  loss_cls: 0.525  loss_box_reg: 0.676  loss_rpn_cls: 0.096  loss_rpn_loc: 0.036  time: 0.2562  data_time: 0.0064  lr: 0.000679  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:35 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 359  total_loss: 1.171  loss_cls: 0.477  loss_box_reg: 0.609  loss_rpn_cls: 0.127  loss_rpn_loc: 0.032  time: 0.2554  data_time: 0.0055  lr: 0.000719  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:40 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 379  total_loss: 1.307  loss_cls: 0.536  loss_box_reg: 0.595  loss_rpn_cls: 0.106  loss_rpn_loc: 0.072  time: 0.2552  data_time: 0.0067  lr: 0.000759  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:45 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 399  total_loss: 1.336  loss_cls: 0.554  loss_box_reg: 0.610  loss_rpn_cls: 0.107  loss_rpn_loc: 0.047  time: 0.2549  data_time: 0.0060  lr: 0.000799  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:50 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 419  total_loss: 1.113  loss_cls: 0.425  loss_box_reg: 0.523  loss_rpn_cls: 0.090  loss_rpn_loc: 0.052  time: 0.2552  data_time: 0.0173  lr: 0.000839  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:12:56 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 439  total_loss: 1.328  loss_cls: 0.562  loss_box_reg: 0.592  loss_rpn_cls: 0.108  loss_rpn_loc: 0.043  time: 0.2552  data_time: 0.0062  lr: 0.000879  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:01 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 459  total_loss: 1.183  loss_cls: 0.434  loss_box_reg: 0.558  loss_rpn_cls: 0.104  loss_rpn_loc: 0.044  time: 0.2548  data_time: 0.0058  lr: 0.000919  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:06 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 479  total_loss: 1.219  loss_cls: 0.491  loss_box_reg: 0.564  loss_rpn_cls: 0.109  loss_rpn_loc: 0.050  time: 0.2547  data_time: 0.0062  lr: 0.000959  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:11 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 499  total_loss: 1.328  loss_cls: 0.471  loss_box_reg: 0.643  loss_rpn_cls: 0.118  loss_rpn_loc: 0.076  time: 0.2546  data_time: 0.0143  lr: 0.000999  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:16 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 519  total_loss: 1.193  loss_cls: 0.401  loss_box_reg: 0.622  loss_rpn_cls: 0.111  loss_rpn_loc: 0.061  time: 0.2547  data_time: 0.0166  lr: 0.001039  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:21 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 539  total_loss: 1.050  loss_cls: 0.340  loss_box_reg: 0.551  loss_rpn_cls: 0.081  loss_rpn_loc: 0.042  time: 0.2548  data_time: 0.0059  lr: 0.001079  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:26 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 559  total_loss: 1.090  loss_cls: 0.376  loss_box_reg: 0.546  loss_rpn_cls: 0.097  loss_rpn_loc: 0.055  time: 0.2544  data_time: 0.0059  lr: 0.001119  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:31 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 579  total_loss: 1.232  loss_cls: 0.491  loss_box_reg: 0.551  loss_rpn_cls: 0.089  loss_rpn_loc: 0.055  time: 0.2543  data_time: 0.0056  lr: 0.001159  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:36 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 599  total_loss: 1.261  loss_cls: 0.432  loss_box_reg: 0.575  loss_rpn_cls: 0.102  loss_rpn_loc: 0.071  time: 0.2543  data_time: 0.0062  lr: 0.001199  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:41 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 619  total_loss: 1.158  loss_cls: 0.394  loss_box_reg: 0.480  loss_rpn_cls: 0.098  loss_rpn_loc: 0.050  time: 0.2542  data_time: 0.0061  lr: 0.001239  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:47 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 639  total_loss: 1.135  loss_cls: 0.418  loss_box_reg: 0.491  loss_rpn_cls: 0.086  loss_rpn_loc: 0.047  time: 0.2548  data_time: 0.0375  lr: 0.001279  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:52 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 659  total_loss: 0.973  loss_cls: 0.293  loss_box_reg: 0.571  loss_rpn_cls: 0.072  loss_rpn_loc: 0.048  time: 0.2548  data_time: 0.0060  lr: 0.001319  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:13:57 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 679  total_loss: 1.028  loss_cls: 0.312  loss_box_reg: 0.556  loss_rpn_cls: 0.086  loss_rpn_loc: 0.051  time: 0.2547  data_time: 0.0112  lr: 0.001359  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:02 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 699  total_loss: 0.963  loss_cls: 0.357  loss_box_reg: 0.489  loss_rpn_cls: 0.062  loss_rpn_loc: 0.060  time: 0.2543  data_time: 0.0151  lr: 0.001399  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:07 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 719  total_loss: 1.257  loss_cls: 0.358  loss_box_reg: 0.523  loss_rpn_cls: 0.116  loss_rpn_loc: 0.091  time: 0.2547  data_time: 0.0213  lr: 0.001439  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:12 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 739  total_loss: 1.131  loss_cls: 0.424  loss_box_reg: 0.511  loss_rpn_cls: 0.103  loss_rpn_loc: 0.039  time: 0.2544  data_time: 0.0059  lr: 0.001479  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:17 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 759  total_loss: 0.932  loss_cls: 0.308  loss_box_reg: 0.506  loss_rpn_cls: 0.078  loss_rpn_loc: 0.060  time: 0.2542  data_time: 0.0056  lr: 0.001518  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:22 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 779  total_loss: 1.114  loss_cls: 0.366  loss_box_reg: 0.540  loss_rpn_cls: 0.091  loss_rpn_loc: 0.049  time: 0.2545  data_time: 0.0170  lr: 0.001558  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:27 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 799  total_loss: 1.064  loss_cls: 0.330  loss_box_reg: 0.506  loss_rpn_cls: 0.073  loss_rpn_loc: 0.028  time: 0.2543  data_time: 0.0065  lr: 0.001598  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:32 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 819  total_loss: 1.078  loss_cls: 0.419  loss_box_reg: 0.541  loss_rpn_cls: 0.093  loss_rpn_loc: 0.041  time: 0.2544  data_time: 0.0118  lr: 0.001638  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:37 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 839  total_loss: 1.072  loss_cls: 0.369  loss_box_reg: 0.535  loss_rpn_cls: 0.109  loss_rpn_loc: 0.077  time: 0.2544  data_time: 0.0062  lr: 0.001678  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:42 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 859  total_loss: 1.074  loss_cls: 0.428  loss_box_reg: 0.553  loss_rpn_cls: 0.113  loss_rpn_loc: 0.037  time: 0.2542  data_time: 0.0081  lr: 0.001718  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:47 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 879  total_loss: 1.051  loss_cls: 0.378  loss_box_reg: 0.494  loss_rpn_cls: 0.092  loss_rpn_loc: 0.050  time: 0.2541  data_time: 0.0057  lr: 0.001758  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:52 d2.utils.events]: \u001b[0m eta: 0:12:59  iter: 899  total_loss: 1.061  loss_cls: 0.413  loss_box_reg: 0.500  loss_rpn_cls: 0.068  loss_rpn_loc: 0.038  time: 0.2539  data_time: 0.0058  lr: 0.001798  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:14:57 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 919  total_loss: 1.196  loss_cls: 0.395  loss_box_reg: 0.569  loss_rpn_cls: 0.108  loss_rpn_loc: 0.071  time: 0.2539  data_time: 0.0073  lr: 0.001838  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:02 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 939  total_loss: 1.240  loss_cls: 0.430  loss_box_reg: 0.575  loss_rpn_cls: 0.111  loss_rpn_loc: 0.048  time: 0.2537  data_time: 0.0059  lr: 0.001878  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:07 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 959  total_loss: 1.071  loss_cls: 0.406  loss_box_reg: 0.546  loss_rpn_cls: 0.102  loss_rpn_loc: 0.056  time: 0.2536  data_time: 0.0061  lr: 0.001918  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:12 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 979  total_loss: 1.231  loss_cls: 0.424  loss_box_reg: 0.542  loss_rpn_cls: 0.094  loss_rpn_loc: 0.060  time: 0.2536  data_time: 0.0057  lr: 0.001958  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:17 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 999  total_loss: 1.121  loss_cls: 0.424  loss_box_reg: 0.509  loss_rpn_cls: 0.098  loss_rpn_loc: 0.035  time: 0.2535  data_time: 0.0117  lr: 0.001998  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:22 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 1019  total_loss: 0.995  loss_cls: 0.336  loss_box_reg: 0.474  loss_rpn_cls: 0.090  loss_rpn_loc: 0.065  time: 0.2534  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:27 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 1039  total_loss: 1.102  loss_cls: 0.412  loss_box_reg: 0.435  loss_rpn_cls: 0.097  loss_rpn_loc: 0.045  time: 0.2535  data_time: 0.0192  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:32 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 1059  total_loss: 1.114  loss_cls: 0.396  loss_box_reg: 0.480  loss_rpn_cls: 0.100  loss_rpn_loc: 0.061  time: 0.2534  data_time: 0.0090  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:37 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1079  total_loss: 0.978  loss_cls: 0.340  loss_box_reg: 0.447  loss_rpn_cls: 0.090  loss_rpn_loc: 0.041  time: 0.2534  data_time: 0.0150  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:42 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1099  total_loss: 0.903  loss_cls: 0.262  loss_box_reg: 0.531  loss_rpn_cls: 0.061  loss_rpn_loc: 0.029  time: 0.2533  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:47 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1119  total_loss: 1.116  loss_cls: 0.375  loss_box_reg: 0.518  loss_rpn_cls: 0.095  loss_rpn_loc: 0.047  time: 0.2532  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:52 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 1139  total_loss: 0.900  loss_cls: 0.287  loss_box_reg: 0.492  loss_rpn_cls: 0.060  loss_rpn_loc: 0.036  time: 0.2531  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:15:58 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1159  total_loss: 0.937  loss_cls: 0.342  loss_box_reg: 0.465  loss_rpn_cls: 0.088  loss_rpn_loc: 0.064  time: 0.2534  data_time: 0.0210  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:03 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 1179  total_loss: 0.956  loss_cls: 0.314  loss_box_reg: 0.491  loss_rpn_cls: 0.077  loss_rpn_loc: 0.032  time: 0.2533  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:08 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 1199  total_loss: 0.977  loss_cls: 0.397  loss_box_reg: 0.457  loss_rpn_cls: 0.080  loss_rpn_loc: 0.053  time: 0.2532  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:13 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 1219  total_loss: 0.873  loss_cls: 0.282  loss_box_reg: 0.459  loss_rpn_cls: 0.104  loss_rpn_loc: 0.060  time: 0.2531  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:18 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1239  total_loss: 1.001  loss_cls: 0.342  loss_box_reg: 0.483  loss_rpn_cls: 0.098  loss_rpn_loc: 0.053  time: 0.2532  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:23 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 1259  total_loss: 0.897  loss_cls: 0.313  loss_box_reg: 0.450  loss_rpn_cls: 0.073  loss_rpn_loc: 0.050  time: 0.2531  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:28 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 1279  total_loss: 0.863  loss_cls: 0.245  loss_box_reg: 0.466  loss_rpn_cls: 0.048  loss_rpn_loc: 0.024  time: 0.2531  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:33 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 1299  total_loss: 0.879  loss_cls: 0.313  loss_box_reg: 0.451  loss_rpn_cls: 0.071  loss_rpn_loc: 0.034  time: 0.2530  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:38 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 1319  total_loss: 0.962  loss_cls: 0.296  loss_box_reg: 0.528  loss_rpn_cls: 0.077  loss_rpn_loc: 0.044  time: 0.2531  data_time: 0.0191  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:43 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 1339  total_loss: 1.073  loss_cls: 0.371  loss_box_reg: 0.492  loss_rpn_cls: 0.075  loss_rpn_loc: 0.057  time: 0.2530  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:48 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 1359  total_loss: 1.066  loss_cls: 0.393  loss_box_reg: 0.492  loss_rpn_cls: 0.086  loss_rpn_loc: 0.043  time: 0.2531  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:53 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 1379  total_loss: 0.824  loss_cls: 0.237  loss_box_reg: 0.417  loss_rpn_cls: 0.082  loss_rpn_loc: 0.050  time: 0.2531  data_time: 0.0118  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:16:58 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 1399  total_loss: 0.887  loss_cls: 0.287  loss_box_reg: 0.485  loss_rpn_cls: 0.072  loss_rpn_loc: 0.044  time: 0.2531  data_time: 0.0072  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:03 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 1419  total_loss: 0.962  loss_cls: 0.306  loss_box_reg: 0.434  loss_rpn_cls: 0.077  loss_rpn_loc: 0.052  time: 0.2530  data_time: 0.0078  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:09 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 1439  total_loss: 1.035  loss_cls: 0.376  loss_box_reg: 0.493  loss_rpn_cls: 0.074  loss_rpn_loc: 0.052  time: 0.2532  data_time: 0.0209  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:14 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1459  total_loss: 0.814  loss_cls: 0.251  loss_box_reg: 0.395  loss_rpn_cls: 0.083  loss_rpn_loc: 0.034  time: 0.2531  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:19 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 1479  total_loss: 0.973  loss_cls: 0.333  loss_box_reg: 0.431  loss_rpn_cls: 0.074  loss_rpn_loc: 0.041  time: 0.2531  data_time: 0.0077  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:24 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1499  total_loss: 0.836  loss_cls: 0.237  loss_box_reg: 0.486  loss_rpn_cls: 0.077  loss_rpn_loc: 0.062  time: 0.2531  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:29 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 1519  total_loss: 0.963  loss_cls: 0.273  loss_box_reg: 0.524  loss_rpn_cls: 0.074  loss_rpn_loc: 0.038  time: 0.2531  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:34 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 1539  total_loss: 0.912  loss_cls: 0.267  loss_box_reg: 0.486  loss_rpn_cls: 0.083  loss_rpn_loc: 0.068  time: 0.2532  data_time: 0.0065  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:39 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 1559  total_loss: 1.018  loss_cls: 0.307  loss_box_reg: 0.509  loss_rpn_cls: 0.087  loss_rpn_loc: 0.057  time: 0.2531  data_time: 0.0095  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:44 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 1579  total_loss: 1.002  loss_cls: 0.305  loss_box_reg: 0.422  loss_rpn_cls: 0.078  loss_rpn_loc: 0.056  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:49 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 1599  total_loss: 0.823  loss_cls: 0.245  loss_box_reg: 0.439  loss_rpn_cls: 0.068  loss_rpn_loc: 0.052  time: 0.2530  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:17:54 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 1619  total_loss: 0.833  loss_cls: 0.279  loss_box_reg: 0.449  loss_rpn_cls: 0.054  loss_rpn_loc: 0.030  time: 0.2530  data_time: 0.0166  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:00 d2.utils.events]: \u001b[0m eta: 0:09:52  iter: 1639  total_loss: 0.777  loss_cls: 0.207  loss_box_reg: 0.436  loss_rpn_cls: 0.067  loss_rpn_loc: 0.056  time: 0.2535  data_time: 0.0461  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:05 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 1659  total_loss: 1.022  loss_cls: 0.342  loss_box_reg: 0.432  loss_rpn_cls: 0.101  loss_rpn_loc: 0.060  time: 0.2534  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:10 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 1679  total_loss: 0.918  loss_cls: 0.214  loss_box_reg: 0.414  loss_rpn_cls: 0.069  loss_rpn_loc: 0.070  time: 0.2533  data_time: 0.0056  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:15 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 1699  total_loss: 1.082  loss_cls: 0.275  loss_box_reg: 0.523  loss_rpn_cls: 0.091  loss_rpn_loc: 0.080  time: 0.2533  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:20 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 1719  total_loss: 0.914  loss_cls: 0.272  loss_box_reg: 0.425  loss_rpn_cls: 0.098  loss_rpn_loc: 0.065  time: 0.2533  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:25 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1739  total_loss: 0.939  loss_cls: 0.355  loss_box_reg: 0.442  loss_rpn_cls: 0.063  loss_rpn_loc: 0.046  time: 0.2533  data_time: 0.0116  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:30 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 1759  total_loss: 0.968  loss_cls: 0.271  loss_box_reg: 0.423  loss_rpn_cls: 0.088  loss_rpn_loc: 0.054  time: 0.2532  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:35 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 1779  total_loss: 0.769  loss_cls: 0.198  loss_box_reg: 0.400  loss_rpn_cls: 0.068  loss_rpn_loc: 0.034  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:40 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 1799  total_loss: 0.963  loss_cls: 0.263  loss_box_reg: 0.429  loss_rpn_cls: 0.069  loss_rpn_loc: 0.056  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:45 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1819  total_loss: 0.906  loss_cls: 0.253  loss_box_reg: 0.480  loss_rpn_cls: 0.094  loss_rpn_loc: 0.042  time: 0.2531  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:50 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 1839  total_loss: 0.873  loss_cls: 0.251  loss_box_reg: 0.470  loss_rpn_cls: 0.049  loss_rpn_loc: 0.043  time: 0.2530  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:18:55 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 1859  total_loss: 0.713  loss_cls: 0.195  loss_box_reg: 0.420  loss_rpn_cls: 0.060  loss_rpn_loc: 0.045  time: 0.2530  data_time: 0.0086  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:00 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 1879  total_loss: 0.801  loss_cls: 0.182  loss_box_reg: 0.490  loss_rpn_cls: 0.063  loss_rpn_loc: 0.057  time: 0.2530  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:05 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1899  total_loss: 0.847  loss_cls: 0.266  loss_box_reg: 0.458  loss_rpn_cls: 0.083  loss_rpn_loc: 0.046  time: 0.2530  data_time: 0.0154  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:10 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1919  total_loss: 0.726  loss_cls: 0.211  loss_box_reg: 0.393  loss_rpn_cls: 0.067  loss_rpn_loc: 0.048  time: 0.2531  data_time: 0.0229  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:15 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1939  total_loss: 0.830  loss_cls: 0.222  loss_box_reg: 0.439  loss_rpn_cls: 0.063  loss_rpn_loc: 0.072  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:20 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 1959  total_loss: 0.846  loss_cls: 0.258  loss_box_reg: 0.464  loss_rpn_cls: 0.081  loss_rpn_loc: 0.060  time: 0.2530  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:25 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1979  total_loss: 0.861  loss_cls: 0.267  loss_box_reg: 0.444  loss_rpn_cls: 0.069  loss_rpn_loc: 0.054  time: 0.2530  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:31 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1999  total_loss: 0.718  loss_cls: 0.176  loss_box_reg: 0.440  loss_rpn_cls: 0.046  loss_rpn_loc: 0.032  time: 0.2531  data_time: 0.0247  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:36 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 2019  total_loss: 0.880  loss_cls: 0.205  loss_box_reg: 0.468  loss_rpn_cls: 0.090  loss_rpn_loc: 0.069  time: 0.2530  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:41 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 2039  total_loss: 0.893  loss_cls: 0.283  loss_box_reg: 0.471  loss_rpn_cls: 0.061  loss_rpn_loc: 0.043  time: 0.2530  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:46 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 2059  total_loss: 0.725  loss_cls: 0.247  loss_box_reg: 0.392  loss_rpn_cls: 0.055  loss_rpn_loc: 0.024  time: 0.2530  data_time: 0.0135  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:51 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 2079  total_loss: 0.752  loss_cls: 0.194  loss_box_reg: 0.384  loss_rpn_cls: 0.061  loss_rpn_loc: 0.030  time: 0.2532  data_time: 0.0304  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:19:56 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 2099  total_loss: 0.871  loss_cls: 0.190  loss_box_reg: 0.455  loss_rpn_cls: 0.066  loss_rpn_loc: 0.040  time: 0.2531  data_time: 0.0089  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:01 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 2119  total_loss: 0.844  loss_cls: 0.204  loss_box_reg: 0.390  loss_rpn_cls: 0.066  loss_rpn_loc: 0.053  time: 0.2531  data_time: 0.0098  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:06 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 2139  total_loss: 0.782  loss_cls: 0.235  loss_box_reg: 0.407  loss_rpn_cls: 0.050  loss_rpn_loc: 0.033  time: 0.2531  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:11 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2159  total_loss: 0.792  loss_cls: 0.295  loss_box_reg: 0.413  loss_rpn_cls: 0.056  loss_rpn_loc: 0.038  time: 0.2531  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:16 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 2179  total_loss: 0.842  loss_cls: 0.252  loss_box_reg: 0.468  loss_rpn_cls: 0.058  loss_rpn_loc: 0.046  time: 0.2530  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:22 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 2199  total_loss: 0.884  loss_cls: 0.262  loss_box_reg: 0.460  loss_rpn_cls: 0.084  loss_rpn_loc: 0.061  time: 0.2531  data_time: 0.0285  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:27 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 2219  total_loss: 0.727  loss_cls: 0.255  loss_box_reg: 0.355  loss_rpn_cls: 0.060  loss_rpn_loc: 0.046  time: 0.2531  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:32 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 2239  total_loss: 0.734  loss_cls: 0.216  loss_box_reg: 0.418  loss_rpn_cls: 0.059  loss_rpn_loc: 0.038  time: 0.2530  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:37 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 2259  total_loss: 0.844  loss_cls: 0.334  loss_box_reg: 0.364  loss_rpn_cls: 0.059  loss_rpn_loc: 0.037  time: 0.2531  data_time: 0.0117  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:42 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 2279  total_loss: 0.844  loss_cls: 0.214  loss_box_reg: 0.415  loss_rpn_cls: 0.072  loss_rpn_loc: 0.037  time: 0.2534  data_time: 0.0528  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:47 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 2299  total_loss: 0.834  loss_cls: 0.273  loss_box_reg: 0.405  loss_rpn_cls: 0.063  loss_rpn_loc: 0.055  time: 0.2534  data_time: 0.0080  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:53 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 2319  total_loss: 0.741  loss_cls: 0.261  loss_box_reg: 0.376  loss_rpn_cls: 0.052  loss_rpn_loc: 0.032  time: 0.2533  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:20:57 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 2339  total_loss: 0.693  loss_cls: 0.166  loss_box_reg: 0.435  loss_rpn_cls: 0.069  loss_rpn_loc: 0.043  time: 0.2533  data_time: 0.0098  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:03 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 2359  total_loss: 0.763  loss_cls: 0.205  loss_box_reg: 0.432  loss_rpn_cls: 0.044  loss_rpn_loc: 0.043  time: 0.2533  data_time: 0.0127  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:07 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 2379  total_loss: 0.734  loss_cls: 0.237  loss_box_reg: 0.385  loss_rpn_cls: 0.052  loss_rpn_loc: 0.047  time: 0.2532  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:12 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 2399  total_loss: 0.756  loss_cls: 0.212  loss_box_reg: 0.386  loss_rpn_cls: 0.071  loss_rpn_loc: 0.056  time: 0.2532  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:18 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2419  total_loss: 0.678  loss_cls: 0.187  loss_box_reg: 0.378  loss_rpn_cls: 0.049  loss_rpn_loc: 0.036  time: 0.2533  data_time: 0.0240  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:23 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 2439  total_loss: 0.680  loss_cls: 0.195  loss_box_reg: 0.362  loss_rpn_cls: 0.062  loss_rpn_loc: 0.069  time: 0.2533  data_time: 0.0133  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:28 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 2459  total_loss: 0.701  loss_cls: 0.186  loss_box_reg: 0.418  loss_rpn_cls: 0.074  loss_rpn_loc: 0.064  time: 0.2533  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:33 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 2479  total_loss: 0.809  loss_cls: 0.215  loss_box_reg: 0.411  loss_rpn_cls: 0.055  loss_rpn_loc: 0.050  time: 0.2532  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:38 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2499  total_loss: 0.731  loss_cls: 0.221  loss_box_reg: 0.374  loss_rpn_cls: 0.047  loss_rpn_loc: 0.052  time: 0.2532  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:43 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 2519  total_loss: 0.694  loss_cls: 0.195  loss_box_reg: 0.332  loss_rpn_cls: 0.044  loss_rpn_loc: 0.049  time: 0.2532  data_time: 0.0228  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:48 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 2539  total_loss: 0.761  loss_cls: 0.216  loss_box_reg: 0.380  loss_rpn_cls: 0.046  loss_rpn_loc: 0.039  time: 0.2533  data_time: 0.0168  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:53 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 2559  total_loss: 0.814  loss_cls: 0.210  loss_box_reg: 0.432  loss_rpn_cls: 0.059  loss_rpn_loc: 0.045  time: 0.2532  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:21:58 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 2579  total_loss: 0.658  loss_cls: 0.209  loss_box_reg: 0.366  loss_rpn_cls: 0.062  loss_rpn_loc: 0.030  time: 0.2532  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:03 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 2599  total_loss: 0.660  loss_cls: 0.186  loss_box_reg: 0.363  loss_rpn_cls: 0.050  loss_rpn_loc: 0.041  time: 0.2532  data_time: 0.0153  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:08 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 2619  total_loss: 0.760  loss_cls: 0.232  loss_box_reg: 0.419  loss_rpn_cls: 0.057  loss_rpn_loc: 0.062  time: 0.2532  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:13 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 2639  total_loss: 0.778  loss_cls: 0.228  loss_box_reg: 0.401  loss_rpn_cls: 0.058  loss_rpn_loc: 0.058  time: 0.2532  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:18 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 2659  total_loss: 0.654  loss_cls: 0.206  loss_box_reg: 0.338  loss_rpn_cls: 0.051  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0074  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:24 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2679  total_loss: 0.805  loss_cls: 0.254  loss_box_reg: 0.388  loss_rpn_cls: 0.053  loss_rpn_loc: 0.044  time: 0.2532  data_time: 0.0264  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:29 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2699  total_loss: 0.824  loss_cls: 0.252  loss_box_reg: 0.422  loss_rpn_cls: 0.060  loss_rpn_loc: 0.056  time: 0.2532  data_time: 0.0055  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:34 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 2719  total_loss: 0.700  loss_cls: 0.189  loss_box_reg: 0.369  loss_rpn_cls: 0.060  loss_rpn_loc: 0.045  time: 0.2532  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:39 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 2739  total_loss: 0.692  loss_cls: 0.176  loss_box_reg: 0.366  loss_rpn_cls: 0.056  loss_rpn_loc: 0.052  time: 0.2532  data_time: 0.0105  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:44 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 2759  total_loss: 0.853  loss_cls: 0.264  loss_box_reg: 0.440  loss_rpn_cls: 0.054  loss_rpn_loc: 0.036  time: 0.2532  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:49 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 2779  total_loss: 0.529  loss_cls: 0.152  loss_box_reg: 0.330  loss_rpn_cls: 0.037  loss_rpn_loc: 0.027  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:54 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 2799  total_loss: 0.744  loss_cls: 0.250  loss_box_reg: 0.398  loss_rpn_cls: 0.048  loss_rpn_loc: 0.047  time: 0.2532  data_time: 0.0355  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:22:59 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 2819  total_loss: 0.693  loss_cls: 0.163  loss_box_reg: 0.364  loss_rpn_cls: 0.043  loss_rpn_loc: 0.049  time: 0.2532  data_time: 0.0121  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:04 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 2839  total_loss: 0.720  loss_cls: 0.219  loss_box_reg: 0.349  loss_rpn_cls: 0.057  loss_rpn_loc: 0.039  time: 0.2532  data_time: 0.0086  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:09 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 2859  total_loss: 0.779  loss_cls: 0.210  loss_box_reg: 0.377  loss_rpn_cls: 0.069  loss_rpn_loc: 0.065  time: 0.2532  data_time: 0.0056  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:14 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2879  total_loss: 0.607  loss_cls: 0.149  loss_box_reg: 0.332  loss_rpn_cls: 0.040  loss_rpn_loc: 0.027  time: 0.2532  data_time: 0.0070  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:19 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2899  total_loss: 0.713  loss_cls: 0.195  loss_box_reg: 0.393  loss_rpn_cls: 0.071  loss_rpn_loc: 0.055  time: 0.2531  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:24 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 2919  total_loss: 0.618  loss_cls: 0.157  loss_box_reg: 0.373  loss_rpn_cls: 0.040  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:29 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 2939  total_loss: 0.638  loss_cls: 0.186  loss_box_reg: 0.345  loss_rpn_cls: 0.047  loss_rpn_loc: 0.041  time: 0.2531  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:34 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 2959  total_loss: 0.698  loss_cls: 0.165  loss_box_reg: 0.369  loss_rpn_cls: 0.059  loss_rpn_loc: 0.070  time: 0.2531  data_time: 0.0054  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:40 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 2979  total_loss: 0.697  loss_cls: 0.162  loss_box_reg: 0.348  loss_rpn_cls: 0.051  loss_rpn_loc: 0.041  time: 0.2531  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:45 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2999  total_loss: 0.591  loss_cls: 0.158  loss_box_reg: 0.342  loss_rpn_cls: 0.045  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0083  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:50 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 3019  total_loss: 0.751  loss_cls: 0.163  loss_box_reg: 0.426  loss_rpn_cls: 0.052  loss_rpn_loc: 0.042  time: 0.2532  data_time: 0.0130  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:23:55 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 3039  total_loss: 0.649  loss_cls: 0.209  loss_box_reg: 0.368  loss_rpn_cls: 0.035  loss_rpn_loc: 0.032  time: 0.2531  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:00 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 3059  total_loss: 0.538  loss_cls: 0.140  loss_box_reg: 0.327  loss_rpn_cls: 0.031  loss_rpn_loc: 0.032  time: 0.2532  data_time: 0.0407  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:05 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 3079  total_loss: 0.574  loss_cls: 0.138  loss_box_reg: 0.326  loss_rpn_cls: 0.044  loss_rpn_loc: 0.046  time: 0.2532  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:10 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 3099  total_loss: 0.583  loss_cls: 0.175  loss_box_reg: 0.356  loss_rpn_cls: 0.046  loss_rpn_loc: 0.038  time: 0.2532  data_time: 0.0202  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:16 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3119  total_loss: 0.651  loss_cls: 0.161  loss_box_reg: 0.368  loss_rpn_cls: 0.046  loss_rpn_loc: 0.041  time: 0.2532  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:20 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 3139  total_loss: 0.656  loss_cls: 0.164  loss_box_reg: 0.340  loss_rpn_cls: 0.074  loss_rpn_loc: 0.055  time: 0.2532  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:26 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 3159  total_loss: 0.712  loss_cls: 0.161  loss_box_reg: 0.395  loss_rpn_cls: 0.069  loss_rpn_loc: 0.060  time: 0.2532  data_time: 0.0184  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:31 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 3179  total_loss: 0.619  loss_cls: 0.154  loss_box_reg: 0.375  loss_rpn_cls: 0.049  loss_rpn_loc: 0.044  time: 0.2532  data_time: 0.0203  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:36 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 3199  total_loss: 0.701  loss_cls: 0.200  loss_box_reg: 0.338  loss_rpn_cls: 0.060  loss_rpn_loc: 0.034  time: 0.2532  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:41 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 3219  total_loss: 0.734  loss_cls: 0.258  loss_box_reg: 0.341  loss_rpn_cls: 0.061  loss_rpn_loc: 0.039  time: 0.2531  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:46 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 3239  total_loss: 0.662  loss_cls: 0.214  loss_box_reg: 0.337  loss_rpn_cls: 0.060  loss_rpn_loc: 0.034  time: 0.2532  data_time: 0.0206  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:51 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 3259  total_loss: 0.751  loss_cls: 0.201  loss_box_reg: 0.380  loss_rpn_cls: 0.053  loss_rpn_loc: 0.071  time: 0.2532  data_time: 0.0131  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:24:56 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 3279  total_loss: 0.699  loss_cls: 0.178  loss_box_reg: 0.377  loss_rpn_cls: 0.037  loss_rpn_loc: 0.060  time: 0.2532  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:01 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3299  total_loss: 0.770  loss_cls: 0.162  loss_box_reg: 0.430  loss_rpn_cls: 0.059  loss_rpn_loc: 0.046  time: 0.2531  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:06 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 3319  total_loss: 0.577  loss_cls: 0.152  loss_box_reg: 0.333  loss_rpn_cls: 0.034  loss_rpn_loc: 0.028  time: 0.2531  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:11 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 3339  total_loss: 0.643  loss_cls: 0.125  loss_box_reg: 0.339  loss_rpn_cls: 0.049  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:16 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 3359  total_loss: 0.619  loss_cls: 0.176  loss_box_reg: 0.362  loss_rpn_cls: 0.044  loss_rpn_loc: 0.037  time: 0.2530  data_time: 0.0085  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:21 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 3379  total_loss: 0.744  loss_cls: 0.154  loss_box_reg: 0.400  loss_rpn_cls: 0.064  loss_rpn_loc: 0.051  time: 0.2530  data_time: 0.0076  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:26 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 3399  total_loss: 0.797  loss_cls: 0.213  loss_box_reg: 0.407  loss_rpn_cls: 0.075  loss_rpn_loc: 0.047  time: 0.2529  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:31 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 3419  total_loss: 0.669  loss_cls: 0.165  loss_box_reg: 0.362  loss_rpn_cls: 0.065  loss_rpn_loc: 0.041  time: 0.2529  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:36 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 3439  total_loss: 0.695  loss_cls: 0.218  loss_box_reg: 0.351  loss_rpn_cls: 0.054  loss_rpn_loc: 0.036  time: 0.2529  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:41 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 3459  total_loss: 0.649  loss_cls: 0.196  loss_box_reg: 0.361  loss_rpn_cls: 0.037  loss_rpn_loc: 0.032  time: 0.2530  data_time: 0.0343  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:46 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3479  total_loss: 0.639  loss_cls: 0.163  loss_box_reg: 0.311  loss_rpn_cls: 0.053  loss_rpn_loc: 0.041  time: 0.2530  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:51 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 3499  total_loss: 0.685  loss_cls: 0.242  loss_box_reg: 0.380  loss_rpn_cls: 0.059  loss_rpn_loc: 0.065  time: 0.2530  data_time: 0.0065  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:25:56 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 3519  total_loss: 0.632  loss_cls: 0.161  loss_box_reg: 0.340  loss_rpn_cls: 0.067  loss_rpn_loc: 0.029  time: 0.2530  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:01 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 3539  total_loss: 0.664  loss_cls: 0.170  loss_box_reg: 0.356  loss_rpn_cls: 0.059  loss_rpn_loc: 0.031  time: 0.2530  data_time: 0.0154  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:06 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3559  total_loss: 0.631  loss_cls: 0.126  loss_box_reg: 0.344  loss_rpn_cls: 0.061  loss_rpn_loc: 0.050  time: 0.2529  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:11 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 3579  total_loss: 0.535  loss_cls: 0.118  loss_box_reg: 0.315  loss_rpn_cls: 0.039  loss_rpn_loc: 0.036  time: 0.2529  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:16 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 3599  total_loss: 0.627  loss_cls: 0.144  loss_box_reg: 0.352  loss_rpn_cls: 0.026  loss_rpn_loc: 0.034  time: 0.2529  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:21 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 3619  total_loss: 0.593  loss_cls: 0.179  loss_box_reg: 0.272  loss_rpn_cls: 0.036  loss_rpn_loc: 0.043  time: 0.2529  data_time: 0.0072  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:27 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3639  total_loss: 0.514  loss_cls: 0.139  loss_box_reg: 0.303  loss_rpn_cls: 0.029  loss_rpn_loc: 0.034  time: 0.2530  data_time: 0.0327  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:32 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 3659  total_loss: 0.556  loss_cls: 0.147  loss_box_reg: 0.315  loss_rpn_cls: 0.050  loss_rpn_loc: 0.049  time: 0.2530  data_time: 0.0056  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:37 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3679  total_loss: 0.759  loss_cls: 0.143  loss_box_reg: 0.420  loss_rpn_cls: 0.063  loss_rpn_loc: 0.075  time: 0.2529  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:42 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 3699  total_loss: 0.539  loss_cls: 0.135  loss_box_reg: 0.333  loss_rpn_cls: 0.043  loss_rpn_loc: 0.038  time: 0.2529  data_time: 0.0103  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:47 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 3719  total_loss: 0.702  loss_cls: 0.223  loss_box_reg: 0.351  loss_rpn_cls: 0.064  loss_rpn_loc: 0.049  time: 0.2529  data_time: 0.0056  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:52 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3739  total_loss: 0.664  loss_cls: 0.177  loss_box_reg: 0.349  loss_rpn_cls: 0.036  loss_rpn_loc: 0.037  time: 0.2529  data_time: 0.0112  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:26:57 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 3759  total_loss: 0.524  loss_cls: 0.149  loss_box_reg: 0.279  loss_rpn_cls: 0.025  loss_rpn_loc: 0.024  time: 0.2529  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:02 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 3779  total_loss: 0.575  loss_cls: 0.157  loss_box_reg: 0.355  loss_rpn_cls: 0.028  loss_rpn_loc: 0.039  time: 0.2530  data_time: 0.0333  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:07 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 3799  total_loss: 0.640  loss_cls: 0.194  loss_box_reg: 0.318  loss_rpn_cls: 0.054  loss_rpn_loc: 0.050  time: 0.2530  data_time: 0.0054  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:12 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3819  total_loss: 0.588  loss_cls: 0.127  loss_box_reg: 0.348  loss_rpn_cls: 0.041  loss_rpn_loc: 0.036  time: 0.2529  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:17 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 3839  total_loss: 0.686  loss_cls: 0.143  loss_box_reg: 0.375  loss_rpn_cls: 0.049  loss_rpn_loc: 0.051  time: 0.2529  data_time: 0.0055  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:22 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 3859  total_loss: 0.622  loss_cls: 0.135  loss_box_reg: 0.363  loss_rpn_cls: 0.045  loss_rpn_loc: 0.050  time: 0.2529  data_time: 0.0097  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:27 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 3879  total_loss: 0.790  loss_cls: 0.207  loss_box_reg: 0.397  loss_rpn_cls: 0.067  loss_rpn_loc: 0.069  time: 0.2529  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:32 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 3899  total_loss: 0.545  loss_cls: 0.146  loss_box_reg: 0.333  loss_rpn_cls: 0.032  loss_rpn_loc: 0.039  time: 0.2529  data_time: 0.0145  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:37 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3919  total_loss: 0.582  loss_cls: 0.120  loss_box_reg: 0.360  loss_rpn_cls: 0.028  loss_rpn_loc: 0.026  time: 0.2529  data_time: 0.0133  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:43 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 3939  total_loss: 0.798  loss_cls: 0.167  loss_box_reg: 0.418  loss_rpn_cls: 0.070  loss_rpn_loc: 0.090  time: 0.2530  data_time: 0.0191  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:48 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 3959  total_loss: 0.673  loss_cls: 0.188  loss_box_reg: 0.392  loss_rpn_cls: 0.062  loss_rpn_loc: 0.036  time: 0.2530  data_time: 0.0116  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:53 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 3979  total_loss: 0.654  loss_cls: 0.138  loss_box_reg: 0.319  loss_rpn_cls: 0.045  loss_rpn_loc: 0.036  time: 0.2529  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.558  loss_cls: 0.178  loss_box_reg: 0.315  loss_rpn_cls: 0.044  loss_rpn_loc: 0.057  time: 0.2530  data_time: 0.0229  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.558  loss_cls: 0.178  loss_box_reg: 0.315  loss_rpn_cls: 0.048  loss_rpn_loc: 0.052  time: 0.2530  data_time: 0.0232  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:27:59 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:16:51 (0.2531 s / it)\n",
            "\u001b[32m[05/04 01:27:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:55 (0:00:03 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_64\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:28:00 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:28:00 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 01:28:00 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| tomato_frui.. | 136          | tomato_fruit  | 57           | tomato_seed.. | 65           |\n",
            "| tomato_youn.. | 38           | tomato_flower | 51           | bell_pepper.. | 72           |\n",
            "| bell_pepper.. | 20           | bell_pepper.. | 29           | bell_pepper.. | 24           |\n",
            "| bell_pepper.. | 24           | cucumber_fl.. | 33           | cucumber_pl.. | 2            |\n",
            "| cucumber_se.. | 32           | cucumber_fr.. | 81           | cucumber_fr.. | 18           |\n",
            "|               |              |               |              |               |              |\n",
            "|     total     | 682          |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[05/04 01:28:00 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:28:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 01:28:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 01:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1449 s / img. ETA=0:00:28\n",
            "\u001b[32m[05/04 01:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 43/206. 0.1533 s / img. ETA=0:00:25\n",
            "\u001b[32m[05/04 01:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 69/206. 0.1692 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 01:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 101/206. 0.1662 s / img. ETA=0:00:17\n",
            "\u001b[32m[05/04 01:28:23 d2.evaluation.evaluator]: \u001b[0mInference done 134/206. 0.1631 s / img. ETA=0:00:11\n",
            "\u001b[32m[05/04 01:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 165/206. 0.1627 s / img. ETA=0:00:06\n",
            "\u001b[32m[05/04 01:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 200/206. 0.1590 s / img. ETA=0:00:00\n",
            "\u001b[32m[05/04 01:28:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.400168 (0.161195 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:28:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.158659 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:28:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 01:28:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_64/coco_instances_results.json\n",
            "\u001b[32m[05/04 01:28:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.627\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.538\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            "\u001b[32m[05/04 01:28:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 36.784 | 62.685 | 40.157 | 23.160 | 34.535 | 46.175 |\n",
            "\u001b[32m[05/04 01:28:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 35.858 | tomato_fruit       | 20.917 | tomato_seedling          | 31.935 |\n",
            "| tomato_young_plant      | 54.588 | tomato_flower      | 51.607 | bell_pepper_fruit        | 49.204 |\n",
            "| bell_pepper_young_plant | 30.078 | bell_pepper_flower | 38.370 | bell_pepper_fruit_unripe | 24.951 |\n",
            "| bell_pepper_seedling    | 18.030 | cucumber_flower    | 63.234 | cucumber_plant           | 11.653 |\n",
            "| cucumber_seedling       | 29.151 | cucumber_fruit     | 57.176 | cucumber_fruit_unripe    | 35.009 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_64___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_64___2.png\n",
            "\u001b[32m[05/04 01:28:36 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:28:36 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:28:36 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 01:28:36 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 01:28:36 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:28:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 01:28:36 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 01:28:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_128\n",
            "**********************************************\n",
            "\u001b[32m[05/04 01:28:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 01:28:43 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 19  total_loss: 3.464  loss_cls: 2.555  loss_box_reg: 0.679  loss_rpn_cls: 0.195  loss_rpn_loc: 0.034  time: 0.3152  data_time: 0.0194  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:28:49 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 39  total_loss: 2.550  loss_cls: 1.393  loss_box_reg: 0.736  loss_rpn_cls: 0.157  loss_rpn_loc: 0.090  time: 0.3209  data_time: 0.0058  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:28:56 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 59  total_loss: 2.087  loss_cls: 1.064  loss_box_reg: 0.742  loss_rpn_cls: 0.174  loss_rpn_loc: 0.052  time: 0.3199  data_time: 0.0063  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:02 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 79  total_loss: 2.007  loss_cls: 0.919  loss_box_reg: 0.791  loss_rpn_cls: 0.190  loss_rpn_loc: 0.062  time: 0.3211  data_time: 0.0162  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:09 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 99  total_loss: 1.818  loss_cls: 0.829  loss_box_reg: 0.713  loss_rpn_cls: 0.176  loss_rpn_loc: 0.046  time: 0.3239  data_time: 0.0214  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:15 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 119  total_loss: 1.932  loss_cls: 0.788  loss_box_reg: 0.903  loss_rpn_cls: 0.140  loss_rpn_loc: 0.072  time: 0.3242  data_time: 0.0063  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:22 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 139  total_loss: 1.746  loss_cls: 0.738  loss_box_reg: 0.781  loss_rpn_cls: 0.127  loss_rpn_loc: 0.043  time: 0.3243  data_time: 0.0059  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:28 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 159  total_loss: 1.587  loss_cls: 0.692  loss_box_reg: 0.820  loss_rpn_cls: 0.127  loss_rpn_loc: 0.052  time: 0.3240  data_time: 0.0067  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:35 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 179  total_loss: 1.705  loss_cls: 0.672  loss_box_reg: 0.825  loss_rpn_cls: 0.127  loss_rpn_loc: 0.059  time: 0.3234  data_time: 0.0068  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:42 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 199  total_loss: 1.658  loss_cls: 0.631  loss_box_reg: 0.822  loss_rpn_cls: 0.117  loss_rpn_loc: 0.054  time: 0.3244  data_time: 0.0175  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:48 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 219  total_loss: 1.527  loss_cls: 0.567  loss_box_reg: 0.772  loss_rpn_cls: 0.128  loss_rpn_loc: 0.056  time: 0.3243  data_time: 0.0061  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:29:55 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 239  total_loss: 1.305  loss_cls: 0.440  loss_box_reg: 0.677  loss_rpn_cls: 0.103  loss_rpn_loc: 0.033  time: 0.3245  data_time: 0.0081  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:01 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 259  total_loss: 1.383  loss_cls: 0.487  loss_box_reg: 0.614  loss_rpn_cls: 0.133  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0063  lr: 0.000519  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:08 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 279  total_loss: 1.368  loss_cls: 0.542  loss_box_reg: 0.602  loss_rpn_cls: 0.105  loss_rpn_loc: 0.044  time: 0.3248  data_time: 0.0062  lr: 0.000559  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:14 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 299  total_loss: 1.333  loss_cls: 0.590  loss_box_reg: 0.604  loss_rpn_cls: 0.117  loss_rpn_loc: 0.027  time: 0.3244  data_time: 0.0062  lr: 0.000599  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:21 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 319  total_loss: 1.251  loss_cls: 0.422  loss_box_reg: 0.602  loss_rpn_cls: 0.103  loss_rpn_loc: 0.049  time: 0.3267  data_time: 0.0482  lr: 0.000639  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:28 d2.utils.events]: \u001b[0m eta: 0:19:44  iter: 339  total_loss: 1.193  loss_cls: 0.473  loss_box_reg: 0.548  loss_rpn_cls: 0.117  loss_rpn_loc: 0.050  time: 0.3266  data_time: 0.0064  lr: 0.000679  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:34 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 359  total_loss: 0.932  loss_cls: 0.340  loss_box_reg: 0.458  loss_rpn_cls: 0.111  loss_rpn_loc: 0.040  time: 0.3265  data_time: 0.0061  lr: 0.000719  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:41 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 379  total_loss: 1.117  loss_cls: 0.425  loss_box_reg: 0.499  loss_rpn_cls: 0.107  loss_rpn_loc: 0.038  time: 0.3260  data_time: 0.0059  lr: 0.000759  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:47 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 399  total_loss: 1.206  loss_cls: 0.564  loss_box_reg: 0.573  loss_rpn_cls: 0.122  loss_rpn_loc: 0.049  time: 0.3262  data_time: 0.0143  lr: 0.000799  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:30:54 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 419  total_loss: 1.186  loss_cls: 0.503  loss_box_reg: 0.532  loss_rpn_cls: 0.079  loss_rpn_loc: 0.045  time: 0.3260  data_time: 0.0061  lr: 0.000839  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:00 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 439  total_loss: 1.083  loss_cls: 0.365  loss_box_reg: 0.477  loss_rpn_cls: 0.101  loss_rpn_loc: 0.050  time: 0.3257  data_time: 0.0062  lr: 0.000879  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:07 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 459  total_loss: 0.965  loss_cls: 0.357  loss_box_reg: 0.509  loss_rpn_cls: 0.080  loss_rpn_loc: 0.031  time: 0.3255  data_time: 0.0057  lr: 0.000919  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:13 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 479  total_loss: 1.204  loss_cls: 0.453  loss_box_reg: 0.572  loss_rpn_cls: 0.127  loss_rpn_loc: 0.050  time: 0.3252  data_time: 0.0069  lr: 0.000959  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:20 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 499  total_loss: 0.923  loss_cls: 0.359  loss_box_reg: 0.415  loss_rpn_cls: 0.100  loss_rpn_loc: 0.059  time: 0.3256  data_time: 0.0072  lr: 0.000999  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:26 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 519  total_loss: 1.147  loss_cls: 0.422  loss_box_reg: 0.527  loss_rpn_cls: 0.112  loss_rpn_loc: 0.034  time: 0.3255  data_time: 0.0059  lr: 0.001039  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:33 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 539  total_loss: 1.126  loss_cls: 0.407  loss_box_reg: 0.462  loss_rpn_cls: 0.085  loss_rpn_loc: 0.070  time: 0.3253  data_time: 0.0064  lr: 0.001079  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:39 d2.utils.events]: \u001b[0m eta: 0:18:32  iter: 559  total_loss: 0.938  loss_cls: 0.375  loss_box_reg: 0.444  loss_rpn_cls: 0.094  loss_rpn_loc: 0.030  time: 0.3254  data_time: 0.0153  lr: 0.001119  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:46 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 579  total_loss: 1.056  loss_cls: 0.391  loss_box_reg: 0.456  loss_rpn_cls: 0.098  loss_rpn_loc: 0.027  time: 0.3252  data_time: 0.0064  lr: 0.001159  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:52 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 599  total_loss: 1.024  loss_cls: 0.323  loss_box_reg: 0.474  loss_rpn_cls: 0.114  loss_rpn_loc: 0.081  time: 0.3251  data_time: 0.0061  lr: 0.001199  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:31:59 d2.utils.events]: \u001b[0m eta: 0:18:14  iter: 619  total_loss: 0.972  loss_cls: 0.314  loss_box_reg: 0.373  loss_rpn_cls: 0.077  loss_rpn_loc: 0.053  time: 0.3252  data_time: 0.0062  lr: 0.001239  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:05 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 639  total_loss: 0.925  loss_cls: 0.354  loss_box_reg: 0.475  loss_rpn_cls: 0.056  loss_rpn_loc: 0.048  time: 0.3251  data_time: 0.0059  lr: 0.001279  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:11 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 659  total_loss: 0.729  loss_cls: 0.229  loss_box_reg: 0.363  loss_rpn_cls: 0.068  loss_rpn_loc: 0.026  time: 0.3249  data_time: 0.0061  lr: 0.001319  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:18 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 679  total_loss: 0.963  loss_cls: 0.365  loss_box_reg: 0.460  loss_rpn_cls: 0.097  loss_rpn_loc: 0.061  time: 0.3248  data_time: 0.0066  lr: 0.001359  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:24 d2.utils.events]: \u001b[0m eta: 0:17:47  iter: 699  total_loss: 0.965  loss_cls: 0.366  loss_box_reg: 0.433  loss_rpn_cls: 0.083  loss_rpn_loc: 0.053  time: 0.3247  data_time: 0.0072  lr: 0.001399  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:31 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 719  total_loss: 1.113  loss_cls: 0.337  loss_box_reg: 0.498  loss_rpn_cls: 0.100  loss_rpn_loc: 0.044  time: 0.3244  data_time: 0.0082  lr: 0.001439  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:37 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 739  total_loss: 0.982  loss_cls: 0.285  loss_box_reg: 0.471  loss_rpn_cls: 0.117  loss_rpn_loc: 0.064  time: 0.3245  data_time: 0.0060  lr: 0.001479  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:44 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 759  total_loss: 1.091  loss_cls: 0.387  loss_box_reg: 0.487  loss_rpn_cls: 0.087  loss_rpn_loc: 0.066  time: 0.3243  data_time: 0.0062  lr: 0.001518  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:50 d2.utils.events]: \u001b[0m eta: 0:17:21  iter: 779  total_loss: 0.877  loss_cls: 0.291  loss_box_reg: 0.420  loss_rpn_cls: 0.079  loss_rpn_loc: 0.055  time: 0.3244  data_time: 0.0060  lr: 0.001558  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:32:57 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 799  total_loss: 1.002  loss_cls: 0.401  loss_box_reg: 0.442  loss_rpn_cls: 0.084  loss_rpn_loc: 0.054  time: 0.3244  data_time: 0.0066  lr: 0.001598  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:03 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 819  total_loss: 0.928  loss_cls: 0.328  loss_box_reg: 0.446  loss_rpn_cls: 0.086  loss_rpn_loc: 0.043  time: 0.3242  data_time: 0.0068  lr: 0.001638  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:10 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 839  total_loss: 1.188  loss_cls: 0.460  loss_box_reg: 0.500  loss_rpn_cls: 0.117  loss_rpn_loc: 0.060  time: 0.3243  data_time: 0.0146  lr: 0.001678  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:16 d2.utils.events]: \u001b[0m eta: 0:16:53  iter: 859  total_loss: 0.980  loss_cls: 0.350  loss_box_reg: 0.436  loss_rpn_cls: 0.079  loss_rpn_loc: 0.062  time: 0.3245  data_time: 0.0129  lr: 0.001718  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:23 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 879  total_loss: 1.158  loss_cls: 0.480  loss_box_reg: 0.520  loss_rpn_cls: 0.111  loss_rpn_loc: 0.050  time: 0.3245  data_time: 0.0093  lr: 0.001758  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:29 d2.utils.events]: \u001b[0m eta: 0:16:42  iter: 899  total_loss: 1.046  loss_cls: 0.304  loss_box_reg: 0.388  loss_rpn_cls: 0.086  loss_rpn_loc: 0.053  time: 0.3244  data_time: 0.0066  lr: 0.001798  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:36 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 919  total_loss: 0.871  loss_cls: 0.257  loss_box_reg: 0.416  loss_rpn_cls: 0.077  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0297  lr: 0.001838  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:43 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 939  total_loss: 0.979  loss_cls: 0.378  loss_box_reg: 0.440  loss_rpn_cls: 0.072  loss_rpn_loc: 0.035  time: 0.3248  data_time: 0.0052  lr: 0.001878  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:49 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 959  total_loss: 0.988  loss_cls: 0.255  loss_box_reg: 0.478  loss_rpn_cls: 0.114  loss_rpn_loc: 0.073  time: 0.3247  data_time: 0.0148  lr: 0.001918  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:33:55 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 979  total_loss: 0.836  loss_cls: 0.268  loss_box_reg: 0.400  loss_rpn_cls: 0.083  loss_rpn_loc: 0.047  time: 0.3246  data_time: 0.0076  lr: 0.001958  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:02 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 999  total_loss: 0.809  loss_cls: 0.272  loss_box_reg: 0.412  loss_rpn_cls: 0.074  loss_rpn_loc: 0.050  time: 0.3245  data_time: 0.0063  lr: 0.001998  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:08 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 1019  total_loss: 0.874  loss_cls: 0.286  loss_box_reg: 0.425  loss_rpn_cls: 0.086  loss_rpn_loc: 0.056  time: 0.3245  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:15 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 1039  total_loss: 0.911  loss_cls: 0.277  loss_box_reg: 0.449  loss_rpn_cls: 0.094  loss_rpn_loc: 0.037  time: 0.3244  data_time: 0.0065  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:21 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 1059  total_loss: 0.820  loss_cls: 0.290  loss_box_reg: 0.355  loss_rpn_cls: 0.091  loss_rpn_loc: 0.062  time: 0.3244  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:28 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 1079  total_loss: 0.907  loss_cls: 0.299  loss_box_reg: 0.456  loss_rpn_cls: 0.090  loss_rpn_loc: 0.070  time: 0.3244  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:34 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 1099  total_loss: 0.955  loss_cls: 0.425  loss_box_reg: 0.460  loss_rpn_cls: 0.061  loss_rpn_loc: 0.040  time: 0.3243  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:41 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 1119  total_loss: 1.141  loss_cls: 0.455  loss_box_reg: 0.487  loss_rpn_cls: 0.102  loss_rpn_loc: 0.068  time: 0.3243  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:47 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 1139  total_loss: 0.860  loss_cls: 0.284  loss_box_reg: 0.428  loss_rpn_cls: 0.108  loss_rpn_loc: 0.037  time: 0.3243  data_time: 0.0176  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:34:54 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 1159  total_loss: 0.776  loss_cls: 0.276  loss_box_reg: 0.432  loss_rpn_cls: 0.046  loss_rpn_loc: 0.039  time: 0.3246  data_time: 0.0279  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:01 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 1179  total_loss: 0.792  loss_cls: 0.232  loss_box_reg: 0.378  loss_rpn_cls: 0.087  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:07 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 1199  total_loss: 0.741  loss_cls: 0.247  loss_box_reg: 0.401  loss_rpn_cls: 0.084  loss_rpn_loc: 0.042  time: 0.3246  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:14 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 1219  total_loss: 0.804  loss_cls: 0.227  loss_box_reg: 0.417  loss_rpn_cls: 0.070  loss_rpn_loc: 0.055  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:20 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 1239  total_loss: 0.657  loss_cls: 0.176  loss_box_reg: 0.318  loss_rpn_cls: 0.067  loss_rpn_loc: 0.031  time: 0.3246  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:26 d2.utils.events]: \u001b[0m eta: 0:14:45  iter: 1259  total_loss: 0.792  loss_cls: 0.209  loss_box_reg: 0.380  loss_rpn_cls: 0.088  loss_rpn_loc: 0.047  time: 0.3246  data_time: 0.0092  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:33 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 1279  total_loss: 0.707  loss_cls: 0.235  loss_box_reg: 0.342  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 0.3245  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:39 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 1299  total_loss: 0.716  loss_cls: 0.254  loss_box_reg: 0.389  loss_rpn_cls: 0.064  loss_rpn_loc: 0.027  time: 0.3245  data_time: 0.0117  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:46 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 1319  total_loss: 0.823  loss_cls: 0.267  loss_box_reg: 0.387  loss_rpn_cls: 0.084  loss_rpn_loc: 0.057  time: 0.3244  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:52 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 1339  total_loss: 0.637  loss_cls: 0.167  loss_box_reg: 0.380  loss_rpn_cls: 0.051  loss_rpn_loc: 0.034  time: 0.3244  data_time: 0.0056  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:35:59 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 1359  total_loss: 0.745  loss_cls: 0.209  loss_box_reg: 0.403  loss_rpn_cls: 0.060  loss_rpn_loc: 0.043  time: 0.3244  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:05 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 1379  total_loss: 1.049  loss_cls: 0.286  loss_box_reg: 0.475  loss_rpn_cls: 0.103  loss_rpn_loc: 0.069  time: 0.3243  data_time: 0.0055  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:12 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 1399  total_loss: 0.748  loss_cls: 0.255  loss_box_reg: 0.392  loss_rpn_cls: 0.048  loss_rpn_loc: 0.036  time: 0.3243  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:18 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 1419  total_loss: 0.790  loss_cls: 0.256  loss_box_reg: 0.386  loss_rpn_cls: 0.075  loss_rpn_loc: 0.039  time: 0.3243  data_time: 0.0132  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:25 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 1439  total_loss: 1.019  loss_cls: 0.391  loss_box_reg: 0.490  loss_rpn_cls: 0.079  loss_rpn_loc: 0.053  time: 0.3243  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:31 d2.utils.events]: \u001b[0m eta: 0:13:40  iter: 1459  total_loss: 0.807  loss_cls: 0.198  loss_box_reg: 0.373  loss_rpn_cls: 0.081  loss_rpn_loc: 0.059  time: 0.3243  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:38 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 1479  total_loss: 0.729  loss_cls: 0.240  loss_box_reg: 0.363  loss_rpn_cls: 0.046  loss_rpn_loc: 0.047  time: 0.3243  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:44 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 1499  total_loss: 0.737  loss_cls: 0.258  loss_box_reg: 0.367  loss_rpn_cls: 0.078  loss_rpn_loc: 0.047  time: 0.3245  data_time: 0.0279  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:51 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 1519  total_loss: 1.056  loss_cls: 0.316  loss_box_reg: 0.434  loss_rpn_cls: 0.104  loss_rpn_loc: 0.065  time: 0.3245  data_time: 0.0095  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:36:58 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 1539  total_loss: 0.790  loss_cls: 0.246  loss_box_reg: 0.398  loss_rpn_cls: 0.064  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0391  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:04 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 1559  total_loss: 0.710  loss_cls: 0.267  loss_box_reg: 0.343  loss_rpn_cls: 0.054  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:11 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 1579  total_loss: 0.823  loss_cls: 0.276  loss_box_reg: 0.382  loss_rpn_cls: 0.091  loss_rpn_loc: 0.037  time: 0.3248  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:17 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 1599  total_loss: 0.793  loss_cls: 0.234  loss_box_reg: 0.344  loss_rpn_cls: 0.082  loss_rpn_loc: 0.053  time: 0.3247  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:24 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 1619  total_loss: 0.845  loss_cls: 0.222  loss_box_reg: 0.448  loss_rpn_cls: 0.059  loss_rpn_loc: 0.065  time: 0.3247  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:30 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 1639  total_loss: 0.885  loss_cls: 0.269  loss_box_reg: 0.413  loss_rpn_cls: 0.075  loss_rpn_loc: 0.055  time: 0.3248  data_time: 0.0187  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:37 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 1659  total_loss: 0.747  loss_cls: 0.266  loss_box_reg: 0.348  loss_rpn_cls: 0.070  loss_rpn_loc: 0.050  time: 0.3248  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:44 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1679  total_loss: 0.686  loss_cls: 0.230  loss_box_reg: 0.358  loss_rpn_cls: 0.052  loss_rpn_loc: 0.062  time: 0.3249  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:50 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1699  total_loss: 0.735  loss_cls: 0.233  loss_box_reg: 0.382  loss_rpn_cls: 0.064  loss_rpn_loc: 0.032  time: 0.3249  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:37:56 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 1719  total_loss: 0.889  loss_cls: 0.236  loss_box_reg: 0.427  loss_rpn_cls: 0.079  loss_rpn_loc: 0.046  time: 0.3248  data_time: 0.0076  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:03 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 1739  total_loss: 0.841  loss_cls: 0.192  loss_box_reg: 0.392  loss_rpn_cls: 0.057  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0082  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:09 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 1759  total_loss: 0.695  loss_cls: 0.237  loss_box_reg: 0.344  loss_rpn_cls: 0.062  loss_rpn_loc: 0.045  time: 0.3248  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:16 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 1779  total_loss: 0.621  loss_cls: 0.163  loss_box_reg: 0.380  loss_rpn_cls: 0.050  loss_rpn_loc: 0.048  time: 0.3248  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:22 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1799  total_loss: 0.715  loss_cls: 0.178  loss_box_reg: 0.361  loss_rpn_cls: 0.103  loss_rpn_loc: 0.062  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:29 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 1819  total_loss: 0.605  loss_cls: 0.195  loss_box_reg: 0.355  loss_rpn_cls: 0.062  loss_rpn_loc: 0.036  time: 0.3247  data_time: 0.0137  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:35 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 1839  total_loss: 0.719  loss_cls: 0.254  loss_box_reg: 0.438  loss_rpn_cls: 0.080  loss_rpn_loc: 0.036  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:42 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1859  total_loss: 0.852  loss_cls: 0.193  loss_box_reg: 0.406  loss_rpn_cls: 0.064  loss_rpn_loc: 0.056  time: 0.3247  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:48 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 1879  total_loss: 0.695  loss_cls: 0.235  loss_box_reg: 0.357  loss_rpn_cls: 0.066  loss_rpn_loc: 0.051  time: 0.3247  data_time: 0.0065  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:38:55 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1899  total_loss: 0.715  loss_cls: 0.193  loss_box_reg: 0.343  loss_rpn_cls: 0.072  loss_rpn_loc: 0.059  time: 0.3248  data_time: 0.0169  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:02 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 1919  total_loss: 0.591  loss_cls: 0.173  loss_box_reg: 0.329  loss_rpn_cls: 0.062  loss_rpn_loc: 0.067  time: 0.3248  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:08 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 1939  total_loss: 0.690  loss_cls: 0.169  loss_box_reg: 0.398  loss_rpn_cls: 0.033  loss_rpn_loc: 0.030  time: 0.3248  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:14 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 1959  total_loss: 0.790  loss_cls: 0.204  loss_box_reg: 0.411  loss_rpn_cls: 0.047  loss_rpn_loc: 0.059  time: 0.3247  data_time: 0.0120  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:21 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 1979  total_loss: 0.572  loss_cls: 0.181  loss_box_reg: 0.280  loss_rpn_cls: 0.042  loss_rpn_loc: 0.051  time: 0.3247  data_time: 0.0054  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:27 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 1999  total_loss: 0.670  loss_cls: 0.228  loss_box_reg: 0.340  loss_rpn_cls: 0.036  loss_rpn_loc: 0.047  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:34 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 2019  total_loss: 0.692  loss_cls: 0.214  loss_box_reg: 0.384  loss_rpn_cls: 0.046  loss_rpn_loc: 0.029  time: 0.3247  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:40 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 2039  total_loss: 0.637  loss_cls: 0.177  loss_box_reg: 0.377  loss_rpn_cls: 0.063  loss_rpn_loc: 0.049  time: 0.3247  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:47 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 2059  total_loss: 0.843  loss_cls: 0.318  loss_box_reg: 0.357  loss_rpn_cls: 0.060  loss_rpn_loc: 0.036  time: 0.3246  data_time: 0.0099  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:39:53 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 2079  total_loss: 0.714  loss_cls: 0.220  loss_box_reg: 0.376  loss_rpn_cls: 0.057  loss_rpn_loc: 0.044  time: 0.3247  data_time: 0.0070  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:00 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 2099  total_loss: 0.724  loss_cls: 0.212  loss_box_reg: 0.374  loss_rpn_cls: 0.075  loss_rpn_loc: 0.033  time: 0.3247  data_time: 0.0147  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:06 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 2119  total_loss: 0.652  loss_cls: 0.164  loss_box_reg: 0.313  loss_rpn_cls: 0.069  loss_rpn_loc: 0.045  time: 0.3247  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:13 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 2139  total_loss: 0.775  loss_cls: 0.263  loss_box_reg: 0.382  loss_rpn_cls: 0.066  loss_rpn_loc: 0.047  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:19 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 2159  total_loss: 0.620  loss_cls: 0.172  loss_box_reg: 0.346  loss_rpn_cls: 0.038  loss_rpn_loc: 0.039  time: 0.3246  data_time: 0.0094  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:26 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 2179  total_loss: 0.891  loss_cls: 0.240  loss_box_reg: 0.340  loss_rpn_cls: 0.097  loss_rpn_loc: 0.081  time: 0.3247  data_time: 0.0202  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:32 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 2199  total_loss: 0.712  loss_cls: 0.205  loss_box_reg: 0.332  loss_rpn_cls: 0.069  loss_rpn_loc: 0.043  time: 0.3247  data_time: 0.0086  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:39 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 2219  total_loss: 0.656  loss_cls: 0.219  loss_box_reg: 0.325  loss_rpn_cls: 0.052  loss_rpn_loc: 0.041  time: 0.3247  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:45 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 2239  total_loss: 0.636  loss_cls: 0.161  loss_box_reg: 0.357  loss_rpn_cls: 0.050  loss_rpn_loc: 0.043  time: 0.3246  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:52 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 2259  total_loss: 0.833  loss_cls: 0.263  loss_box_reg: 0.348  loss_rpn_cls: 0.067  loss_rpn_loc: 0.065  time: 0.3246  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:40:58 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 2279  total_loss: 0.725  loss_cls: 0.207  loss_box_reg: 0.404  loss_rpn_cls: 0.054  loss_rpn_loc: 0.034  time: 0.3246  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:05 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 2299  total_loss: 0.755  loss_cls: 0.224  loss_box_reg: 0.392  loss_rpn_cls: 0.052  loss_rpn_loc: 0.034  time: 0.3247  data_time: 0.0283  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:12 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 2319  total_loss: 0.622  loss_cls: 0.146  loss_box_reg: 0.360  loss_rpn_cls: 0.041  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:18 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 2339  total_loss: 0.489  loss_cls: 0.141  loss_box_reg: 0.303  loss_rpn_cls: 0.033  loss_rpn_loc: 0.031  time: 0.3247  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:24 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 2359  total_loss: 0.631  loss_cls: 0.165  loss_box_reg: 0.297  loss_rpn_cls: 0.065  loss_rpn_loc: 0.087  time: 0.3247  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:31 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 2379  total_loss: 0.670  loss_cls: 0.162  loss_box_reg: 0.352  loss_rpn_cls: 0.065  loss_rpn_loc: 0.053  time: 0.3248  data_time: 0.0278  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:38 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 2399  total_loss: 0.617  loss_cls: 0.138  loss_box_reg: 0.344  loss_rpn_cls: 0.036  loss_rpn_loc: 0.036  time: 0.3247  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:45 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 2419  total_loss: 0.547  loss_cls: 0.137  loss_box_reg: 0.299  loss_rpn_cls: 0.035  loss_rpn_loc: 0.031  time: 0.3249  data_time: 0.0279  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:51 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 2439  total_loss: 0.624  loss_cls: 0.152  loss_box_reg: 0.351  loss_rpn_cls: 0.051  loss_rpn_loc: 0.050  time: 0.3249  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:41:58 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 2459  total_loss: 0.656  loss_cls: 0.167  loss_box_reg: 0.329  loss_rpn_cls: 0.046  loss_rpn_loc: 0.056  time: 0.3249  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:04 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 2479  total_loss: 0.609  loss_cls: 0.161  loss_box_reg: 0.297  loss_rpn_cls: 0.049  loss_rpn_loc: 0.081  time: 0.3249  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:11 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 2499  total_loss: 0.579  loss_cls: 0.179  loss_box_reg: 0.286  loss_rpn_cls: 0.048  loss_rpn_loc: 0.068  time: 0.3250  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:18 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 2519  total_loss: 0.455  loss_cls: 0.119  loss_box_reg: 0.251  loss_rpn_cls: 0.025  loss_rpn_loc: 0.035  time: 0.3253  data_time: 0.0438  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:25 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 2539  total_loss: 0.597  loss_cls: 0.180  loss_box_reg: 0.300  loss_rpn_cls: 0.057  loss_rpn_loc: 0.055  time: 0.3253  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:31 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 2559  total_loss: 0.653  loss_cls: 0.179  loss_box_reg: 0.345  loss_rpn_cls: 0.052  loss_rpn_loc: 0.050  time: 0.3253  data_time: 0.0091  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:38 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2579  total_loss: 0.643  loss_cls: 0.197  loss_box_reg: 0.314  loss_rpn_cls: 0.052  loss_rpn_loc: 0.040  time: 0.3253  data_time: 0.0055  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:44 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2599  total_loss: 0.756  loss_cls: 0.228  loss_box_reg: 0.362  loss_rpn_cls: 0.097  loss_rpn_loc: 0.045  time: 0.3253  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:51 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 2619  total_loss: 0.679  loss_cls: 0.185  loss_box_reg: 0.355  loss_rpn_cls: 0.070  loss_rpn_loc: 0.039  time: 0.3253  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:42:57 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 2639  total_loss: 0.678  loss_cls: 0.220  loss_box_reg: 0.339  loss_rpn_cls: 0.051  loss_rpn_loc: 0.029  time: 0.3253  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:04 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 2659  total_loss: 0.844  loss_cls: 0.261  loss_box_reg: 0.348  loss_rpn_cls: 0.040  loss_rpn_loc: 0.032  time: 0.3253  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:10 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 2679  total_loss: 0.611  loss_cls: 0.181  loss_box_reg: 0.295  loss_rpn_cls: 0.064  loss_rpn_loc: 0.038  time: 0.3253  data_time: 0.0068  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:17 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2699  total_loss: 0.675  loss_cls: 0.188  loss_box_reg: 0.357  loss_rpn_cls: 0.047  loss_rpn_loc: 0.037  time: 0.3253  data_time: 0.0212  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:23 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 2719  total_loss: 0.578  loss_cls: 0.188  loss_box_reg: 0.277  loss_rpn_cls: 0.045  loss_rpn_loc: 0.043  time: 0.3253  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:30 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2739  total_loss: 0.601  loss_cls: 0.170  loss_box_reg: 0.316  loss_rpn_cls: 0.065  loss_rpn_loc: 0.037  time: 0.3253  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:36 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 2759  total_loss: 0.643  loss_cls: 0.148  loss_box_reg: 0.307  loss_rpn_cls: 0.073  loss_rpn_loc: 0.055  time: 0.3253  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:43 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2779  total_loss: 0.675  loss_cls: 0.189  loss_box_reg: 0.332  loss_rpn_cls: 0.070  loss_rpn_loc: 0.035  time: 0.3253  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:49 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 2799  total_loss: 0.630  loss_cls: 0.182  loss_box_reg: 0.310  loss_rpn_cls: 0.032  loss_rpn_loc: 0.033  time: 0.3252  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:43:56 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 2819  total_loss: 0.607  loss_cls: 0.192  loss_box_reg: 0.302  loss_rpn_cls: 0.042  loss_rpn_loc: 0.040  time: 0.3252  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:02 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 2839  total_loss: 0.696  loss_cls: 0.190  loss_box_reg: 0.315  loss_rpn_cls: 0.063  loss_rpn_loc: 0.072  time: 0.3252  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:09 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2859  total_loss: 0.653  loss_cls: 0.182  loss_box_reg: 0.321  loss_rpn_cls: 0.048  loss_rpn_loc: 0.059  time: 0.3252  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:15 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 2879  total_loss: 0.718  loss_cls: 0.201  loss_box_reg: 0.369  loss_rpn_cls: 0.074  loss_rpn_loc: 0.049  time: 0.3251  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:22 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 2899  total_loss: 0.609  loss_cls: 0.202  loss_box_reg: 0.359  loss_rpn_cls: 0.037  loss_rpn_loc: 0.026  time: 0.3251  data_time: 0.0092  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:28 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 2919  total_loss: 0.738  loss_cls: 0.253  loss_box_reg: 0.392  loss_rpn_cls: 0.060  loss_rpn_loc: 0.031  time: 0.3251  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:34 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 2939  total_loss: 0.777  loss_cls: 0.263  loss_box_reg: 0.366  loss_rpn_cls: 0.078  loss_rpn_loc: 0.050  time: 0.3250  data_time: 0.0083  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:41 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 2959  total_loss: 0.584  loss_cls: 0.135  loss_box_reg: 0.299  loss_rpn_cls: 0.045  loss_rpn_loc: 0.043  time: 0.3250  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:47 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2979  total_loss: 0.612  loss_cls: 0.151  loss_box_reg: 0.300  loss_rpn_cls: 0.065  loss_rpn_loc: 0.048  time: 0.3250  data_time: 0.0073  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:44:54 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 2999  total_loss: 0.614  loss_cls: 0.142  loss_box_reg: 0.307  loss_rpn_cls: 0.048  loss_rpn_loc: 0.044  time: 0.3250  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:00 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 3019  total_loss: 0.606  loss_cls: 0.159  loss_box_reg: 0.287  loss_rpn_cls: 0.058  loss_rpn_loc: 0.039  time: 0.3249  data_time: 0.0069  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:07 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 3039  total_loss: 0.614  loss_cls: 0.140  loss_box_reg: 0.314  loss_rpn_cls: 0.056  loss_rpn_loc: 0.039  time: 0.3250  data_time: 0.0190  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:13 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 3059  total_loss: 0.774  loss_cls: 0.221  loss_box_reg: 0.370  loss_rpn_cls: 0.058  loss_rpn_loc: 0.050  time: 0.3250  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:20 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 3079  total_loss: 0.550  loss_cls: 0.119  loss_box_reg: 0.321  loss_rpn_cls: 0.048  loss_rpn_loc: 0.037  time: 0.3250  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:26 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 3099  total_loss: 0.704  loss_cls: 0.164  loss_box_reg: 0.339  loss_rpn_cls: 0.057  loss_rpn_loc: 0.051  time: 0.3249  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:33 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 3119  total_loss: 0.562  loss_cls: 0.167  loss_box_reg: 0.291  loss_rpn_cls: 0.044  loss_rpn_loc: 0.059  time: 0.3249  data_time: 0.0067  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:39 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 3139  total_loss: 0.569  loss_cls: 0.158  loss_box_reg: 0.307  loss_rpn_cls: 0.054  loss_rpn_loc: 0.061  time: 0.3250  data_time: 0.0113  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:46 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 3159  total_loss: 0.518  loss_cls: 0.105  loss_box_reg: 0.263  loss_rpn_cls: 0.043  loss_rpn_loc: 0.035  time: 0.3250  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:52 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 3179  total_loss: 0.684  loss_cls: 0.178  loss_box_reg: 0.325  loss_rpn_cls: 0.054  loss_rpn_loc: 0.043  time: 0.3250  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:45:59 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 3199  total_loss: 0.516  loss_cls: 0.159  loss_box_reg: 0.256  loss_rpn_cls: 0.042  loss_rpn_loc: 0.036  time: 0.3249  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:05 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 3219  total_loss: 0.576  loss_cls: 0.117  loss_box_reg: 0.328  loss_rpn_cls: 0.041  loss_rpn_loc: 0.059  time: 0.3249  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:12 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 3239  total_loss: 0.530  loss_cls: 0.166  loss_box_reg: 0.283  loss_rpn_cls: 0.034  loss_rpn_loc: 0.029  time: 0.3249  data_time: 0.0114  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:18 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 3259  total_loss: 0.566  loss_cls: 0.144  loss_box_reg: 0.289  loss_rpn_cls: 0.050  loss_rpn_loc: 0.037  time: 0.3250  data_time: 0.0182  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:25 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 3279  total_loss: 0.650  loss_cls: 0.147  loss_box_reg: 0.309  loss_rpn_cls: 0.035  loss_rpn_loc: 0.046  time: 0.3250  data_time: 0.0065  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:31 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3299  total_loss: 0.561  loss_cls: 0.143  loss_box_reg: 0.285  loss_rpn_cls: 0.034  loss_rpn_loc: 0.044  time: 0.3250  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:38 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 3319  total_loss: 0.544  loss_cls: 0.143  loss_box_reg: 0.313  loss_rpn_cls: 0.033  loss_rpn_loc: 0.034  time: 0.3250  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:45 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3339  total_loss: 0.491  loss_cls: 0.131  loss_box_reg: 0.321  loss_rpn_cls: 0.035  loss_rpn_loc: 0.033  time: 0.3251  data_time: 0.0320  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:51 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 3359  total_loss: 0.626  loss_cls: 0.213  loss_box_reg: 0.305  loss_rpn_cls: 0.069  loss_rpn_loc: 0.059  time: 0.3251  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:46:58 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 3379  total_loss: 0.498  loss_cls: 0.103  loss_box_reg: 0.280  loss_rpn_cls: 0.039  loss_rpn_loc: 0.042  time: 0.3251  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:04 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 3399  total_loss: 0.612  loss_cls: 0.148  loss_box_reg: 0.296  loss_rpn_cls: 0.057  loss_rpn_loc: 0.040  time: 0.3251  data_time: 0.0108  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:11 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 3419  total_loss: 0.671  loss_cls: 0.142  loss_box_reg: 0.328  loss_rpn_cls: 0.087  loss_rpn_loc: 0.051  time: 0.3250  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:17 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 3439  total_loss: 0.635  loss_cls: 0.188  loss_box_reg: 0.335  loss_rpn_cls: 0.041  loss_rpn_loc: 0.033  time: 0.3250  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:24 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3459  total_loss: 0.511  loss_cls: 0.140  loss_box_reg: 0.305  loss_rpn_cls: 0.037  loss_rpn_loc: 0.039  time: 0.3250  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:30 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 3479  total_loss: 0.598  loss_cls: 0.142  loss_box_reg: 0.309  loss_rpn_cls: 0.050  loss_rpn_loc: 0.034  time: 0.3250  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:37 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 3499  total_loss: 0.590  loss_cls: 0.172  loss_box_reg: 0.307  loss_rpn_cls: 0.036  loss_rpn_loc: 0.039  time: 0.3250  data_time: 0.0117  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:43 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 3519  total_loss: 0.532  loss_cls: 0.158  loss_box_reg: 0.284  loss_rpn_cls: 0.037  loss_rpn_loc: 0.040  time: 0.3250  data_time: 0.0059  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:50 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3539  total_loss: 0.542  loss_cls: 0.117  loss_box_reg: 0.252  loss_rpn_cls: 0.050  loss_rpn_loc: 0.066  time: 0.3250  data_time: 0.0073  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:47:57 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 3559  total_loss: 0.518  loss_cls: 0.141  loss_box_reg: 0.263  loss_rpn_cls: 0.043  loss_rpn_loc: 0.041  time: 0.3251  data_time: 0.0178  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:03 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3579  total_loss: 0.706  loss_cls: 0.175  loss_box_reg: 0.327  loss_rpn_cls: 0.050  loss_rpn_loc: 0.045  time: 0.3251  data_time: 0.0058  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:10 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3599  total_loss: 0.511  loss_cls: 0.125  loss_box_reg: 0.310  loss_rpn_cls: 0.023  loss_rpn_loc: 0.023  time: 0.3251  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:16 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3619  total_loss: 0.436  loss_cls: 0.115  loss_box_reg: 0.285  loss_rpn_cls: 0.034  loss_rpn_loc: 0.039  time: 0.3251  data_time: 0.0173  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:23 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 3639  total_loss: 0.460  loss_cls: 0.090  loss_box_reg: 0.293  loss_rpn_cls: 0.042  loss_rpn_loc: 0.032  time: 0.3251  data_time: 0.0057  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:29 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3659  total_loss: 0.489  loss_cls: 0.129  loss_box_reg: 0.264  loss_rpn_cls: 0.053  loss_rpn_loc: 0.038  time: 0.3250  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:36 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 3679  total_loss: 0.588  loss_cls: 0.129  loss_box_reg: 0.285  loss_rpn_cls: 0.052  loss_rpn_loc: 0.070  time: 0.3251  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:42 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3699  total_loss: 0.658  loss_cls: 0.225  loss_box_reg: 0.298  loss_rpn_cls: 0.043  loss_rpn_loc: 0.054  time: 0.3251  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:49 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 3719  total_loss: 0.615  loss_cls: 0.165  loss_box_reg: 0.314  loss_rpn_cls: 0.044  loss_rpn_loc: 0.038  time: 0.3251  data_time: 0.0271  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:48:55 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3739  total_loss: 0.507  loss_cls: 0.119  loss_box_reg: 0.302  loss_rpn_cls: 0.064  loss_rpn_loc: 0.045  time: 0.3251  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:02 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 3759  total_loss: 0.595  loss_cls: 0.181  loss_box_reg: 0.344  loss_rpn_cls: 0.029  loss_rpn_loc: 0.027  time: 0.3251  data_time: 0.0172  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:08 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 3779  total_loss: 0.486  loss_cls: 0.125  loss_box_reg: 0.255  loss_rpn_cls: 0.033  loss_rpn_loc: 0.043  time: 0.3251  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:15 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3799  total_loss: 0.533  loss_cls: 0.095  loss_box_reg: 0.276  loss_rpn_cls: 0.033  loss_rpn_loc: 0.038  time: 0.3250  data_time: 0.0055  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:21 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 3819  total_loss: 0.651  loss_cls: 0.161  loss_box_reg: 0.283  loss_rpn_cls: 0.044  loss_rpn_loc: 0.043  time: 0.3250  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:28 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3839  total_loss: 0.510  loss_cls: 0.151  loss_box_reg: 0.296  loss_rpn_cls: 0.032  loss_rpn_loc: 0.038  time: 0.3250  data_time: 0.0168  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:34 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3859  total_loss: 0.603  loss_cls: 0.172  loss_box_reg: 0.315  loss_rpn_cls: 0.058  loss_rpn_loc: 0.042  time: 0.3250  data_time: 0.0061  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:41 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 3879  total_loss: 0.525  loss_cls: 0.127  loss_box_reg: 0.276  loss_rpn_cls: 0.025  loss_rpn_loc: 0.032  time: 0.3250  data_time: 0.0062  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:47 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 3899  total_loss: 0.479  loss_cls: 0.115  loss_box_reg: 0.281  loss_rpn_cls: 0.046  loss_rpn_loc: 0.030  time: 0.3250  data_time: 0.0060  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:49:53 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 3919  total_loss: 0.498  loss_cls: 0.108  loss_box_reg: 0.278  loss_rpn_cls: 0.044  loss_rpn_loc: 0.044  time: 0.3249  data_time: 0.0063  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:00 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3939  total_loss: 0.516  loss_cls: 0.122  loss_box_reg: 0.298  loss_rpn_cls: 0.028  loss_rpn_loc: 0.047  time: 0.3249  data_time: 0.0102  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:06 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 3959  total_loss: 0.566  loss_cls: 0.130  loss_box_reg: 0.329  loss_rpn_cls: 0.032  loss_rpn_loc: 0.025  time: 0.3250  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:13 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 3979  total_loss: 0.603  loss_cls: 0.137  loss_box_reg: 0.315  loss_rpn_cls: 0.039  loss_rpn_loc: 0.041  time: 0.3250  data_time: 0.0150  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.476  loss_cls: 0.133  loss_box_reg: 0.311  loss_rpn_cls: 0.027  loss_rpn_loc: 0.033  time: 0.3250  data_time: 0.0066  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:20 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.480  loss_cls: 0.152  loss_box_reg: 0.311  loss_rpn_cls: 0.029  loss_rpn_loc: 0.033  time: 0.3249  data_time: 0.0064  lr: 0.002000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:50:21 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:21:39 (0.3250 s / it)\n",
            "\u001b[32m[05/04 01:50:21 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:43 (0:00:03 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_128\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:50:21 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:50:21 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 01:50:21 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:50:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 01:50:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 01:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1593 s / img. ETA=0:00:31\n",
            "\u001b[32m[05/04 01:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 40/206. 0.1704 s / img. ETA=0:00:28\n",
            "\u001b[32m[05/04 01:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 65/206. 0.1839 s / img. ETA=0:00:26\n",
            "\u001b[32m[05/04 01:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 93/206. 0.1816 s / img. ETA=0:00:20\n",
            "\u001b[32m[05/04 01:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 119/206. 0.1839 s / img. ETA=0:00:16\n",
            "\u001b[32m[05/04 01:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 149/206. 0.1807 s / img. ETA=0:00:10\n",
            "\u001b[32m[05/04 01:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 178/206. 0.1793 s / img. ETA=0:00:05\n",
            "\u001b[32m[05/04 01:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.035813 (0.179283 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.177028 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 01:50:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 01:50:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_128/coco_instances_results.json\n",
            "\u001b[32m[05/04 01:50:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.547\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.574\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.376\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            "\u001b[32m[05/04 01:51:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.259 | 61.882 | 45.073 | 19.622 | 33.896 | 50.648 |\n",
            "\u001b[32m[05/04 01:51:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 40.422 | tomato_fruit       | 16.206 | tomato_seedling          | 28.144 |\n",
            "| tomato_young_plant      | 51.363 | tomato_flower      | 52.758 | bell_pepper_fruit        | 57.018 |\n",
            "| bell_pepper_young_plant | 38.858 | bell_pepper_flower | 38.643 | bell_pepper_fruit_unripe | 22.395 |\n",
            "| bell_pepper_seedling    | 22.193 | cucumber_flower    | 63.548 | cucumber_plant           | 18.965 |\n",
            "| cucumber_seedling       | 28.706 | cucumber_fruit     | 59.288 | cucumber_fruit_unripe    | 50.373 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_128___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.002_128___2.png\n",
            "Saving results...\n",
            "Saved /content/drive/My Drive/Green Thumbs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_05-03-2020_21:04.json\n",
            "\u001b[32m[05/04 01:51:01 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 01:51:01 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 01:51:01 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 01:51:01 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 01:51:01 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 01:51:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 01:51:01 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 01:51:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_64\n",
            "**********************************************\n",
            "\u001b[32m[05/04 01:51:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 01:51:06 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 19  total_loss: 4.000  loss_cls: 2.757  loss_box_reg: 0.896  loss_rpn_cls: 0.237  loss_rpn_loc: 0.059  time: 0.2542  data_time: 0.0163  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:11 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 39  total_loss: 3.500  loss_cls: 2.224  loss_box_reg: 0.994  loss_rpn_cls: 0.180  loss_rpn_loc: 0.078  time: 0.2493  data_time: 0.0061  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:17 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 59  total_loss: 2.468  loss_cls: 1.325  loss_box_reg: 0.896  loss_rpn_cls: 0.178  loss_rpn_loc: 0.046  time: 0.2538  data_time: 0.0120  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:22 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 79  total_loss: 2.325  loss_cls: 1.070  loss_box_reg: 0.960  loss_rpn_cls: 0.181  loss_rpn_loc: 0.041  time: 0.2552  data_time: 0.0238  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:27 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 99  total_loss: 2.308  loss_cls: 1.095  loss_box_reg: 0.952  loss_rpn_cls: 0.180  loss_rpn_loc: 0.055  time: 0.2544  data_time: 0.0058  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:32 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 119  total_loss: 2.205  loss_cls: 1.021  loss_box_reg: 0.954  loss_rpn_cls: 0.163  loss_rpn_loc: 0.076  time: 0.2556  data_time: 0.0132  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:37 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 139  total_loss: 2.118  loss_cls: 0.941  loss_box_reg: 0.923  loss_rpn_cls: 0.192  loss_rpn_loc: 0.045  time: 0.2550  data_time: 0.0061  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:42 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 159  total_loss: 1.972  loss_cls: 0.878  loss_box_reg: 0.879  loss_rpn_cls: 0.168  loss_rpn_loc: 0.052  time: 0.2551  data_time: 0.0058  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:47 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 179  total_loss: 1.941  loss_cls: 0.868  loss_box_reg: 0.904  loss_rpn_cls: 0.113  loss_rpn_loc: 0.035  time: 0.2540  data_time: 0.0062  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:52 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 199  total_loss: 2.010  loss_cls: 0.848  loss_box_reg: 0.906  loss_rpn_cls: 0.139  loss_rpn_loc: 0.038  time: 0.2541  data_time: 0.0056  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:51:58 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 219  total_loss: 1.969  loss_cls: 0.775  loss_box_reg: 0.941  loss_rpn_cls: 0.138  loss_rpn_loc: 0.057  time: 0.2557  data_time: 0.0355  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:03 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 239  total_loss: 1.682  loss_cls: 0.643  loss_box_reg: 0.864  loss_rpn_cls: 0.112  loss_rpn_loc: 0.034  time: 0.2564  data_time: 0.0223  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:08 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 259  total_loss: 1.854  loss_cls: 0.785  loss_box_reg: 0.872  loss_rpn_cls: 0.126  loss_rpn_loc: 0.046  time: 0.2558  data_time: 0.0065  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:13 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 279  total_loss: 1.533  loss_cls: 0.490  loss_box_reg: 0.850  loss_rpn_cls: 0.111  loss_rpn_loc: 0.040  time: 0.2554  data_time: 0.0060  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:18 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 299  total_loss: 1.718  loss_cls: 0.679  loss_box_reg: 0.885  loss_rpn_cls: 0.148  loss_rpn_loc: 0.068  time: 0.2552  data_time: 0.0088  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:23 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 319  total_loss: 1.694  loss_cls: 0.648  loss_box_reg: 0.849  loss_rpn_cls: 0.133  loss_rpn_loc: 0.062  time: 0.2548  data_time: 0.0070  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:28 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 339  total_loss: 1.602  loss_cls: 0.603  loss_box_reg: 0.820  loss_rpn_cls: 0.117  loss_rpn_loc: 0.038  time: 0.2542  data_time: 0.0058  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:33 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 359  total_loss: 1.469  loss_cls: 0.567  loss_box_reg: 0.783  loss_rpn_cls: 0.106  loss_rpn_loc: 0.034  time: 0.2541  data_time: 0.0064  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:39 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 379  total_loss: 1.546  loss_cls: 0.634  loss_box_reg: 0.765  loss_rpn_cls: 0.122  loss_rpn_loc: 0.045  time: 0.2552  data_time: 0.0361  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:44 d2.utils.events]: \u001b[0m eta: 0:15:06  iter: 399  total_loss: 1.452  loss_cls: 0.551  loss_box_reg: 0.716  loss_rpn_cls: 0.088  loss_rpn_loc: 0.045  time: 0.2551  data_time: 0.0059  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:49 d2.utils.events]: \u001b[0m eta: 0:15:00  iter: 419  total_loss: 1.486  loss_cls: 0.580  loss_box_reg: 0.638  loss_rpn_cls: 0.112  loss_rpn_loc: 0.060  time: 0.2547  data_time: 0.0055  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:54 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 439  total_loss: 1.288  loss_cls: 0.498  loss_box_reg: 0.584  loss_rpn_cls: 0.113  loss_rpn_loc: 0.076  time: 0.2542  data_time: 0.0063  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:52:58 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 459  total_loss: 1.273  loss_cls: 0.484  loss_box_reg: 0.659  loss_rpn_cls: 0.124  loss_rpn_loc: 0.072  time: 0.2538  data_time: 0.0056  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:04 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 479  total_loss: 1.314  loss_cls: 0.451  loss_box_reg: 0.541  loss_rpn_cls: 0.135  loss_rpn_loc: 0.069  time: 0.2540  data_time: 0.0211  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:09 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 499  total_loss: 1.238  loss_cls: 0.506  loss_box_reg: 0.568  loss_rpn_cls: 0.129  loss_rpn_loc: 0.059  time: 0.2538  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:14 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 519  total_loss: 1.243  loss_cls: 0.516  loss_box_reg: 0.586  loss_rpn_cls: 0.095  loss_rpn_loc: 0.039  time: 0.2536  data_time: 0.0093  lr: 0.000519  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:19 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 539  total_loss: 1.163  loss_cls: 0.285  loss_box_reg: 0.538  loss_rpn_cls: 0.135  loss_rpn_loc: 0.064  time: 0.2536  data_time: 0.0062  lr: 0.000539  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:24 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 559  total_loss: 1.081  loss_cls: 0.412  loss_box_reg: 0.566  loss_rpn_cls: 0.105  loss_rpn_loc: 0.044  time: 0.2537  data_time: 0.0209  lr: 0.000559  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:29 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 579  total_loss: 0.980  loss_cls: 0.338  loss_box_reg: 0.552  loss_rpn_cls: 0.074  loss_rpn_loc: 0.024  time: 0.2536  data_time: 0.0055  lr: 0.000579  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:34 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 599  total_loss: 1.128  loss_cls: 0.448  loss_box_reg: 0.525  loss_rpn_cls: 0.092  loss_rpn_loc: 0.045  time: 0.2532  data_time: 0.0060  lr: 0.000599  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:39 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 619  total_loss: 1.041  loss_cls: 0.396  loss_box_reg: 0.534  loss_rpn_cls: 0.067  loss_rpn_loc: 0.040  time: 0.2532  data_time: 0.0058  lr: 0.000619  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:44 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 639  total_loss: 1.139  loss_cls: 0.402  loss_box_reg: 0.505  loss_rpn_cls: 0.094  loss_rpn_loc: 0.068  time: 0.2532  data_time: 0.0057  lr: 0.000639  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:49 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 659  total_loss: 1.116  loss_cls: 0.398  loss_box_reg: 0.499  loss_rpn_cls: 0.124  loss_rpn_loc: 0.039  time: 0.2531  data_time: 0.0092  lr: 0.000659  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:54 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 679  total_loss: 1.044  loss_cls: 0.315  loss_box_reg: 0.500  loss_rpn_cls: 0.086  loss_rpn_loc: 0.061  time: 0.2529  data_time: 0.0090  lr: 0.000679  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:53:59 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 699  total_loss: 1.007  loss_cls: 0.337  loss_box_reg: 0.488  loss_rpn_cls: 0.077  loss_rpn_loc: 0.057  time: 0.2528  data_time: 0.0059  lr: 0.000699  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:05 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 719  total_loss: 1.055  loss_cls: 0.404  loss_box_reg: 0.511  loss_rpn_cls: 0.106  loss_rpn_loc: 0.048  time: 0.2536  data_time: 0.0486  lr: 0.000719  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:09 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 739  total_loss: 1.119  loss_cls: 0.407  loss_box_reg: 0.482  loss_rpn_cls: 0.099  loss_rpn_loc: 0.058  time: 0.2534  data_time: 0.0056  lr: 0.000739  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:15 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 759  total_loss: 1.016  loss_cls: 0.371  loss_box_reg: 0.578  loss_rpn_cls: 0.060  loss_rpn_loc: 0.047  time: 0.2535  data_time: 0.0063  lr: 0.000759  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:20 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 779  total_loss: 1.096  loss_cls: 0.341  loss_box_reg: 0.598  loss_rpn_cls: 0.098  loss_rpn_loc: 0.046  time: 0.2535  data_time: 0.0061  lr: 0.000779  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:25 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 799  total_loss: 0.831  loss_cls: 0.264  loss_box_reg: 0.456  loss_rpn_cls: 0.080  loss_rpn_loc: 0.055  time: 0.2534  data_time: 0.0077  lr: 0.000799  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:30 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 819  total_loss: 1.217  loss_cls: 0.366  loss_box_reg: 0.526  loss_rpn_cls: 0.092  loss_rpn_loc: 0.040  time: 0.2533  data_time: 0.0065  lr: 0.000819  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:35 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 839  total_loss: 0.987  loss_cls: 0.316  loss_box_reg: 0.533  loss_rpn_cls: 0.103  loss_rpn_loc: 0.069  time: 0.2534  data_time: 0.0063  lr: 0.000839  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:40 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 859  total_loss: 1.056  loss_cls: 0.464  loss_box_reg: 0.496  loss_rpn_cls: 0.096  loss_rpn_loc: 0.030  time: 0.2536  data_time: 0.0284  lr: 0.000859  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:45 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 879  total_loss: 1.175  loss_cls: 0.505  loss_box_reg: 0.530  loss_rpn_cls: 0.111  loss_rpn_loc: 0.046  time: 0.2535  data_time: 0.0055  lr: 0.000879  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:50 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 899  total_loss: 1.071  loss_cls: 0.400  loss_box_reg: 0.482  loss_rpn_cls: 0.107  loss_rpn_loc: 0.051  time: 0.2533  data_time: 0.0085  lr: 0.000899  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:54:55 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 919  total_loss: 0.945  loss_cls: 0.345  loss_box_reg: 0.475  loss_rpn_cls: 0.068  loss_rpn_loc: 0.054  time: 0.2533  data_time: 0.0070  lr: 0.000919  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:00 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 939  total_loss: 0.960  loss_cls: 0.313  loss_box_reg: 0.473  loss_rpn_cls: 0.081  loss_rpn_loc: 0.069  time: 0.2533  data_time: 0.0059  lr: 0.000939  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:05 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 959  total_loss: 1.241  loss_cls: 0.408  loss_box_reg: 0.569  loss_rpn_cls: 0.108  loss_rpn_loc: 0.060  time: 0.2533  data_time: 0.0066  lr: 0.000959  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:10 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 979  total_loss: 1.036  loss_cls: 0.380  loss_box_reg: 0.503  loss_rpn_cls: 0.114  loss_rpn_loc: 0.060  time: 0.2533  data_time: 0.0061  lr: 0.000979  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:16 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 999  total_loss: 1.004  loss_cls: 0.323  loss_box_reg: 0.434  loss_rpn_cls: 0.077  loss_rpn_loc: 0.048  time: 0.2538  data_time: 0.0327  lr: 0.000999  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:21 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1019  total_loss: 1.029  loss_cls: 0.374  loss_box_reg: 0.491  loss_rpn_cls: 0.081  loss_rpn_loc: 0.039  time: 0.2535  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:26 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1039  total_loss: 1.110  loss_cls: 0.402  loss_box_reg: 0.542  loss_rpn_cls: 0.095  loss_rpn_loc: 0.049  time: 0.2535  data_time: 0.0087  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:31 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 1059  total_loss: 0.922  loss_cls: 0.350  loss_box_reg: 0.462  loss_rpn_cls: 0.060  loss_rpn_loc: 0.035  time: 0.2535  data_time: 0.0173  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:36 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1079  total_loss: 0.953  loss_cls: 0.273  loss_box_reg: 0.463  loss_rpn_cls: 0.090  loss_rpn_loc: 0.037  time: 0.2539  data_time: 0.0339  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:41 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1099  total_loss: 0.948  loss_cls: 0.288  loss_box_reg: 0.490  loss_rpn_cls: 0.083  loss_rpn_loc: 0.028  time: 0.2538  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:47 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 1119  total_loss: 0.972  loss_cls: 0.376  loss_box_reg: 0.481  loss_rpn_cls: 0.076  loss_rpn_loc: 0.051  time: 0.2539  data_time: 0.0056  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:52 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 1139  total_loss: 1.079  loss_cls: 0.378  loss_box_reg: 0.470  loss_rpn_cls: 0.086  loss_rpn_loc: 0.068  time: 0.2539  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:55:57 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1159  total_loss: 0.874  loss_cls: 0.228  loss_box_reg: 0.401  loss_rpn_cls: 0.085  loss_rpn_loc: 0.037  time: 0.2539  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:02 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 1179  total_loss: 0.905  loss_cls: 0.315  loss_box_reg: 0.452  loss_rpn_cls: 0.083  loss_rpn_loc: 0.044  time: 0.2538  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:07 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 1199  total_loss: 0.760  loss_cls: 0.181  loss_box_reg: 0.439  loss_rpn_cls: 0.069  loss_rpn_loc: 0.037  time: 0.2537  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:12 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1219  total_loss: 0.912  loss_cls: 0.288  loss_box_reg: 0.505  loss_rpn_cls: 0.098  loss_rpn_loc: 0.051  time: 0.2537  data_time: 0.0214  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:17 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1239  total_loss: 0.820  loss_cls: 0.216  loss_box_reg: 0.442  loss_rpn_cls: 0.084  loss_rpn_loc: 0.022  time: 0.2537  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:22 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 1259  total_loss: 0.850  loss_cls: 0.265  loss_box_reg: 0.379  loss_rpn_cls: 0.080  loss_rpn_loc: 0.045  time: 0.2536  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:27 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 1279  total_loss: 0.841  loss_cls: 0.240  loss_box_reg: 0.400  loss_rpn_cls: 0.073  loss_rpn_loc: 0.046  time: 0.2535  data_time: 0.0055  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:32 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 1299  total_loss: 1.033  loss_cls: 0.370  loss_box_reg: 0.466  loss_rpn_cls: 0.072  loss_rpn_loc: 0.093  time: 0.2534  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:37 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 1319  total_loss: 0.744  loss_cls: 0.210  loss_box_reg: 0.388  loss_rpn_cls: 0.057  loss_rpn_loc: 0.035  time: 0.2533  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:42 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 1339  total_loss: 0.929  loss_cls: 0.281  loss_box_reg: 0.406  loss_rpn_cls: 0.075  loss_rpn_loc: 0.058  time: 0.2537  data_time: 0.0352  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:47 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1359  total_loss: 0.911  loss_cls: 0.315  loss_box_reg: 0.486  loss_rpn_cls: 0.086  loss_rpn_loc: 0.043  time: 0.2536  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:52 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1379  total_loss: 0.662  loss_cls: 0.218  loss_box_reg: 0.372  loss_rpn_cls: 0.039  loss_rpn_loc: 0.028  time: 0.2536  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:56:57 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 1399  total_loss: 0.899  loss_cls: 0.281  loss_box_reg: 0.453  loss_rpn_cls: 0.082  loss_rpn_loc: 0.059  time: 0.2536  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:03 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 1419  total_loss: 0.778  loss_cls: 0.230  loss_box_reg: 0.384  loss_rpn_cls: 0.054  loss_rpn_loc: 0.034  time: 0.2537  data_time: 0.0140  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:08 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 1439  total_loss: 0.909  loss_cls: 0.297  loss_box_reg: 0.449  loss_rpn_cls: 0.056  loss_rpn_loc: 0.038  time: 0.2536  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:13 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1459  total_loss: 0.761  loss_cls: 0.241  loss_box_reg: 0.419  loss_rpn_cls: 0.058  loss_rpn_loc: 0.047  time: 0.2536  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:18 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 1479  total_loss: 0.959  loss_cls: 0.353  loss_box_reg: 0.460  loss_rpn_cls: 0.065  loss_rpn_loc: 0.044  time: 0.2536  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:23 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1499  total_loss: 0.780  loss_cls: 0.238  loss_box_reg: 0.485  loss_rpn_cls: 0.067  loss_rpn_loc: 0.053  time: 0.2536  data_time: 0.0147  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:28 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 1519  total_loss: 0.896  loss_cls: 0.266  loss_box_reg: 0.434  loss_rpn_cls: 0.071  loss_rpn_loc: 0.074  time: 0.2535  data_time: 0.0116  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:33 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 1539  total_loss: 0.941  loss_cls: 0.272  loss_box_reg: 0.455  loss_rpn_cls: 0.065  loss_rpn_loc: 0.033  time: 0.2535  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:38 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 1559  total_loss: 0.730  loss_cls: 0.263  loss_box_reg: 0.378  loss_rpn_cls: 0.052  loss_rpn_loc: 0.031  time: 0.2534  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:43 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 1579  total_loss: 0.744  loss_cls: 0.216  loss_box_reg: 0.437  loss_rpn_cls: 0.063  loss_rpn_loc: 0.033  time: 0.2534  data_time: 0.0114  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:48 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 1599  total_loss: 0.842  loss_cls: 0.302  loss_box_reg: 0.432  loss_rpn_cls: 0.084  loss_rpn_loc: 0.073  time: 0.2533  data_time: 0.0076  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:53 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 1619  total_loss: 0.779  loss_cls: 0.261  loss_box_reg: 0.425  loss_rpn_cls: 0.070  loss_rpn_loc: 0.039  time: 0.2534  data_time: 0.0208  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:57:58 d2.utils.events]: \u001b[0m eta: 0:09:52  iter: 1639  total_loss: 0.912  loss_cls: 0.271  loss_box_reg: 0.446  loss_rpn_cls: 0.108  loss_rpn_loc: 0.079  time: 0.2534  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:03 d2.utils.events]: \u001b[0m eta: 0:09:47  iter: 1659  total_loss: 0.864  loss_cls: 0.307  loss_box_reg: 0.415  loss_rpn_cls: 0.073  loss_rpn_loc: 0.051  time: 0.2533  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:08 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 1679  total_loss: 0.830  loss_cls: 0.266  loss_box_reg: 0.402  loss_rpn_cls: 0.065  loss_rpn_loc: 0.054  time: 0.2533  data_time: 0.0087  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:14 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 1699  total_loss: 0.855  loss_cls: 0.289  loss_box_reg: 0.461  loss_rpn_cls: 0.061  loss_rpn_loc: 0.033  time: 0.2536  data_time: 0.0367  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:19 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 1719  total_loss: 0.780  loss_cls: 0.192  loss_box_reg: 0.431  loss_rpn_cls: 0.072  loss_rpn_loc: 0.038  time: 0.2535  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:24 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1739  total_loss: 0.889  loss_cls: 0.253  loss_box_reg: 0.398  loss_rpn_cls: 0.093  loss_rpn_loc: 0.047  time: 0.2535  data_time: 0.0128  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:29 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 1759  total_loss: 0.801  loss_cls: 0.259  loss_box_reg: 0.396  loss_rpn_cls: 0.071  loss_rpn_loc: 0.051  time: 0.2535  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:34 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 1779  total_loss: 0.791  loss_cls: 0.249  loss_box_reg: 0.387  loss_rpn_cls: 0.062  loss_rpn_loc: 0.044  time: 0.2534  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:39 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 1799  total_loss: 0.774  loss_cls: 0.263  loss_box_reg: 0.384  loss_rpn_cls: 0.069  loss_rpn_loc: 0.051  time: 0.2534  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:44 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1819  total_loss: 0.620  loss_cls: 0.189  loss_box_reg: 0.379  loss_rpn_cls: 0.052  loss_rpn_loc: 0.024  time: 0.2534  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:49 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1839  total_loss: 0.761  loss_cls: 0.263  loss_box_reg: 0.361  loss_rpn_cls: 0.052  loss_rpn_loc: 0.046  time: 0.2534  data_time: 0.0073  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:58:54 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1859  total_loss: 0.681  loss_cls: 0.169  loss_box_reg: 0.396  loss_rpn_cls: 0.042  loss_rpn_loc: 0.036  time: 0.2534  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:00 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1879  total_loss: 0.748  loss_cls: 0.176  loss_box_reg: 0.394  loss_rpn_cls: 0.059  loss_rpn_loc: 0.039  time: 0.2536  data_time: 0.0419  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:05 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 1899  total_loss: 0.746  loss_cls: 0.207  loss_box_reg: 0.409  loss_rpn_cls: 0.059  loss_rpn_loc: 0.040  time: 0.2537  data_time: 0.0225  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:10 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1919  total_loss: 0.566  loss_cls: 0.167  loss_box_reg: 0.346  loss_rpn_cls: 0.035  loss_rpn_loc: 0.046  time: 0.2536  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:15 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1939  total_loss: 0.758  loss_cls: 0.193  loss_box_reg: 0.372  loss_rpn_cls: 0.062  loss_rpn_loc: 0.040  time: 0.2536  data_time: 0.0114  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:20 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 1959  total_loss: 0.906  loss_cls: 0.289  loss_box_reg: 0.456  loss_rpn_cls: 0.081  loss_rpn_loc: 0.065  time: 0.2535  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:25 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1979  total_loss: 0.779  loss_cls: 0.223  loss_box_reg: 0.375  loss_rpn_cls: 0.068  loss_rpn_loc: 0.035  time: 0.2535  data_time: 0.0055  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:30 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1999  total_loss: 0.790  loss_cls: 0.266  loss_box_reg: 0.425  loss_rpn_cls: 0.069  loss_rpn_loc: 0.048  time: 0.2534  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:35 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 2019  total_loss: 0.719  loss_cls: 0.214  loss_box_reg: 0.361  loss_rpn_cls: 0.062  loss_rpn_loc: 0.037  time: 0.2534  data_time: 0.0080  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:40 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 2039  total_loss: 0.622  loss_cls: 0.174  loss_box_reg: 0.307  loss_rpn_cls: 0.047  loss_rpn_loc: 0.051  time: 0.2532  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:45 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 2059  total_loss: 0.784  loss_cls: 0.186  loss_box_reg: 0.419  loss_rpn_cls: 0.063  loss_rpn_loc: 0.069  time: 0.2532  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:49 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 2079  total_loss: 0.754  loss_cls: 0.210  loss_box_reg: 0.380  loss_rpn_cls: 0.054  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 01:59:54 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 2099  total_loss: 0.827  loss_cls: 0.251  loss_box_reg: 0.398  loss_rpn_cls: 0.067  loss_rpn_loc: 0.053  time: 0.2531  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:00 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 2119  total_loss: 0.870  loss_cls: 0.352  loss_box_reg: 0.403  loss_rpn_cls: 0.071  loss_rpn_loc: 0.036  time: 0.2531  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:04 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 2139  total_loss: 0.597  loss_cls: 0.158  loss_box_reg: 0.343  loss_rpn_cls: 0.050  loss_rpn_loc: 0.035  time: 0.2530  data_time: 0.0096  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:09 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 2159  total_loss: 0.789  loss_cls: 0.232  loss_box_reg: 0.404  loss_rpn_cls: 0.056  loss_rpn_loc: 0.052  time: 0.2530  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:15 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2179  total_loss: 0.720  loss_cls: 0.186  loss_box_reg: 0.394  loss_rpn_cls: 0.043  loss_rpn_loc: 0.062  time: 0.2530  data_time: 0.0080  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:20 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 2199  total_loss: 0.839  loss_cls: 0.245  loss_box_reg: 0.456  loss_rpn_cls: 0.073  loss_rpn_loc: 0.051  time: 0.2530  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:25 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 2219  total_loss: 0.748  loss_cls: 0.255  loss_box_reg: 0.405  loss_rpn_cls: 0.055  loss_rpn_loc: 0.023  time: 0.2531  data_time: 0.0230  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:31 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 2239  total_loss: 0.826  loss_cls: 0.226  loss_box_reg: 0.403  loss_rpn_cls: 0.047  loss_rpn_loc: 0.023  time: 0.2534  data_time: 0.0357  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:36 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 2259  total_loss: 0.858  loss_cls: 0.300  loss_box_reg: 0.415  loss_rpn_cls: 0.074  loss_rpn_loc: 0.054  time: 0.2534  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:41 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 2279  total_loss: 0.721  loss_cls: 0.194  loss_box_reg: 0.349  loss_rpn_cls: 0.064  loss_rpn_loc: 0.047  time: 0.2533  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:46 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 2299  total_loss: 0.655  loss_cls: 0.185  loss_box_reg: 0.359  loss_rpn_cls: 0.056  loss_rpn_loc: 0.039  time: 0.2533  data_time: 0.0086  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:51 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2319  total_loss: 0.783  loss_cls: 0.261  loss_box_reg: 0.388  loss_rpn_cls: 0.041  loss_rpn_loc: 0.054  time: 0.2534  data_time: 0.0132  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:00:56 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 2339  total_loss: 0.726  loss_cls: 0.223  loss_box_reg: 0.394  loss_rpn_cls: 0.060  loss_rpn_loc: 0.045  time: 0.2534  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:01 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 2359  total_loss: 0.770  loss_cls: 0.203  loss_box_reg: 0.392  loss_rpn_cls: 0.059  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:06 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 2379  total_loss: 0.714  loss_cls: 0.159  loss_box_reg: 0.373  loss_rpn_cls: 0.055  loss_rpn_loc: 0.050  time: 0.2533  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:11 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 2399  total_loss: 0.709  loss_cls: 0.192  loss_box_reg: 0.362  loss_rpn_cls: 0.055  loss_rpn_loc: 0.048  time: 0.2533  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:16 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2419  total_loss: 0.731  loss_cls: 0.171  loss_box_reg: 0.403  loss_rpn_cls: 0.055  loss_rpn_loc: 0.041  time: 0.2533  data_time: 0.0083  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:21 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 2439  total_loss: 0.670  loss_cls: 0.164  loss_box_reg: 0.384  loss_rpn_cls: 0.043  loss_rpn_loc: 0.051  time: 0.2532  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:27 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 2459  total_loss: 0.769  loss_cls: 0.198  loss_box_reg: 0.392  loss_rpn_cls: 0.082  loss_rpn_loc: 0.071  time: 0.2536  data_time: 0.0528  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:32 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 2479  total_loss: 0.680  loss_cls: 0.224  loss_box_reg: 0.391  loss_rpn_cls: 0.064  loss_rpn_loc: 0.052  time: 0.2536  data_time: 0.0113  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:37 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2499  total_loss: 0.654  loss_cls: 0.154  loss_box_reg: 0.348  loss_rpn_cls: 0.051  loss_rpn_loc: 0.030  time: 0.2535  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:42 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 2519  total_loss: 0.671  loss_cls: 0.211  loss_box_reg: 0.357  loss_rpn_cls: 0.048  loss_rpn_loc: 0.048  time: 0.2535  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:47 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 2539  total_loss: 0.612  loss_cls: 0.125  loss_box_reg: 0.341  loss_rpn_cls: 0.028  loss_rpn_loc: 0.048  time: 0.2535  data_time: 0.0116  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:52 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2559  total_loss: 0.662  loss_cls: 0.183  loss_box_reg: 0.328  loss_rpn_cls: 0.047  loss_rpn_loc: 0.029  time: 0.2535  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:01:58 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 2579  total_loss: 0.724  loss_cls: 0.236  loss_box_reg: 0.365  loss_rpn_cls: 0.059  loss_rpn_loc: 0.048  time: 0.2536  data_time: 0.0303  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:03 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 2599  total_loss: 0.544  loss_cls: 0.117  loss_box_reg: 0.308  loss_rpn_cls: 0.048  loss_rpn_loc: 0.038  time: 0.2536  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:08 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 2619  total_loss: 0.784  loss_cls: 0.241  loss_box_reg: 0.376  loss_rpn_cls: 0.054  loss_rpn_loc: 0.034  time: 0.2536  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:13 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 2639  total_loss: 0.704  loss_cls: 0.184  loss_box_reg: 0.400  loss_rpn_cls: 0.053  loss_rpn_loc: 0.057  time: 0.2536  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:18 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 2659  total_loss: 0.759  loss_cls: 0.223  loss_box_reg: 0.442  loss_rpn_cls: 0.060  loss_rpn_loc: 0.044  time: 0.2535  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:23 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2679  total_loss: 0.717  loss_cls: 0.188  loss_box_reg: 0.366  loss_rpn_cls: 0.057  loss_rpn_loc: 0.065  time: 0.2535  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:29 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 2699  total_loss: 0.599  loss_cls: 0.187  loss_box_reg: 0.337  loss_rpn_cls: 0.032  loss_rpn_loc: 0.024  time: 0.2537  data_time: 0.0408  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:33 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 2719  total_loss: 0.596  loss_cls: 0.187  loss_box_reg: 0.357  loss_rpn_cls: 0.039  loss_rpn_loc: 0.034  time: 0.2537  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:38 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 2739  total_loss: 0.651  loss_cls: 0.208  loss_box_reg: 0.349  loss_rpn_cls: 0.034  loss_rpn_loc: 0.040  time: 0.2536  data_time: 0.0120  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:44 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 2759  total_loss: 0.521  loss_cls: 0.161  loss_box_reg: 0.328  loss_rpn_cls: 0.040  loss_rpn_loc: 0.036  time: 0.2536  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:49 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 2779  total_loss: 0.741  loss_cls: 0.192  loss_box_reg: 0.404  loss_rpn_cls: 0.051  loss_rpn_loc: 0.038  time: 0.2537  data_time: 0.0206  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:54 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 2799  total_loss: 0.815  loss_cls: 0.210  loss_box_reg: 0.392  loss_rpn_cls: 0.071  loss_rpn_loc: 0.070  time: 0.2536  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:02:59 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2819  total_loss: 0.631  loss_cls: 0.134  loss_box_reg: 0.359  loss_rpn_cls: 0.040  loss_rpn_loc: 0.032  time: 0.2536  data_time: 0.0055  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:04 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 2839  total_loss: 0.575  loss_cls: 0.125  loss_box_reg: 0.364  loss_rpn_cls: 0.029  loss_rpn_loc: 0.032  time: 0.2536  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:09 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 2859  total_loss: 0.734  loss_cls: 0.254  loss_box_reg: 0.389  loss_rpn_cls: 0.044  loss_rpn_loc: 0.036  time: 0.2536  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:14 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2879  total_loss: 0.666  loss_cls: 0.182  loss_box_reg: 0.321  loss_rpn_cls: 0.070  loss_rpn_loc: 0.048  time: 0.2535  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:19 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2899  total_loss: 0.744  loss_cls: 0.195  loss_box_reg: 0.418  loss_rpn_cls: 0.054  loss_rpn_loc: 0.064  time: 0.2535  data_time: 0.0131  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:24 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 2919  total_loss: 0.592  loss_cls: 0.145  loss_box_reg: 0.368  loss_rpn_cls: 0.034  loss_rpn_loc: 0.034  time: 0.2535  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:29 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 2939  total_loss: 0.608  loss_cls: 0.132  loss_box_reg: 0.362  loss_rpn_cls: 0.055  loss_rpn_loc: 0.049  time: 0.2535  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:34 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2959  total_loss: 0.700  loss_cls: 0.198  loss_box_reg: 0.373  loss_rpn_cls: 0.050  loss_rpn_loc: 0.061  time: 0.2535  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:39 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 2979  total_loss: 0.641  loss_cls: 0.125  loss_box_reg: 0.362  loss_rpn_cls: 0.047  loss_rpn_loc: 0.050  time: 0.2534  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:44 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 2999  total_loss: 0.655  loss_cls: 0.168  loss_box_reg: 0.289  loss_rpn_cls: 0.063  loss_rpn_loc: 0.051  time: 0.2534  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:49 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 3019  total_loss: 0.658  loss_cls: 0.144  loss_box_reg: 0.377  loss_rpn_cls: 0.070  loss_rpn_loc: 0.048  time: 0.2535  data_time: 0.0140  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:54 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 3039  total_loss: 0.736  loss_cls: 0.230  loss_box_reg: 0.360  loss_rpn_cls: 0.046  loss_rpn_loc: 0.050  time: 0.2535  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:03:59 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 3059  total_loss: 0.581  loss_cls: 0.129  loss_box_reg: 0.322  loss_rpn_cls: 0.035  loss_rpn_loc: 0.031  time: 0.2534  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:04 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 3079  total_loss: 0.804  loss_cls: 0.294  loss_box_reg: 0.393  loss_rpn_cls: 0.065  loss_rpn_loc: 0.052  time: 0.2534  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:09 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3099  total_loss: 0.573  loss_cls: 0.162  loss_box_reg: 0.325  loss_rpn_cls: 0.033  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:14 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 3119  total_loss: 0.554  loss_cls: 0.149  loss_box_reg: 0.290  loss_rpn_cls: 0.032  loss_rpn_loc: 0.039  time: 0.2533  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:19 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 3139  total_loss: 0.722  loss_cls: 0.184  loss_box_reg: 0.333  loss_rpn_cls: 0.038  loss_rpn_loc: 0.031  time: 0.2533  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:24 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 3159  total_loss: 0.684  loss_cls: 0.193  loss_box_reg: 0.320  loss_rpn_cls: 0.044  loss_rpn_loc: 0.038  time: 0.2533  data_time: 0.0180  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:29 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 3179  total_loss: 0.714  loss_cls: 0.180  loss_box_reg: 0.402  loss_rpn_cls: 0.050  loss_rpn_loc: 0.044  time: 0.2533  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:35 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 3199  total_loss: 0.654  loss_cls: 0.162  loss_box_reg: 0.330  loss_rpn_cls: 0.034  loss_rpn_loc: 0.038  time: 0.2535  data_time: 0.0404  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:40 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 3219  total_loss: 0.686  loss_cls: 0.148  loss_box_reg: 0.358  loss_rpn_cls: 0.052  loss_rpn_loc: 0.051  time: 0.2535  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:45 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 3239  total_loss: 0.589  loss_cls: 0.151  loss_box_reg: 0.329  loss_rpn_cls: 0.064  loss_rpn_loc: 0.037  time: 0.2534  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:50 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 3259  total_loss: 0.600  loss_cls: 0.118  loss_box_reg: 0.278  loss_rpn_cls: 0.033  loss_rpn_loc: 0.043  time: 0.2535  data_time: 0.0206  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:04:55 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 3279  total_loss: 0.447  loss_cls: 0.106  loss_box_reg: 0.275  loss_rpn_cls: 0.040  loss_rpn_loc: 0.035  time: 0.2534  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:00 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 3299  total_loss: 0.649  loss_cls: 0.133  loss_box_reg: 0.342  loss_rpn_cls: 0.062  loss_rpn_loc: 0.043  time: 0.2534  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:05 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 3319  total_loss: 0.724  loss_cls: 0.172  loss_box_reg: 0.388  loss_rpn_cls: 0.053  loss_rpn_loc: 0.049  time: 0.2534  data_time: 0.0160  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:10 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 3339  total_loss: 0.561  loss_cls: 0.124  loss_box_reg: 0.301  loss_rpn_cls: 0.033  loss_rpn_loc: 0.030  time: 0.2534  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:16 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 3359  total_loss: 0.675  loss_cls: 0.155  loss_box_reg: 0.381  loss_rpn_cls: 0.048  loss_rpn_loc: 0.045  time: 0.2535  data_time: 0.0221  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:21 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 3379  total_loss: 0.742  loss_cls: 0.248  loss_box_reg: 0.372  loss_rpn_cls: 0.082  loss_rpn_loc: 0.044  time: 0.2535  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:26 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 3399  total_loss: 0.687  loss_cls: 0.148  loss_box_reg: 0.375  loss_rpn_cls: 0.057  loss_rpn_loc: 0.069  time: 0.2535  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:31 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 3419  total_loss: 0.673  loss_cls: 0.143  loss_box_reg: 0.346  loss_rpn_cls: 0.056  loss_rpn_loc: 0.035  time: 0.2536  data_time: 0.0293  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:36 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 3439  total_loss: 0.682  loss_cls: 0.240  loss_box_reg: 0.316  loss_rpn_cls: 0.054  loss_rpn_loc: 0.059  time: 0.2536  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:41 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3459  total_loss: 0.741  loss_cls: 0.298  loss_box_reg: 0.335  loss_rpn_cls: 0.066  loss_rpn_loc: 0.047  time: 0.2535  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:46 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 3479  total_loss: 0.666  loss_cls: 0.164  loss_box_reg: 0.349  loss_rpn_cls: 0.039  loss_rpn_loc: 0.039  time: 0.2535  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:51 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 3499  total_loss: 0.711  loss_cls: 0.186  loss_box_reg: 0.340  loss_rpn_cls: 0.063  loss_rpn_loc: 0.046  time: 0.2535  data_time: 0.0140  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:05:56 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 3519  total_loss: 0.504  loss_cls: 0.119  loss_box_reg: 0.293  loss_rpn_cls: 0.043  loss_rpn_loc: 0.032  time: 0.2535  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:02 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 3539  total_loss: 0.603  loss_cls: 0.163  loss_box_reg: 0.335  loss_rpn_cls: 0.041  loss_rpn_loc: 0.054  time: 0.2536  data_time: 0.0227  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:07 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3559  total_loss: 0.528  loss_cls: 0.099  loss_box_reg: 0.304  loss_rpn_cls: 0.025  loss_rpn_loc: 0.041  time: 0.2535  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:12 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 3579  total_loss: 0.563  loss_cls: 0.139  loss_box_reg: 0.315  loss_rpn_cls: 0.029  loss_rpn_loc: 0.024  time: 0.2535  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:17 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 3599  total_loss: 0.695  loss_cls: 0.216  loss_box_reg: 0.393  loss_rpn_cls: 0.079  loss_rpn_loc: 0.028  time: 0.2535  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:22 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 3619  total_loss: 0.522  loss_cls: 0.152  loss_box_reg: 0.306  loss_rpn_cls: 0.024  loss_rpn_loc: 0.028  time: 0.2534  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:27 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3639  total_loss: 0.536  loss_cls: 0.126  loss_box_reg: 0.301  loss_rpn_cls: 0.029  loss_rpn_loc: 0.028  time: 0.2534  data_time: 0.0083  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:32 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 3659  total_loss: 0.674  loss_cls: 0.154  loss_box_reg: 0.363  loss_rpn_cls: 0.069  loss_rpn_loc: 0.018  time: 0.2534  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:37 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3679  total_loss: 0.569  loss_cls: 0.139  loss_box_reg: 0.301  loss_rpn_cls: 0.039  loss_rpn_loc: 0.042  time: 0.2534  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:42 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 3699  total_loss: 0.532  loss_cls: 0.132  loss_box_reg: 0.321  loss_rpn_cls: 0.055  loss_rpn_loc: 0.059  time: 0.2534  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:47 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 3719  total_loss: 0.626  loss_cls: 0.139  loss_box_reg: 0.323  loss_rpn_cls: 0.038  loss_rpn_loc: 0.042  time: 0.2535  data_time: 0.0455  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:52 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3739  total_loss: 0.571  loss_cls: 0.135  loss_box_reg: 0.370  loss_rpn_cls: 0.049  loss_rpn_loc: 0.050  time: 0.2535  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:06:57 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 3759  total_loss: 0.696  loss_cls: 0.192  loss_box_reg: 0.388  loss_rpn_cls: 0.063  loss_rpn_loc: 0.050  time: 0.2535  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:02 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 3779  total_loss: 0.659  loss_cls: 0.194  loss_box_reg: 0.361  loss_rpn_cls: 0.042  loss_rpn_loc: 0.028  time: 0.2535  data_time: 0.0092  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:07 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 3799  total_loss: 0.687  loss_cls: 0.197  loss_box_reg: 0.334  loss_rpn_cls: 0.048  loss_rpn_loc: 0.040  time: 0.2535  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:12 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3819  total_loss: 0.669  loss_cls: 0.183  loss_box_reg: 0.299  loss_rpn_cls: 0.066  loss_rpn_loc: 0.069  time: 0.2534  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:17 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 3839  total_loss: 0.568  loss_cls: 0.177  loss_box_reg: 0.323  loss_rpn_cls: 0.042  loss_rpn_loc: 0.049  time: 0.2534  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:22 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 3859  total_loss: 0.517  loss_cls: 0.125  loss_box_reg: 0.294  loss_rpn_cls: 0.045  loss_rpn_loc: 0.048  time: 0.2534  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:27 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 3879  total_loss: 0.651  loss_cls: 0.165  loss_box_reg: 0.306  loss_rpn_cls: 0.049  loss_rpn_loc: 0.037  time: 0.2533  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:32 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 3899  total_loss: 0.633  loss_cls: 0.170  loss_box_reg: 0.329  loss_rpn_cls: 0.046  loss_rpn_loc: 0.042  time: 0.2533  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:38 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3919  total_loss: 0.607  loss_cls: 0.189  loss_box_reg: 0.322  loss_rpn_cls: 0.028  loss_rpn_loc: 0.027  time: 0.2534  data_time: 0.0378  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:43 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 3939  total_loss: 0.611  loss_cls: 0.153  loss_box_reg: 0.306  loss_rpn_cls: 0.023  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0103  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:48 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 3959  total_loss: 0.607  loss_cls: 0.169  loss_box_reg: 0.330  loss_rpn_cls: 0.031  loss_rpn_loc: 0.048  time: 0.2534  data_time: 0.0054  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:53 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 3979  total_loss: 0.654  loss_cls: 0.190  loss_box_reg: 0.338  loss_rpn_cls: 0.054  loss_rpn_loc: 0.061  time: 0.2534  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.522  loss_cls: 0.131  loss_box_reg: 0.289  loss_rpn_cls: 0.033  loss_rpn_loc: 0.037  time: 0.2534  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.522  loss_cls: 0.111  loss_box_reg: 0.295  loss_rpn_cls: 0.033  loss_rpn_loc: 0.037  time: 0.2534  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:07:59 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:16:53 (0.2534 s / it)\n",
            "\u001b[32m[05/04 02:07:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:57 (0:00:03 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_64\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:08:00 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:08:00 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 02:08:00 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:08:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 02:08:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 02:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1323 s / img. ETA=0:00:26\n",
            "\u001b[32m[05/04 02:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 45/206. 0.1434 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 02:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 71/206. 0.1610 s / img. ETA=0:00:22\n",
            "\u001b[32m[05/04 02:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 103/206. 0.1596 s / img. ETA=0:00:16\n",
            "\u001b[32m[05/04 02:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 138/206. 0.1560 s / img. ETA=0:00:10\n",
            "\u001b[32m[05/04 02:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 171/206. 0.1550 s / img. ETA=0:00:05\n",
            "\u001b[32m[05/04 02:08:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.953608 (0.153998 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:08:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.151185 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:08:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 02:08:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_64/coco_instances_results.json\n",
            "\u001b[32m[05/04 02:08:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.86s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.606\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.420\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.301\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.563\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
            "\u001b[32m[05/04 02:08:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 37.651 | 60.602 | 41.956 | 23.253 | 34.912 | 44.463 |\n",
            "\u001b[32m[05/04 02:08:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 37.647 | tomato_fruit       | 27.205 | tomato_seedling          | 32.203 |\n",
            "| tomato_young_plant      | 36.313 | tomato_flower      | 48.407 | bell_pepper_fruit        | 59.540 |\n",
            "| bell_pepper_young_plant | 27.565 | bell_pepper_flower | 35.322 | bell_pepper_fruit_unripe | 25.595 |\n",
            "| bell_pepper_seedling    | 19.446 | cucumber_flower    | 58.335 | cucumber_plant           | 29.868 |\n",
            "| cucumber_seedling       | 31.752 | cucumber_fruit     | 54.855 | cucumber_fruit_unripe    | 40.720 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_64___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_64___2.png\n",
            "\u001b[32m[05/04 02:08:34 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:08:34 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:08:34 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 02:08:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 02:08:34 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:08:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 02:08:34 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 02:08:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128\n",
            "**********************************************\n",
            "\u001b[32m[05/04 02:08:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 02:08:41 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 19  total_loss: 3.674  loss_cls: 2.760  loss_box_reg: 0.666  loss_rpn_cls: 0.170  loss_rpn_loc: 0.042  time: 0.3508  data_time: 0.0396  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:08:48 d2.utils.events]: \u001b[0m eta: 0:21:26  iter: 39  total_loss: 3.207  loss_cls: 2.171  loss_box_reg: 0.813  loss_rpn_cls: 0.213  loss_rpn_loc: 0.073  time: 0.3358  data_time: 0.0065  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:08:55 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 59  total_loss: 2.229  loss_cls: 1.143  loss_box_reg: 0.731  loss_rpn_cls: 0.181  loss_rpn_loc: 0.057  time: 0.3357  data_time: 0.0230  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:01 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 79  total_loss: 2.022  loss_cls: 0.969  loss_box_reg: 0.769  loss_rpn_cls: 0.207  loss_rpn_loc: 0.066  time: 0.3324  data_time: 0.0062  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:08 d2.utils.events]: \u001b[0m eta: 0:21:01  iter: 99  total_loss: 1.798  loss_cls: 0.838  loss_box_reg: 0.690  loss_rpn_cls: 0.176  loss_rpn_loc: 0.059  time: 0.3300  data_time: 0.0060  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:14 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 119  total_loss: 2.102  loss_cls: 1.016  loss_box_reg: 0.843  loss_rpn_cls: 0.195  loss_rpn_loc: 0.045  time: 0.3294  data_time: 0.0061  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:21 d2.utils.events]: \u001b[0m eta: 0:20:53  iter: 139  total_loss: 1.928  loss_cls: 0.877  loss_box_reg: 0.805  loss_rpn_cls: 0.187  loss_rpn_loc: 0.074  time: 0.3292  data_time: 0.0061  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:27 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 159  total_loss: 1.837  loss_cls: 0.809  loss_box_reg: 0.746  loss_rpn_cls: 0.152  loss_rpn_loc: 0.078  time: 0.3302  data_time: 0.0186  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:34 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 179  total_loss: 1.770  loss_cls: 0.765  loss_box_reg: 0.780  loss_rpn_cls: 0.161  loss_rpn_loc: 0.072  time: 0.3299  data_time: 0.0064  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:41 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 199  total_loss: 1.773  loss_cls: 0.736  loss_box_reg: 0.803  loss_rpn_cls: 0.161  loss_rpn_loc: 0.058  time: 0.3296  data_time: 0.0098  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:47 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 219  total_loss: 1.810  loss_cls: 0.731  loss_box_reg: 0.799  loss_rpn_cls: 0.149  loss_rpn_loc: 0.035  time: 0.3292  data_time: 0.0057  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:09:53 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 239  total_loss: 1.717  loss_cls: 0.734  loss_box_reg: 0.842  loss_rpn_cls: 0.127  loss_rpn_loc: 0.036  time: 0.3281  data_time: 0.0059  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:00 d2.utils.events]: \u001b[0m eta: 0:20:16  iter: 259  total_loss: 1.550  loss_cls: 0.655  loss_box_reg: 0.759  loss_rpn_cls: 0.117  loss_rpn_loc: 0.036  time: 0.3282  data_time: 0.0144  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:07 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 279  total_loss: 1.675  loss_cls: 0.593  loss_box_reg: 0.803  loss_rpn_cls: 0.128  loss_rpn_loc: 0.041  time: 0.3279  data_time: 0.0066  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:13 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 299  total_loss: 1.575  loss_cls: 0.636  loss_box_reg: 0.803  loss_rpn_cls: 0.134  loss_rpn_loc: 0.044  time: 0.3269  data_time: 0.0056  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:19 d2.utils.events]: \u001b[0m eta: 0:19:50  iter: 319  total_loss: 1.376  loss_cls: 0.537  loss_box_reg: 0.735  loss_rpn_cls: 0.118  loss_rpn_loc: 0.044  time: 0.3261  data_time: 0.0061  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:26 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 339  total_loss: 1.423  loss_cls: 0.560  loss_box_reg: 0.675  loss_rpn_cls: 0.134  loss_rpn_loc: 0.050  time: 0.3260  data_time: 0.0074  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:32 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 359  total_loss: 1.300  loss_cls: 0.486  loss_box_reg: 0.659  loss_rpn_cls: 0.122  loss_rpn_loc: 0.062  time: 0.3260  data_time: 0.0066  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:39 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 379  total_loss: 1.178  loss_cls: 0.499  loss_box_reg: 0.606  loss_rpn_cls: 0.104  loss_rpn_loc: 0.026  time: 0.3259  data_time: 0.0121  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:45 d2.utils.events]: \u001b[0m eta: 0:19:25  iter: 399  total_loss: 1.331  loss_cls: 0.494  loss_box_reg: 0.611  loss_rpn_cls: 0.111  loss_rpn_loc: 0.066  time: 0.3258  data_time: 0.0056  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:52 d2.utils.events]: \u001b[0m eta: 0:19:19  iter: 419  total_loss: 1.312  loss_cls: 0.519  loss_box_reg: 0.643  loss_rpn_cls: 0.103  loss_rpn_loc: 0.042  time: 0.3256  data_time: 0.0063  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:10:58 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 439  total_loss: 1.287  loss_cls: 0.561  loss_box_reg: 0.583  loss_rpn_cls: 0.080  loss_rpn_loc: 0.036  time: 0.3262  data_time: 0.0170  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:05 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 459  total_loss: 1.377  loss_cls: 0.538  loss_box_reg: 0.598  loss_rpn_cls: 0.115  loss_rpn_loc: 0.078  time: 0.3260  data_time: 0.0078  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:11 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 479  total_loss: 1.190  loss_cls: 0.452  loss_box_reg: 0.590  loss_rpn_cls: 0.093  loss_rpn_loc: 0.043  time: 0.3257  data_time: 0.0064  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:18 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 499  total_loss: 0.949  loss_cls: 0.354  loss_box_reg: 0.501  loss_rpn_cls: 0.095  loss_rpn_loc: 0.039  time: 0.3259  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:24 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 519  total_loss: 1.086  loss_cls: 0.360  loss_box_reg: 0.508  loss_rpn_cls: 0.103  loss_rpn_loc: 0.038  time: 0.3261  data_time: 0.0062  lr: 0.000519  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:31 d2.utils.events]: \u001b[0m eta: 0:18:41  iter: 539  total_loss: 1.078  loss_cls: 0.456  loss_box_reg: 0.501  loss_rpn_cls: 0.116  loss_rpn_loc: 0.050  time: 0.3258  data_time: 0.0061  lr: 0.000539  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:37 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 559  total_loss: 0.967  loss_cls: 0.374  loss_box_reg: 0.464  loss_rpn_cls: 0.097  loss_rpn_loc: 0.042  time: 0.3256  data_time: 0.0075  lr: 0.000559  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:44 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 579  total_loss: 0.921  loss_cls: 0.342  loss_box_reg: 0.472  loss_rpn_cls: 0.097  loss_rpn_loc: 0.043  time: 0.3256  data_time: 0.0060  lr: 0.000579  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:50 d2.utils.events]: \u001b[0m eta: 0:18:22  iter: 599  total_loss: 1.152  loss_cls: 0.461  loss_box_reg: 0.501  loss_rpn_cls: 0.097  loss_rpn_loc: 0.048  time: 0.3254  data_time: 0.0061  lr: 0.000599  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:11:57 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 619  total_loss: 0.913  loss_cls: 0.303  loss_box_reg: 0.414  loss_rpn_cls: 0.085  loss_rpn_loc: 0.030  time: 0.3255  data_time: 0.0054  lr: 0.000619  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:03 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 639  total_loss: 0.767  loss_cls: 0.272  loss_box_reg: 0.378  loss_rpn_cls: 0.086  loss_rpn_loc: 0.044  time: 0.3252  data_time: 0.0060  lr: 0.000639  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:10 d2.utils.events]: \u001b[0m eta: 0:18:02  iter: 659  total_loss: 0.987  loss_cls: 0.351  loss_box_reg: 0.417  loss_rpn_cls: 0.085  loss_rpn_loc: 0.065  time: 0.3252  data_time: 0.0062  lr: 0.000659  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:16 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 679  total_loss: 0.981  loss_cls: 0.301  loss_box_reg: 0.478  loss_rpn_cls: 0.063  loss_rpn_loc: 0.035  time: 0.3253  data_time: 0.0061  lr: 0.000679  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:23 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 699  total_loss: 0.989  loss_cls: 0.384  loss_box_reg: 0.436  loss_rpn_cls: 0.087  loss_rpn_loc: 0.049  time: 0.3254  data_time: 0.0060  lr: 0.000699  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:29 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 719  total_loss: 0.982  loss_cls: 0.351  loss_box_reg: 0.471  loss_rpn_cls: 0.104  loss_rpn_loc: 0.062  time: 0.3253  data_time: 0.0102  lr: 0.000719  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:36 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 739  total_loss: 1.016  loss_cls: 0.381  loss_box_reg: 0.446  loss_rpn_cls: 0.087  loss_rpn_loc: 0.065  time: 0.3253  data_time: 0.0066  lr: 0.000739  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:42 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 759  total_loss: 0.959  loss_cls: 0.379  loss_box_reg: 0.393  loss_rpn_cls: 0.094  loss_rpn_loc: 0.051  time: 0.3252  data_time: 0.0067  lr: 0.000759  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:49 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 779  total_loss: 1.044  loss_cls: 0.393  loss_box_reg: 0.443  loss_rpn_cls: 0.085  loss_rpn_loc: 0.076  time: 0.3252  data_time: 0.0061  lr: 0.000779  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:12:55 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 799  total_loss: 0.949  loss_cls: 0.316  loss_box_reg: 0.440  loss_rpn_cls: 0.082  loss_rpn_loc: 0.046  time: 0.3253  data_time: 0.0059  lr: 0.000799  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:02 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 819  total_loss: 0.924  loss_cls: 0.353  loss_box_reg: 0.398  loss_rpn_cls: 0.083  loss_rpn_loc: 0.037  time: 0.3251  data_time: 0.0057  lr: 0.000819  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:08 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 839  total_loss: 0.917  loss_cls: 0.350  loss_box_reg: 0.464  loss_rpn_cls: 0.091  loss_rpn_loc: 0.050  time: 0.3252  data_time: 0.0064  lr: 0.000839  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:15 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 859  total_loss: 0.877  loss_cls: 0.363  loss_box_reg: 0.395  loss_rpn_cls: 0.102  loss_rpn_loc: 0.041  time: 0.3255  data_time: 0.0216  lr: 0.000859  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:21 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 879  total_loss: 1.034  loss_cls: 0.349  loss_box_reg: 0.414  loss_rpn_cls: 0.098  loss_rpn_loc: 0.065  time: 0.3253  data_time: 0.0061  lr: 0.000879  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:28 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 899  total_loss: 0.880  loss_cls: 0.319  loss_box_reg: 0.434  loss_rpn_cls: 0.099  loss_rpn_loc: 0.046  time: 0.3252  data_time: 0.0090  lr: 0.000899  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:35 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 919  total_loss: 0.910  loss_cls: 0.289  loss_box_reg: 0.494  loss_rpn_cls: 0.084  loss_rpn_loc: 0.036  time: 0.3258  data_time: 0.0375  lr: 0.000919  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:41 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 939  total_loss: 0.958  loss_cls: 0.379  loss_box_reg: 0.451  loss_rpn_cls: 0.085  loss_rpn_loc: 0.045  time: 0.3256  data_time: 0.0057  lr: 0.000939  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:48 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 959  total_loss: 1.113  loss_cls: 0.333  loss_box_reg: 0.479  loss_rpn_cls: 0.118  loss_rpn_loc: 0.088  time: 0.3259  data_time: 0.0243  lr: 0.000959  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:13:55 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 979  total_loss: 0.904  loss_cls: 0.333  loss_box_reg: 0.421  loss_rpn_cls: 0.102  loss_rpn_loc: 0.049  time: 0.3260  data_time: 0.0056  lr: 0.000979  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:01 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 999  total_loss: 0.768  loss_cls: 0.220  loss_box_reg: 0.348  loss_rpn_cls: 0.080  loss_rpn_loc: 0.049  time: 0.3259  data_time: 0.0065  lr: 0.000999  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:08 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 1019  total_loss: 1.128  loss_cls: 0.422  loss_box_reg: 0.405  loss_rpn_cls: 0.116  loss_rpn_loc: 0.100  time: 0.3258  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:14 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 1039  total_loss: 0.926  loss_cls: 0.307  loss_box_reg: 0.473  loss_rpn_cls: 0.104  loss_rpn_loc: 0.059  time: 0.3256  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:20 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 1059  total_loss: 1.018  loss_cls: 0.355  loss_box_reg: 0.477  loss_rpn_cls: 0.103  loss_rpn_loc: 0.040  time: 0.3255  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:27 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 1079  total_loss: 0.809  loss_cls: 0.310  loss_box_reg: 0.400  loss_rpn_cls: 0.043  loss_rpn_loc: 0.027  time: 0.3255  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:33 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 1099  total_loss: 0.883  loss_cls: 0.312  loss_box_reg: 0.413  loss_rpn_cls: 0.081  loss_rpn_loc: 0.041  time: 0.3255  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:40 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 1119  total_loss: 0.825  loss_cls: 0.292  loss_box_reg: 0.395  loss_rpn_cls: 0.052  loss_rpn_loc: 0.037  time: 0.3254  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:46 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 1139  total_loss: 0.778  loss_cls: 0.313  loss_box_reg: 0.386  loss_rpn_cls: 0.058  loss_rpn_loc: 0.041  time: 0.3253  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:53 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 1159  total_loss: 0.759  loss_cls: 0.299  loss_box_reg: 0.327  loss_rpn_cls: 0.074  loss_rpn_loc: 0.052  time: 0.3252  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:14:59 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 1179  total_loss: 0.824  loss_cls: 0.226  loss_box_reg: 0.397  loss_rpn_cls: 0.078  loss_rpn_loc: 0.040  time: 0.3251  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:05 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 1199  total_loss: 0.647  loss_cls: 0.195  loss_box_reg: 0.342  loss_rpn_cls: 0.058  loss_rpn_loc: 0.027  time: 0.3250  data_time: 0.0073  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:12 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 1219  total_loss: 0.928  loss_cls: 0.314  loss_box_reg: 0.437  loss_rpn_cls: 0.072  loss_rpn_loc: 0.036  time: 0.3248  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:18 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 1239  total_loss: 0.675  loss_cls: 0.276  loss_box_reg: 0.359  loss_rpn_cls: 0.055  loss_rpn_loc: 0.046  time: 0.3247  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:25 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 1259  total_loss: 0.862  loss_cls: 0.244  loss_box_reg: 0.442  loss_rpn_cls: 0.090  loss_rpn_loc: 0.064  time: 0.3248  data_time: 0.0072  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:31 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 1279  total_loss: 0.709  loss_cls: 0.182  loss_box_reg: 0.353  loss_rpn_cls: 0.062  loss_rpn_loc: 0.037  time: 0.3250  data_time: 0.0179  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:38 d2.utils.events]: \u001b[0m eta: 0:14:34  iter: 1299  total_loss: 0.836  loss_cls: 0.323  loss_box_reg: 0.369  loss_rpn_cls: 0.072  loss_rpn_loc: 0.046  time: 0.3250  data_time: 0.0177  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:44 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 1319  total_loss: 0.815  loss_cls: 0.282  loss_box_reg: 0.393  loss_rpn_cls: 0.062  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0056  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:51 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 1339  total_loss: 0.706  loss_cls: 0.221  loss_box_reg: 0.367  loss_rpn_cls: 0.069  loss_rpn_loc: 0.035  time: 0.3250  data_time: 0.0159  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:15:58 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 1359  total_loss: 0.789  loss_cls: 0.284  loss_box_reg: 0.371  loss_rpn_cls: 0.078  loss_rpn_loc: 0.054  time: 0.3250  data_time: 0.0054  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:04 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 1379  total_loss: 0.821  loss_cls: 0.260  loss_box_reg: 0.411  loss_rpn_cls: 0.083  loss_rpn_loc: 0.051  time: 0.3250  data_time: 0.0092  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:10 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 1399  total_loss: 0.696  loss_cls: 0.202  loss_box_reg: 0.393  loss_rpn_cls: 0.055  loss_rpn_loc: 0.061  time: 0.3249  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:17 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 1419  total_loss: 0.938  loss_cls: 0.302  loss_box_reg: 0.379  loss_rpn_cls: 0.065  loss_rpn_loc: 0.042  time: 0.3249  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:23 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 1439  total_loss: 0.630  loss_cls: 0.183  loss_box_reg: 0.350  loss_rpn_cls: 0.066  loss_rpn_loc: 0.032  time: 0.3249  data_time: 0.0092  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:30 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 1459  total_loss: 0.785  loss_cls: 0.261  loss_box_reg: 0.420  loss_rpn_cls: 0.072  loss_rpn_loc: 0.037  time: 0.3249  data_time: 0.0194  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:36 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 1479  total_loss: 0.810  loss_cls: 0.313  loss_box_reg: 0.401  loss_rpn_cls: 0.068  loss_rpn_loc: 0.050  time: 0.3248  data_time: 0.0090  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:43 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 1499  total_loss: 0.756  loss_cls: 0.207  loss_box_reg: 0.347  loss_rpn_cls: 0.068  loss_rpn_loc: 0.035  time: 0.3249  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:50 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 1519  total_loss: 0.784  loss_cls: 0.221  loss_box_reg: 0.371  loss_rpn_cls: 0.062  loss_rpn_loc: 0.057  time: 0.3250  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:16:56 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 1539  total_loss: 0.852  loss_cls: 0.306  loss_box_reg: 0.339  loss_rpn_cls: 0.060  loss_rpn_loc: 0.052  time: 0.3249  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:03 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 1559  total_loss: 0.812  loss_cls: 0.288  loss_box_reg: 0.396  loss_rpn_cls: 0.077  loss_rpn_loc: 0.053  time: 0.3249  data_time: 0.0148  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:09 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1579  total_loss: 0.765  loss_cls: 0.219  loss_box_reg: 0.415  loss_rpn_cls: 0.050  loss_rpn_loc: 0.056  time: 0.3249  data_time: 0.0056  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:16 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 1599  total_loss: 0.694  loss_cls: 0.209  loss_box_reg: 0.363  loss_rpn_cls: 0.045  loss_rpn_loc: 0.044  time: 0.3249  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:22 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 1619  total_loss: 0.736  loss_cls: 0.306  loss_box_reg: 0.352  loss_rpn_cls: 0.064  loss_rpn_loc: 0.032  time: 0.3249  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:28 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 1639  total_loss: 0.684  loss_cls: 0.202  loss_box_reg: 0.307  loss_rpn_cls: 0.085  loss_rpn_loc: 0.042  time: 0.3248  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:35 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 1659  total_loss: 0.676  loss_cls: 0.239  loss_box_reg: 0.355  loss_rpn_cls: 0.058  loss_rpn_loc: 0.041  time: 0.3248  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:41 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1679  total_loss: 0.801  loss_cls: 0.301  loss_box_reg: 0.332  loss_rpn_cls: 0.068  loss_rpn_loc: 0.044  time: 0.3247  data_time: 0.0072  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:48 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1699  total_loss: 0.725  loss_cls: 0.224  loss_box_reg: 0.357  loss_rpn_cls: 0.065  loss_rpn_loc: 0.049  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:17:54 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 1719  total_loss: 0.685  loss_cls: 0.244  loss_box_reg: 0.346  loss_rpn_cls: 0.060  loss_rpn_loc: 0.044  time: 0.3246  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:01 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 1739  total_loss: 0.817  loss_cls: 0.207  loss_box_reg: 0.347  loss_rpn_cls: 0.095  loss_rpn_loc: 0.056  time: 0.3246  data_time: 0.0056  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:07 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 1759  total_loss: 0.587  loss_cls: 0.159  loss_box_reg: 0.279  loss_rpn_cls: 0.067  loss_rpn_loc: 0.040  time: 0.3246  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:14 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 1779  total_loss: 0.645  loss_cls: 0.156  loss_box_reg: 0.347  loss_rpn_cls: 0.057  loss_rpn_loc: 0.048  time: 0.3246  data_time: 0.0088  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:20 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 1799  total_loss: 0.602  loss_cls: 0.182  loss_box_reg: 0.301  loss_rpn_cls: 0.065  loss_rpn_loc: 0.040  time: 0.3245  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:26 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1819  total_loss: 0.644  loss_cls: 0.200  loss_box_reg: 0.357  loss_rpn_cls: 0.045  loss_rpn_loc: 0.042  time: 0.3244  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:33 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1839  total_loss: 0.682  loss_cls: 0.188  loss_box_reg: 0.321  loss_rpn_cls: 0.071  loss_rpn_loc: 0.048  time: 0.3245  data_time: 0.0184  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:40 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 1859  total_loss: 0.598  loss_cls: 0.149  loss_box_reg: 0.368  loss_rpn_cls: 0.065  loss_rpn_loc: 0.049  time: 0.3245  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:46 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 1879  total_loss: 0.719  loss_cls: 0.216  loss_box_reg: 0.347  loss_rpn_cls: 0.047  loss_rpn_loc: 0.048  time: 0.3245  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:52 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 1899  total_loss: 0.703  loss_cls: 0.204  loss_box_reg: 0.366  loss_rpn_cls: 0.051  loss_rpn_loc: 0.077  time: 0.3244  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:18:59 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 1919  total_loss: 0.617  loss_cls: 0.214  loss_box_reg: 0.310  loss_rpn_cls: 0.047  loss_rpn_loc: 0.036  time: 0.3244  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:05 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1939  total_loss: 0.621  loss_cls: 0.188  loss_box_reg: 0.330  loss_rpn_cls: 0.063  loss_rpn_loc: 0.061  time: 0.3245  data_time: 0.0141  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:12 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 1959  total_loss: 0.735  loss_cls: 0.201  loss_box_reg: 0.357  loss_rpn_cls: 0.058  loss_rpn_loc: 0.037  time: 0.3246  data_time: 0.0278  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:19 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 1979  total_loss: 0.608  loss_cls: 0.194  loss_box_reg: 0.272  loss_rpn_cls: 0.048  loss_rpn_loc: 0.043  time: 0.3246  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:25 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 1999  total_loss: 0.635  loss_cls: 0.219  loss_box_reg: 0.345  loss_rpn_cls: 0.043  loss_rpn_loc: 0.043  time: 0.3246  data_time: 0.0099  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:32 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 2019  total_loss: 0.706  loss_cls: 0.125  loss_box_reg: 0.312  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 0.3245  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:38 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 2039  total_loss: 0.745  loss_cls: 0.208  loss_box_reg: 0.359  loss_rpn_cls: 0.053  loss_rpn_loc: 0.046  time: 0.3246  data_time: 0.0110  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:45 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 2059  total_loss: 0.633  loss_cls: 0.214  loss_box_reg: 0.317  loss_rpn_cls: 0.045  loss_rpn_loc: 0.030  time: 0.3246  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:51 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 2079  total_loss: 0.731  loss_cls: 0.239  loss_box_reg: 0.361  loss_rpn_cls: 0.060  loss_rpn_loc: 0.049  time: 0.3246  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:19:58 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 2099  total_loss: 0.563  loss_cls: 0.167  loss_box_reg: 0.313  loss_rpn_cls: 0.066  loss_rpn_loc: 0.021  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:04 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 2119  total_loss: 0.764  loss_cls: 0.226  loss_box_reg: 0.347  loss_rpn_cls: 0.094  loss_rpn_loc: 0.087  time: 0.3247  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:11 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 2139  total_loss: 0.698  loss_cls: 0.215  loss_box_reg: 0.357  loss_rpn_cls: 0.053  loss_rpn_loc: 0.036  time: 0.3246  data_time: 0.0129  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:17 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 2159  total_loss: 0.682  loss_cls: 0.169  loss_box_reg: 0.381  loss_rpn_cls: 0.044  loss_rpn_loc: 0.041  time: 0.3245  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:24 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 2179  total_loss: 0.720  loss_cls: 0.189  loss_box_reg: 0.343  loss_rpn_cls: 0.067  loss_rpn_loc: 0.045  time: 0.3245  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:30 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 2199  total_loss: 0.660  loss_cls: 0.156  loss_box_reg: 0.343  loss_rpn_cls: 0.044  loss_rpn_loc: 0.032  time: 0.3245  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:37 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 2219  total_loss: 0.686  loss_cls: 0.200  loss_box_reg: 0.369  loss_rpn_cls: 0.058  loss_rpn_loc: 0.041  time: 0.3245  data_time: 0.0089  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:43 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 2239  total_loss: 0.634  loss_cls: 0.161  loss_box_reg: 0.309  loss_rpn_cls: 0.058  loss_rpn_loc: 0.025  time: 0.3245  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:50 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 2259  total_loss: 0.775  loss_cls: 0.150  loss_box_reg: 0.329  loss_rpn_cls: 0.094  loss_rpn_loc: 0.057  time: 0.3246  data_time: 0.0119  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:20:56 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 2279  total_loss: 0.633  loss_cls: 0.160  loss_box_reg: 0.381  loss_rpn_cls: 0.084  loss_rpn_loc: 0.037  time: 0.3245  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:03 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 2299  total_loss: 0.733  loss_cls: 0.235  loss_box_reg: 0.366  loss_rpn_cls: 0.057  loss_rpn_loc: 0.038  time: 0.3245  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:09 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 2319  total_loss: 0.613  loss_cls: 0.170  loss_box_reg: 0.311  loss_rpn_cls: 0.059  loss_rpn_loc: 0.031  time: 0.3245  data_time: 0.0222  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:16 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 2339  total_loss: 0.699  loss_cls: 0.209  loss_box_reg: 0.381  loss_rpn_cls: 0.059  loss_rpn_loc: 0.063  time: 0.3245  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:22 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 2359  total_loss: 0.587  loss_cls: 0.158  loss_box_reg: 0.311  loss_rpn_cls: 0.061  loss_rpn_loc: 0.036  time: 0.3245  data_time: 0.0072  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:29 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 2379  total_loss: 0.665  loss_cls: 0.252  loss_box_reg: 0.350  loss_rpn_cls: 0.045  loss_rpn_loc: 0.030  time: 0.3245  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:35 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 2399  total_loss: 0.687  loss_cls: 0.199  loss_box_reg: 0.380  loss_rpn_cls: 0.047  loss_rpn_loc: 0.051  time: 0.3245  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:41 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 2419  total_loss: 0.590  loss_cls: 0.111  loss_box_reg: 0.288  loss_rpn_cls: 0.056  loss_rpn_loc: 0.040  time: 0.3244  data_time: 0.0076  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:48 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 2439  total_loss: 0.674  loss_cls: 0.175  loss_box_reg: 0.331  loss_rpn_cls: 0.047  loss_rpn_loc: 0.030  time: 0.3244  data_time: 0.0123  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:21:55 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 2459  total_loss: 0.704  loss_cls: 0.236  loss_box_reg: 0.301  loss_rpn_cls: 0.075  loss_rpn_loc: 0.033  time: 0.3245  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:01 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 2479  total_loss: 0.610  loss_cls: 0.173  loss_box_reg: 0.330  loss_rpn_cls: 0.033  loss_rpn_loc: 0.036  time: 0.3244  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:08 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 2499  total_loss: 0.585  loss_cls: 0.185  loss_box_reg: 0.305  loss_rpn_cls: 0.052  loss_rpn_loc: 0.032  time: 0.3244  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:14 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 2519  total_loss: 0.549  loss_cls: 0.162  loss_box_reg: 0.301  loss_rpn_cls: 0.041  loss_rpn_loc: 0.044  time: 0.3244  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:20 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 2539  total_loss: 0.585  loss_cls: 0.184  loss_box_reg: 0.311  loss_rpn_cls: 0.058  loss_rpn_loc: 0.033  time: 0.3244  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:27 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 2559  total_loss: 0.551  loss_cls: 0.138  loss_box_reg: 0.289  loss_rpn_cls: 0.035  loss_rpn_loc: 0.040  time: 0.3244  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:33 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 2579  total_loss: 0.733  loss_cls: 0.221  loss_box_reg: 0.379  loss_rpn_cls: 0.070  loss_rpn_loc: 0.038  time: 0.3244  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:40 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 2599  total_loss: 0.579  loss_cls: 0.125  loss_box_reg: 0.336  loss_rpn_cls: 0.054  loss_rpn_loc: 0.036  time: 0.3244  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:47 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 2619  total_loss: 0.506  loss_cls: 0.118  loss_box_reg: 0.289  loss_rpn_cls: 0.031  loss_rpn_loc: 0.041  time: 0.3245  data_time: 0.0262  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:22:53 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 2639  total_loss: 0.504  loss_cls: 0.138  loss_box_reg: 0.289  loss_rpn_cls: 0.041  loss_rpn_loc: 0.041  time: 0.3244  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:00 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 2659  total_loss: 0.790  loss_cls: 0.210  loss_box_reg: 0.311  loss_rpn_cls: 0.066  loss_rpn_loc: 0.055  time: 0.3244  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:06 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 2679  total_loss: 0.601  loss_cls: 0.185  loss_box_reg: 0.323  loss_rpn_cls: 0.046  loss_rpn_loc: 0.049  time: 0.3244  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:13 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 2699  total_loss: 0.586  loss_cls: 0.161  loss_box_reg: 0.307  loss_rpn_cls: 0.051  loss_rpn_loc: 0.045  time: 0.3245  data_time: 0.0235  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:19 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 2719  total_loss: 0.491  loss_cls: 0.116  loss_box_reg: 0.313  loss_rpn_cls: 0.047  loss_rpn_loc: 0.033  time: 0.3246  data_time: 0.0203  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:26 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 2739  total_loss: 0.580  loss_cls: 0.179  loss_box_reg: 0.313  loss_rpn_cls: 0.051  loss_rpn_loc: 0.043  time: 0.3245  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:32 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 2759  total_loss: 0.650  loss_cls: 0.162  loss_box_reg: 0.351  loss_rpn_cls: 0.061  loss_rpn_loc: 0.061  time: 0.3245  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:39 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 2779  total_loss: 0.565  loss_cls: 0.135  loss_box_reg: 0.295  loss_rpn_cls: 0.047  loss_rpn_loc: 0.034  time: 0.3245  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:45 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 2799  total_loss: 0.593  loss_cls: 0.157  loss_box_reg: 0.300  loss_rpn_cls: 0.051  loss_rpn_loc: 0.059  time: 0.3245  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:52 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 2819  total_loss: 0.427  loss_cls: 0.103  loss_box_reg: 0.238  loss_rpn_cls: 0.029  loss_rpn_loc: 0.019  time: 0.3245  data_time: 0.0146  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:23:58 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2839  total_loss: 0.671  loss_cls: 0.168  loss_box_reg: 0.339  loss_rpn_cls: 0.070  loss_rpn_loc: 0.041  time: 0.3245  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:05 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 2859  total_loss: 0.633  loss_cls: 0.216  loss_box_reg: 0.318  loss_rpn_cls: 0.037  loss_rpn_loc: 0.030  time: 0.3245  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:11 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 2879  total_loss: 0.591  loss_cls: 0.157  loss_box_reg: 0.295  loss_rpn_cls: 0.053  loss_rpn_loc: 0.036  time: 0.3246  data_time: 0.0105  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:18 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 2899  total_loss: 0.723  loss_cls: 0.205  loss_box_reg: 0.312  loss_rpn_cls: 0.067  loss_rpn_loc: 0.043  time: 0.3246  data_time: 0.0208  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:25 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 2919  total_loss: 0.569  loss_cls: 0.161  loss_box_reg: 0.281  loss_rpn_cls: 0.058  loss_rpn_loc: 0.062  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:31 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 2939  total_loss: 0.514  loss_cls: 0.129  loss_box_reg: 0.279  loss_rpn_cls: 0.047  loss_rpn_loc: 0.037  time: 0.3246  data_time: 0.0059  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:38 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 2959  total_loss: 0.466  loss_cls: 0.140  loss_box_reg: 0.251  loss_rpn_cls: 0.040  loss_rpn_loc: 0.039  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:44 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 2979  total_loss: 0.576  loss_cls: 0.151  loss_box_reg: 0.262  loss_rpn_cls: 0.071  loss_rpn_loc: 0.049  time: 0.3245  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:50 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 2999  total_loss: 0.684  loss_cls: 0.164  loss_box_reg: 0.371  loss_rpn_cls: 0.059  loss_rpn_loc: 0.047  time: 0.3245  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:24:57 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 3019  total_loss: 0.566  loss_cls: 0.176  loss_box_reg: 0.282  loss_rpn_cls: 0.049  loss_rpn_loc: 0.063  time: 0.3244  data_time: 0.0066  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:03 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 3039  total_loss: 0.593  loss_cls: 0.152  loss_box_reg: 0.265  loss_rpn_cls: 0.063  loss_rpn_loc: 0.039  time: 0.3245  data_time: 0.0185  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:10 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 3059  total_loss: 0.638  loss_cls: 0.221  loss_box_reg: 0.351  loss_rpn_cls: 0.053  loss_rpn_loc: 0.038  time: 0.3244  data_time: 0.0064  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:16 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 3079  total_loss: 0.506  loss_cls: 0.132  loss_box_reg: 0.260  loss_rpn_cls: 0.040  loss_rpn_loc: 0.045  time: 0.3245  data_time: 0.0179  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:23 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 3099  total_loss: 0.570  loss_cls: 0.129  loss_box_reg: 0.288  loss_rpn_cls: 0.042  loss_rpn_loc: 0.053  time: 0.3245  data_time: 0.0071  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:29 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 3119  total_loss: 0.543  loss_cls: 0.164  loss_box_reg: 0.277  loss_rpn_cls: 0.047  loss_rpn_loc: 0.057  time: 0.3244  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:36 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 3139  total_loss: 0.520  loss_cls: 0.125  loss_box_reg: 0.239  loss_rpn_cls: 0.047  loss_rpn_loc: 0.042  time: 0.3244  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:43 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 3159  total_loss: 0.475  loss_cls: 0.100  loss_box_reg: 0.297  loss_rpn_cls: 0.037  loss_rpn_loc: 0.028  time: 0.3246  data_time: 0.0298  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:49 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 3179  total_loss: 0.577  loss_cls: 0.142  loss_box_reg: 0.291  loss_rpn_cls: 0.053  loss_rpn_loc: 0.035  time: 0.3246  data_time: 0.0094  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:25:56 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 3199  total_loss: 0.565  loss_cls: 0.157  loss_box_reg: 0.333  loss_rpn_cls: 0.054  loss_rpn_loc: 0.033  time: 0.3246  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:02 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 3219  total_loss: 0.579  loss_cls: 0.108  loss_box_reg: 0.329  loss_rpn_cls: 0.048  loss_rpn_loc: 0.042  time: 0.3245  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:09 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 3239  total_loss: 0.569  loss_cls: 0.234  loss_box_reg: 0.291  loss_rpn_cls: 0.042  loss_rpn_loc: 0.040  time: 0.3246  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:15 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 3259  total_loss: 0.561  loss_cls: 0.151  loss_box_reg: 0.299  loss_rpn_cls: 0.034  loss_rpn_loc: 0.032  time: 0.3246  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:22 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 3279  total_loss: 0.622  loss_cls: 0.156  loss_box_reg: 0.293  loss_rpn_cls: 0.065  loss_rpn_loc: 0.036  time: 0.3246  data_time: 0.0104  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:28 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 3299  total_loss: 0.574  loss_cls: 0.191  loss_box_reg: 0.283  loss_rpn_cls: 0.050  loss_rpn_loc: 0.037  time: 0.3246  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:35 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3319  total_loss: 0.551  loss_cls: 0.175  loss_box_reg: 0.290  loss_rpn_cls: 0.047  loss_rpn_loc: 0.047  time: 0.3246  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:41 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3339  total_loss: 0.601  loss_cls: 0.220  loss_box_reg: 0.332  loss_rpn_cls: 0.027  loss_rpn_loc: 0.016  time: 0.3246  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:48 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 3359  total_loss: 0.635  loss_cls: 0.177  loss_box_reg: 0.318  loss_rpn_cls: 0.064  loss_rpn_loc: 0.053  time: 0.3246  data_time: 0.0158  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:26:54 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 3379  total_loss: 0.573  loss_cls: 0.141  loss_box_reg: 0.286  loss_rpn_cls: 0.051  loss_rpn_loc: 0.038  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:01 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 3399  total_loss: 0.587  loss_cls: 0.183  loss_box_reg: 0.296  loss_rpn_cls: 0.055  loss_rpn_loc: 0.037  time: 0.3245  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:07 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 3419  total_loss: 0.638  loss_cls: 0.156  loss_box_reg: 0.321  loss_rpn_cls: 0.042  loss_rpn_loc: 0.033  time: 0.3246  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:14 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 3439  total_loss: 0.634  loss_cls: 0.178  loss_box_reg: 0.292  loss_rpn_cls: 0.041  loss_rpn_loc: 0.035  time: 0.3245  data_time: 0.0074  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:20 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3459  total_loss: 0.554  loss_cls: 0.126  loss_box_reg: 0.278  loss_rpn_cls: 0.036  loss_rpn_loc: 0.055  time: 0.3246  data_time: 0.0210  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:27 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 3479  total_loss: 0.568  loss_cls: 0.127  loss_box_reg: 0.304  loss_rpn_cls: 0.029  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0173  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:34 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 3499  total_loss: 0.514  loss_cls: 0.095  loss_box_reg: 0.273  loss_rpn_cls: 0.045  loss_rpn_loc: 0.059  time: 0.3247  data_time: 0.0070  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:40 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 3519  total_loss: 0.525  loss_cls: 0.114  loss_box_reg: 0.325  loss_rpn_cls: 0.042  loss_rpn_loc: 0.031  time: 0.3247  data_time: 0.0055  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:47 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3539  total_loss: 0.585  loss_cls: 0.167  loss_box_reg: 0.268  loss_rpn_cls: 0.041  loss_rpn_loc: 0.032  time: 0.3246  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:27:53 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 3559  total_loss: 0.510  loss_cls: 0.137  loss_box_reg: 0.294  loss_rpn_cls: 0.053  loss_rpn_loc: 0.044  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:00 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3579  total_loss: 0.531  loss_cls: 0.157  loss_box_reg: 0.247  loss_rpn_cls: 0.039  loss_rpn_loc: 0.050  time: 0.3248  data_time: 0.0436  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:06 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 3599  total_loss: 0.465  loss_cls: 0.140  loss_box_reg: 0.270  loss_rpn_cls: 0.034  loss_rpn_loc: 0.057  time: 0.3248  data_time: 0.0069  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:13 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3619  total_loss: 0.545  loss_cls: 0.129  loss_box_reg: 0.253  loss_rpn_cls: 0.055  loss_rpn_loc: 0.032  time: 0.3247  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:19 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 3639  total_loss: 0.598  loss_cls: 0.184  loss_box_reg: 0.330  loss_rpn_cls: 0.044  loss_rpn_loc: 0.037  time: 0.3247  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:26 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3659  total_loss: 0.475  loss_cls: 0.110  loss_box_reg: 0.278  loss_rpn_cls: 0.044  loss_rpn_loc: 0.047  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:32 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 3679  total_loss: 0.532  loss_cls: 0.147  loss_box_reg: 0.260  loss_rpn_cls: 0.030  loss_rpn_loc: 0.031  time: 0.3247  data_time: 0.0057  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:38 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3699  total_loss: 0.469  loss_cls: 0.097  loss_box_reg: 0.268  loss_rpn_cls: 0.031  loss_rpn_loc: 0.033  time: 0.3246  data_time: 0.0062  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:45 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 3719  total_loss: 0.498  loss_cls: 0.131  loss_box_reg: 0.290  loss_rpn_cls: 0.038  loss_rpn_loc: 0.050  time: 0.3246  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:52 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3739  total_loss: 0.549  loss_cls: 0.153  loss_box_reg: 0.302  loss_rpn_cls: 0.031  loss_rpn_loc: 0.029  time: 0.3246  data_time: 0.0061  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:28:58 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 3759  total_loss: 0.543  loss_cls: 0.126  loss_box_reg: 0.314  loss_rpn_cls: 0.034  loss_rpn_loc: 0.033  time: 0.3246  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:04 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 3779  total_loss: 0.583  loss_cls: 0.158  loss_box_reg: 0.285  loss_rpn_cls: 0.032  loss_rpn_loc: 0.041  time: 0.3246  data_time: 0.0100  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:11 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3799  total_loss: 0.462  loss_cls: 0.117  loss_box_reg: 0.256  loss_rpn_cls: 0.029  loss_rpn_loc: 0.035  time: 0.3246  data_time: 0.0108  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:17 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 3819  total_loss: 0.579  loss_cls: 0.141  loss_box_reg: 0.316  loss_rpn_cls: 0.058  loss_rpn_loc: 0.062  time: 0.3246  data_time: 0.0065  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:24 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3839  total_loss: 0.624  loss_cls: 0.158  loss_box_reg: 0.317  loss_rpn_cls: 0.045  loss_rpn_loc: 0.045  time: 0.3246  data_time: 0.0060  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:30 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3859  total_loss: 0.526  loss_cls: 0.171  loss_box_reg: 0.279  loss_rpn_cls: 0.045  loss_rpn_loc: 0.029  time: 0.3245  data_time: 0.0058  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:37 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 3879  total_loss: 0.490  loss_cls: 0.136  loss_box_reg: 0.273  loss_rpn_cls: 0.036  loss_rpn_loc: 0.032  time: 0.3247  data_time: 0.0333  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:44 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 3899  total_loss: 0.447  loss_cls: 0.100  loss_box_reg: 0.257  loss_rpn_cls: 0.042  loss_rpn_loc: 0.039  time: 0.3247  data_time: 0.0067  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:50 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 3919  total_loss: 0.505  loss_cls: 0.140  loss_box_reg: 0.273  loss_rpn_cls: 0.037  loss_rpn_loc: 0.043  time: 0.3247  data_time: 0.0075  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:29:57 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 3939  total_loss: 0.484  loss_cls: 0.097  loss_box_reg: 0.261  loss_rpn_cls: 0.055  loss_rpn_loc: 0.039  time: 0.3247  data_time: 0.0159  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:30:03 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 3959  total_loss: 0.497  loss_cls: 0.141  loss_box_reg: 0.285  loss_rpn_cls: 0.032  loss_rpn_loc: 0.042  time: 0.3247  data_time: 0.0063  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:30:10 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 3979  total_loss: 0.509  loss_cls: 0.103  loss_box_reg: 0.311  loss_rpn_cls: 0.030  loss_rpn_loc: 0.039  time: 0.3247  data_time: 0.0068  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:30:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.561  loss_cls: 0.144  loss_box_reg: 0.284  loss_rpn_cls: 0.027  loss_rpn_loc: 0.048  time: 0.3247  data_time: 0.0098  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:30:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.561  loss_cls: 0.144  loss_box_reg: 0.284  loss_rpn_cls: 0.027  loss_rpn_loc: 0.057  time: 0.3247  data_time: 0.0099  lr: 0.001000  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:30:18 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:21:38 (0.3248 s / it)\n",
            "\u001b[32m[05/04 02:30:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:42 (0:00:04 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:30:19 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:30:19 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 02:30:19 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:30:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 02:30:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 02:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1357 s / img. ETA=0:00:26\n",
            "\u001b[32m[05/04 02:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 44/206. 0.1519 s / img. ETA=0:00:24\n",
            "\u001b[32m[05/04 02:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 70/206. 0.1687 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 02:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 101/206. 0.1664 s / img. ETA=0:00:17\n",
            "\u001b[32m[05/04 02:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 134/206. 0.1621 s / img. ETA=0:00:11\n",
            "\u001b[32m[05/04 02:30:46 d2.evaluation.evaluator]: \u001b[0mInference done 165/206. 0.1619 s / img. ETA=0:00:06\n",
            "\u001b[32m[05/04 02:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 201/206. 0.1577 s / img. ETA=0:00:00\n",
            "\u001b[32m[05/04 02:30:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.123833 (0.159820 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:30:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.156921 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:30:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 02:30:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128/coco_instances_results.json\n",
            "\u001b[32m[05/04 02:30:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.633\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n",
            "\u001b[32m[05/04 02:30:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.163 | 63.267 | 44.170 | 18.519 | 36.337 | 45.662 |\n",
            "\u001b[32m[05/04 02:30:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 40.277 | tomato_fruit       | 26.131 | tomato_seedling          | 26.457 |\n",
            "| tomato_young_plant      | 51.915 | tomato_flower      | 44.327 | bell_pepper_fruit        | 59.501 |\n",
            "| bell_pepper_young_plant | 32.867 | bell_pepper_flower | 37.087 | bell_pepper_fruit_unripe | 29.028 |\n",
            "| bell_pepper_seedling    | 17.652 | cucumber_flower    | 62.655 | cucumber_plant           | 17.360 |\n",
            "| cucumber_seedling       | 31.780 | cucumber_fruit     | 63.819 | cucumber_fruit_unripe    | 46.591 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.001_128___2.png\n",
            "Saving results...\n",
            "Saved /content/drive/My Drive/Green Thumbs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_05-03-2020_21:04.json\n",
            "\u001b[32m[05/04 02:30:54 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:30:54 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:30:54 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 02:30:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 02:30:54 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:30:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 02:30:54 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 02:30:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64\n",
            "**********************************************\n",
            "\u001b[32m[05/04 02:30:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 02:31:00 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 19  total_loss: 3.841  loss_cls: 2.667  loss_box_reg: 0.901  loss_rpn_cls: 0.183  loss_rpn_loc: 0.059  time: 0.2544  data_time: 0.0247  lr: 0.000010  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:05 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 39  total_loss: 3.526  loss_cls: 2.413  loss_box_reg: 0.909  loss_rpn_cls: 0.222  loss_rpn_loc: 0.064  time: 0.2519  data_time: 0.0198  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:10 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 59  total_loss: 3.074  loss_cls: 1.874  loss_box_reg: 0.921  loss_rpn_cls: 0.172  loss_rpn_loc: 0.090  time: 0.2595  data_time: 0.0291  lr: 0.000030  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:16 d2.utils.events]: \u001b[0m eta: 0:16:25  iter: 79  total_loss: 2.469  loss_cls: 1.255  loss_box_reg: 0.908  loss_rpn_cls: 0.232  loss_rpn_loc: 0.041  time: 0.2616  data_time: 0.0233  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:21 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 99  total_loss: 2.379  loss_cls: 1.141  loss_box_reg: 0.893  loss_rpn_cls: 0.197  loss_rpn_loc: 0.081  time: 0.2608  data_time: 0.0068  lr: 0.000050  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:26 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 119  total_loss: 2.252  loss_cls: 1.095  loss_box_reg: 0.919  loss_rpn_cls: 0.208  loss_rpn_loc: 0.049  time: 0.2597  data_time: 0.0164  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:31 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 139  total_loss: 2.187  loss_cls: 1.044  loss_box_reg: 0.915  loss_rpn_cls: 0.164  loss_rpn_loc: 0.045  time: 0.2594  data_time: 0.0135  lr: 0.000070  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:36 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 159  total_loss: 2.223  loss_cls: 1.002  loss_box_reg: 0.919  loss_rpn_cls: 0.188  loss_rpn_loc: 0.041  time: 0.2582  data_time: 0.0061  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:41 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 179  total_loss: 2.028  loss_cls: 0.931  loss_box_reg: 0.959  loss_rpn_cls: 0.163  loss_rpn_loc: 0.054  time: 0.2571  data_time: 0.0070  lr: 0.000090  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:46 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 199  total_loss: 2.083  loss_cls: 0.870  loss_box_reg: 0.949  loss_rpn_cls: 0.126  loss_rpn_loc: 0.062  time: 0.2568  data_time: 0.0116  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:51 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 219  total_loss: 1.947  loss_cls: 0.817  loss_box_reg: 0.905  loss_rpn_cls: 0.140  loss_rpn_loc: 0.040  time: 0.2565  data_time: 0.0136  lr: 0.000110  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:31:56 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 239  total_loss: 1.932  loss_cls: 0.821  loss_box_reg: 0.911  loss_rpn_cls: 0.154  loss_rpn_loc: 0.056  time: 0.2557  data_time: 0.0063  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:01 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 259  total_loss: 1.927  loss_cls: 0.803  loss_box_reg: 0.926  loss_rpn_cls: 0.133  loss_rpn_loc: 0.034  time: 0.2554  data_time: 0.0056  lr: 0.000130  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:06 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 279  total_loss: 1.792  loss_cls: 0.721  loss_box_reg: 0.897  loss_rpn_cls: 0.142  loss_rpn_loc: 0.030  time: 0.2552  data_time: 0.0062  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:11 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 299  total_loss: 1.701  loss_cls: 0.609  loss_box_reg: 0.901  loss_rpn_cls: 0.129  loss_rpn_loc: 0.057  time: 0.2548  data_time: 0.0060  lr: 0.000150  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:16 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 319  total_loss: 1.646  loss_cls: 0.635  loss_box_reg: 0.869  loss_rpn_cls: 0.135  loss_rpn_loc: 0.044  time: 0.2544  data_time: 0.0066  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:21 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 339  total_loss: 1.859  loss_cls: 0.705  loss_box_reg: 0.938  loss_rpn_cls: 0.129  loss_rpn_loc: 0.061  time: 0.2542  data_time: 0.0061  lr: 0.000170  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:26 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 359  total_loss: 1.856  loss_cls: 0.702  loss_box_reg: 0.917  loss_rpn_cls: 0.132  loss_rpn_loc: 0.053  time: 0.2537  data_time: 0.0065  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:31 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 379  total_loss: 1.643  loss_cls: 0.567  loss_box_reg: 0.857  loss_rpn_cls: 0.130  loss_rpn_loc: 0.053  time: 0.2534  data_time: 0.0063  lr: 0.000190  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:36 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 399  total_loss: 1.608  loss_cls: 0.593  loss_box_reg: 0.811  loss_rpn_cls: 0.127  loss_rpn_loc: 0.046  time: 0.2530  data_time: 0.0064  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:41 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 419  total_loss: 1.560  loss_cls: 0.578  loss_box_reg: 0.738  loss_rpn_cls: 0.101  loss_rpn_loc: 0.039  time: 0.2531  data_time: 0.0063  lr: 0.000210  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:46 d2.utils.events]: \u001b[0m eta: 0:14:53  iter: 439  total_loss: 1.627  loss_cls: 0.565  loss_box_reg: 0.836  loss_rpn_cls: 0.111  loss_rpn_loc: 0.051  time: 0.2530  data_time: 0.0060  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:51 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 459  total_loss: 1.366  loss_cls: 0.441  loss_box_reg: 0.712  loss_rpn_cls: 0.129  loss_rpn_loc: 0.037  time: 0.2530  data_time: 0.0061  lr: 0.000230  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:32:56 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 479  total_loss: 1.409  loss_cls: 0.500  loss_box_reg: 0.703  loss_rpn_cls: 0.125  loss_rpn_loc: 0.064  time: 0.2528  data_time: 0.0115  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:01 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 499  total_loss: 1.682  loss_cls: 0.659  loss_box_reg: 0.790  loss_rpn_cls: 0.138  loss_rpn_loc: 0.057  time: 0.2526  data_time: 0.0067  lr: 0.000250  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:06 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 519  total_loss: 1.428  loss_cls: 0.578  loss_box_reg: 0.726  loss_rpn_cls: 0.119  loss_rpn_loc: 0.044  time: 0.2522  data_time: 0.0063  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:12 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 539  total_loss: 1.445  loss_cls: 0.527  loss_box_reg: 0.708  loss_rpn_cls: 0.098  loss_rpn_loc: 0.042  time: 0.2530  data_time: 0.0236  lr: 0.000270  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:17 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 559  total_loss: 1.329  loss_cls: 0.479  loss_box_reg: 0.669  loss_rpn_cls: 0.112  loss_rpn_loc: 0.043  time: 0.2538  data_time: 0.0388  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:22 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 579  total_loss: 1.424  loss_cls: 0.480  loss_box_reg: 0.697  loss_rpn_cls: 0.113  loss_rpn_loc: 0.045  time: 0.2537  data_time: 0.0068  lr: 0.000290  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:27 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 599  total_loss: 1.269  loss_cls: 0.491  loss_box_reg: 0.610  loss_rpn_cls: 0.114  loss_rpn_loc: 0.058  time: 0.2534  data_time: 0.0121  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:32 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 619  total_loss: 1.262  loss_cls: 0.448  loss_box_reg: 0.593  loss_rpn_cls: 0.102  loss_rpn_loc: 0.032  time: 0.2536  data_time: 0.0248  lr: 0.000310  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:37 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 639  total_loss: 1.214  loss_cls: 0.421  loss_box_reg: 0.552  loss_rpn_cls: 0.106  loss_rpn_loc: 0.064  time: 0.2536  data_time: 0.0142  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:42 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 659  total_loss: 1.224  loss_cls: 0.439  loss_box_reg: 0.568  loss_rpn_cls: 0.085  loss_rpn_loc: 0.051  time: 0.2536  data_time: 0.0059  lr: 0.000330  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:47 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 679  total_loss: 1.251  loss_cls: 0.382  loss_box_reg: 0.581  loss_rpn_cls: 0.093  loss_rpn_loc: 0.046  time: 0.2534  data_time: 0.0065  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:52 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 699  total_loss: 1.106  loss_cls: 0.454  loss_box_reg: 0.520  loss_rpn_cls: 0.113  loss_rpn_loc: 0.030  time: 0.2532  data_time: 0.0062  lr: 0.000350  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:33:58 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 719  total_loss: 1.072  loss_cls: 0.398  loss_box_reg: 0.524  loss_rpn_cls: 0.093  loss_rpn_loc: 0.054  time: 0.2536  data_time: 0.0253  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:03 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 739  total_loss: 1.074  loss_cls: 0.325  loss_box_reg: 0.537  loss_rpn_cls: 0.103  loss_rpn_loc: 0.048  time: 0.2537  data_time: 0.0125  lr: 0.000370  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:08 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 759  total_loss: 1.000  loss_cls: 0.387  loss_box_reg: 0.526  loss_rpn_cls: 0.075  loss_rpn_loc: 0.038  time: 0.2534  data_time: 0.0064  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:13 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 779  total_loss: 1.129  loss_cls: 0.309  loss_box_reg: 0.519  loss_rpn_cls: 0.127  loss_rpn_loc: 0.057  time: 0.2540  data_time: 0.0377  lr: 0.000390  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:18 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 799  total_loss: 1.050  loss_cls: 0.390  loss_box_reg: 0.501  loss_rpn_cls: 0.089  loss_rpn_loc: 0.043  time: 0.2540  data_time: 0.0135  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:23 d2.utils.events]: \u001b[0m eta: 0:13:16  iter: 819  total_loss: 0.940  loss_cls: 0.277  loss_box_reg: 0.465  loss_rpn_cls: 0.088  loss_rpn_loc: 0.051  time: 0.2539  data_time: 0.0088  lr: 0.000410  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:28 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 839  total_loss: 1.230  loss_cls: 0.524  loss_box_reg: 0.556  loss_rpn_cls: 0.092  loss_rpn_loc: 0.048  time: 0.2537  data_time: 0.0061  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:34 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 859  total_loss: 1.085  loss_cls: 0.419  loss_box_reg: 0.569  loss_rpn_cls: 0.080  loss_rpn_loc: 0.035  time: 0.2538  data_time: 0.0062  lr: 0.000430  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:39 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 879  total_loss: 1.009  loss_cls: 0.396  loss_box_reg: 0.532  loss_rpn_cls: 0.086  loss_rpn_loc: 0.029  time: 0.2540  data_time: 0.0060  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:44 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 899  total_loss: 0.952  loss_cls: 0.360  loss_box_reg: 0.436  loss_rpn_cls: 0.116  loss_rpn_loc: 0.043  time: 0.2539  data_time: 0.0066  lr: 0.000450  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:49 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 919  total_loss: 0.904  loss_cls: 0.276  loss_box_reg: 0.464  loss_rpn_cls: 0.070  loss_rpn_loc: 0.052  time: 0.2538  data_time: 0.0067  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:54 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 939  total_loss: 1.109  loss_cls: 0.375  loss_box_reg: 0.503  loss_rpn_cls: 0.081  loss_rpn_loc: 0.044  time: 0.2538  data_time: 0.0063  lr: 0.000470  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:34:59 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 959  total_loss: 1.179  loss_cls: 0.436  loss_box_reg: 0.496  loss_rpn_cls: 0.119  loss_rpn_loc: 0.046  time: 0.2537  data_time: 0.0067  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:04 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 979  total_loss: 1.040  loss_cls: 0.360  loss_box_reg: 0.534  loss_rpn_cls: 0.083  loss_rpn_loc: 0.032  time: 0.2536  data_time: 0.0063  lr: 0.000490  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:09 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 999  total_loss: 1.086  loss_cls: 0.406  loss_box_reg: 0.505  loss_rpn_cls: 0.085  loss_rpn_loc: 0.039  time: 0.2536  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:14 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 1019  total_loss: 1.157  loss_cls: 0.363  loss_box_reg: 0.550  loss_rpn_cls: 0.088  loss_rpn_loc: 0.047  time: 0.2536  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:19 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 1039  total_loss: 0.874  loss_cls: 0.274  loss_box_reg: 0.430  loss_rpn_cls: 0.070  loss_rpn_loc: 0.039  time: 0.2538  data_time: 0.0257  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:25 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 1059  total_loss: 1.046  loss_cls: 0.301  loss_box_reg: 0.479  loss_rpn_cls: 0.072  loss_rpn_loc: 0.040  time: 0.2539  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:30 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 1079  total_loss: 1.273  loss_cls: 0.519  loss_box_reg: 0.531  loss_rpn_cls: 0.098  loss_rpn_loc: 0.068  time: 0.2539  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:35 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1099  total_loss: 0.904  loss_cls: 0.363  loss_box_reg: 0.440  loss_rpn_cls: 0.072  loss_rpn_loc: 0.033  time: 0.2542  data_time: 0.0330  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:40 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 1119  total_loss: 0.990  loss_cls: 0.309  loss_box_reg: 0.521  loss_rpn_cls: 0.093  loss_rpn_loc: 0.056  time: 0.2541  data_time: 0.0123  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:45 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 1139  total_loss: 1.041  loss_cls: 0.306  loss_box_reg: 0.591  loss_rpn_cls: 0.078  loss_rpn_loc: 0.053  time: 0.2540  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:50 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1159  total_loss: 1.029  loss_cls: 0.296  loss_box_reg: 0.503  loss_rpn_cls: 0.094  loss_rpn_loc: 0.085  time: 0.2541  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:35:55 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 1179  total_loss: 0.832  loss_cls: 0.292  loss_box_reg: 0.441  loss_rpn_cls: 0.077  loss_rpn_loc: 0.032  time: 0.2540  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:00 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 1199  total_loss: 0.764  loss_cls: 0.243  loss_box_reg: 0.374  loss_rpn_cls: 0.093  loss_rpn_loc: 0.035  time: 0.2539  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:05 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1219  total_loss: 0.870  loss_cls: 0.333  loss_box_reg: 0.452  loss_rpn_cls: 0.089  loss_rpn_loc: 0.036  time: 0.2538  data_time: 0.0073  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:10 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1239  total_loss: 0.961  loss_cls: 0.343  loss_box_reg: 0.459  loss_rpn_cls: 0.078  loss_rpn_loc: 0.040  time: 0.2540  data_time: 0.0258  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:15 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 1259  total_loss: 0.851  loss_cls: 0.249  loss_box_reg: 0.473  loss_rpn_cls: 0.056  loss_rpn_loc: 0.048  time: 0.2539  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:20 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 1279  total_loss: 0.966  loss_cls: 0.304  loss_box_reg: 0.496  loss_rpn_cls: 0.069  loss_rpn_loc: 0.055  time: 0.2538  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:25 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 1299  total_loss: 0.976  loss_cls: 0.293  loss_box_reg: 0.483  loss_rpn_cls: 0.084  loss_rpn_loc: 0.038  time: 0.2537  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:31 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 1319  total_loss: 0.953  loss_cls: 0.257  loss_box_reg: 0.496  loss_rpn_cls: 0.073  loss_rpn_loc: 0.050  time: 0.2538  data_time: 0.0230  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:36 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 1339  total_loss: 0.953  loss_cls: 0.309  loss_box_reg: 0.456  loss_rpn_cls: 0.076  loss_rpn_loc: 0.034  time: 0.2538  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:41 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1359  total_loss: 0.826  loss_cls: 0.234  loss_box_reg: 0.483  loss_rpn_cls: 0.065  loss_rpn_loc: 0.045  time: 0.2539  data_time: 0.0165  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:46 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 1379  total_loss: 0.817  loss_cls: 0.248  loss_box_reg: 0.414  loss_rpn_cls: 0.065  loss_rpn_loc: 0.043  time: 0.2539  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:51 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 1399  total_loss: 0.807  loss_cls: 0.298  loss_box_reg: 0.412  loss_rpn_cls: 0.067  loss_rpn_loc: 0.040  time: 0.2538  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:36:56 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 1419  total_loss: 0.827  loss_cls: 0.267  loss_box_reg: 0.454  loss_rpn_cls: 0.078  loss_rpn_loc: 0.037  time: 0.2538  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:01 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 1439  total_loss: 0.970  loss_cls: 0.339  loss_box_reg: 0.466  loss_rpn_cls: 0.088  loss_rpn_loc: 0.036  time: 0.2537  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:06 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1459  total_loss: 0.978  loss_cls: 0.296  loss_box_reg: 0.465  loss_rpn_cls: 0.087  loss_rpn_loc: 0.081  time: 0.2535  data_time: 0.0090  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:11 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 1479  total_loss: 0.877  loss_cls: 0.260  loss_box_reg: 0.419  loss_rpn_cls: 0.082  loss_rpn_loc: 0.048  time: 0.2535  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:16 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 1499  total_loss: 0.862  loss_cls: 0.255  loss_box_reg: 0.438  loss_rpn_cls: 0.068  loss_rpn_loc: 0.037  time: 0.2538  data_time: 0.0399  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:22 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 1519  total_loss: 0.722  loss_cls: 0.199  loss_box_reg: 0.358  loss_rpn_cls: 0.057  loss_rpn_loc: 0.043  time: 0.2540  data_time: 0.0210  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:27 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 1539  total_loss: 0.950  loss_cls: 0.299  loss_box_reg: 0.456  loss_rpn_cls: 0.067  loss_rpn_loc: 0.051  time: 0.2540  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:32 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 1559  total_loss: 0.947  loss_cls: 0.275  loss_box_reg: 0.453  loss_rpn_cls: 0.097  loss_rpn_loc: 0.056  time: 0.2540  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:37 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 1579  total_loss: 1.121  loss_cls: 0.398  loss_box_reg: 0.535  loss_rpn_cls: 0.094  loss_rpn_loc: 0.074  time: 0.2540  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:42 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 1599  total_loss: 0.729  loss_cls: 0.221  loss_box_reg: 0.357  loss_rpn_cls: 0.076  loss_rpn_loc: 0.042  time: 0.2540  data_time: 0.0151  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:47 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 1619  total_loss: 0.812  loss_cls: 0.255  loss_box_reg: 0.405  loss_rpn_cls: 0.068  loss_rpn_loc: 0.046  time: 0.2540  data_time: 0.0237  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:52 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 1639  total_loss: 0.830  loss_cls: 0.243  loss_box_reg: 0.472  loss_rpn_cls: 0.046  loss_rpn_loc: 0.020  time: 0.2541  data_time: 0.0128  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:37:57 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 1659  total_loss: 0.653  loss_cls: 0.194  loss_box_reg: 0.369  loss_rpn_cls: 0.050  loss_rpn_loc: 0.035  time: 0.2539  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:02 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 1679  total_loss: 0.721  loss_cls: 0.262  loss_box_reg: 0.387  loss_rpn_cls: 0.069  loss_rpn_loc: 0.047  time: 0.2539  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:07 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 1699  total_loss: 0.835  loss_cls: 0.357  loss_box_reg: 0.417  loss_rpn_cls: 0.088  loss_rpn_loc: 0.032  time: 0.2538  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:12 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 1719  total_loss: 0.717  loss_cls: 0.271  loss_box_reg: 0.379  loss_rpn_cls: 0.084  loss_rpn_loc: 0.055  time: 0.2537  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:17 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1739  total_loss: 0.757  loss_cls: 0.260  loss_box_reg: 0.350  loss_rpn_cls: 0.086  loss_rpn_loc: 0.062  time: 0.2537  data_time: 0.0082  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:22 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 1759  total_loss: 0.896  loss_cls: 0.254  loss_box_reg: 0.392  loss_rpn_cls: 0.081  loss_rpn_loc: 0.038  time: 0.2536  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:27 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 1779  total_loss: 0.854  loss_cls: 0.227  loss_box_reg: 0.428  loss_rpn_cls: 0.070  loss_rpn_loc: 0.047  time: 0.2536  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:33 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 1799  total_loss: 0.680  loss_cls: 0.184  loss_box_reg: 0.382  loss_rpn_cls: 0.053  loss_rpn_loc: 0.029  time: 0.2537  data_time: 0.0224  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:38 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1819  total_loss: 0.670  loss_cls: 0.160  loss_box_reg: 0.366  loss_rpn_cls: 0.067  loss_rpn_loc: 0.038  time: 0.2537  data_time: 0.0174  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:43 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1839  total_loss: 0.776  loss_cls: 0.244  loss_box_reg: 0.373  loss_rpn_cls: 0.057  loss_rpn_loc: 0.038  time: 0.2537  data_time: 0.0196  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:48 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1859  total_loss: 0.810  loss_cls: 0.244  loss_box_reg: 0.427  loss_rpn_cls: 0.053  loss_rpn_loc: 0.037  time: 0.2537  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:53 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1879  total_loss: 0.792  loss_cls: 0.279  loss_box_reg: 0.403  loss_rpn_cls: 0.066  loss_rpn_loc: 0.041  time: 0.2536  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:38:58 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 1899  total_loss: 0.652  loss_cls: 0.217  loss_box_reg: 0.374  loss_rpn_cls: 0.066  loss_rpn_loc: 0.026  time: 0.2536  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:03 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1919  total_loss: 0.804  loss_cls: 0.281  loss_box_reg: 0.409  loss_rpn_cls: 0.063  loss_rpn_loc: 0.078  time: 0.2534  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:08 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1939  total_loss: 0.663  loss_cls: 0.193  loss_box_reg: 0.362  loss_rpn_cls: 0.056  loss_rpn_loc: 0.036  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:13 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 1959  total_loss: 0.754  loss_cls: 0.239  loss_box_reg: 0.421  loss_rpn_cls: 0.074  loss_rpn_loc: 0.038  time: 0.2536  data_time: 0.0334  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:18 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1979  total_loss: 0.715  loss_cls: 0.199  loss_box_reg: 0.409  loss_rpn_cls: 0.057  loss_rpn_loc: 0.041  time: 0.2536  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:23 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1999  total_loss: 0.734  loss_cls: 0.179  loss_box_reg: 0.398  loss_rpn_cls: 0.066  loss_rpn_loc: 0.063  time: 0.2535  data_time: 0.0055  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:28 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 2019  total_loss: 0.709  loss_cls: 0.274  loss_box_reg: 0.375  loss_rpn_cls: 0.051  loss_rpn_loc: 0.043  time: 0.2535  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:33 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 2039  total_loss: 0.937  loss_cls: 0.302  loss_box_reg: 0.400  loss_rpn_cls: 0.058  loss_rpn_loc: 0.050  time: 0.2534  data_time: 0.0102  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:38 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 2059  total_loss: 0.737  loss_cls: 0.244  loss_box_reg: 0.408  loss_rpn_cls: 0.075  loss_rpn_loc: 0.035  time: 0.2534  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:43 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 2079  total_loss: 0.701  loss_cls: 0.256  loss_box_reg: 0.358  loss_rpn_cls: 0.055  loss_rpn_loc: 0.046  time: 0.2534  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:49 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 2099  total_loss: 0.689  loss_cls: 0.232  loss_box_reg: 0.329  loss_rpn_cls: 0.091  loss_rpn_loc: 0.033  time: 0.2537  data_time: 0.0324  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:54 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 2119  total_loss: 0.824  loss_cls: 0.197  loss_box_reg: 0.456  loss_rpn_cls: 0.072  loss_rpn_loc: 0.032  time: 0.2536  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:39:59 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 2139  total_loss: 0.572  loss_cls: 0.127  loss_box_reg: 0.387  loss_rpn_cls: 0.037  loss_rpn_loc: 0.025  time: 0.2536  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:04 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2159  total_loss: 0.679  loss_cls: 0.229  loss_box_reg: 0.351  loss_rpn_cls: 0.048  loss_rpn_loc: 0.025  time: 0.2535  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:09 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 2179  total_loss: 0.688  loss_cls: 0.194  loss_box_reg: 0.355  loss_rpn_cls: 0.063  loss_rpn_loc: 0.054  time: 0.2535  data_time: 0.0171  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:14 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 2199  total_loss: 0.822  loss_cls: 0.213  loss_box_reg: 0.411  loss_rpn_cls: 0.063  loss_rpn_loc: 0.044  time: 0.2534  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:19 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 2219  total_loss: 0.695  loss_cls: 0.231  loss_box_reg: 0.345  loss_rpn_cls: 0.060  loss_rpn_loc: 0.042  time: 0.2534  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:24 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 2239  total_loss: 0.859  loss_cls: 0.233  loss_box_reg: 0.433  loss_rpn_cls: 0.068  loss_rpn_loc: 0.076  time: 0.2534  data_time: 0.0071  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:29 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 2259  total_loss: 0.790  loss_cls: 0.258  loss_box_reg: 0.388  loss_rpn_cls: 0.071  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:34 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 2279  total_loss: 0.744  loss_cls: 0.271  loss_box_reg: 0.375  loss_rpn_cls: 0.080  loss_rpn_loc: 0.053  time: 0.2533  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:39 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 2299  total_loss: 0.580  loss_cls: 0.134  loss_box_reg: 0.351  loss_rpn_cls: 0.047  loss_rpn_loc: 0.043  time: 0.2533  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:44 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2319  total_loss: 0.871  loss_cls: 0.253  loss_box_reg: 0.390  loss_rpn_cls: 0.090  loss_rpn_loc: 0.045  time: 0.2533  data_time: 0.0167  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:49 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 2339  total_loss: 0.746  loss_cls: 0.235  loss_box_reg: 0.367  loss_rpn_cls: 0.086  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:54 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 2359  total_loss: 0.614  loss_cls: 0.203  loss_box_reg: 0.347  loss_rpn_cls: 0.054  loss_rpn_loc: 0.022  time: 0.2533  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:40:59 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 2379  total_loss: 0.688  loss_cls: 0.200  loss_box_reg: 0.378  loss_rpn_cls: 0.067  loss_rpn_loc: 0.041  time: 0.2533  data_time: 0.0132  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:05 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 2399  total_loss: 0.699  loss_cls: 0.220  loss_box_reg: 0.358  loss_rpn_cls: 0.057  loss_rpn_loc: 0.042  time: 0.2536  data_time: 0.0386  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:10 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 2419  total_loss: 0.725  loss_cls: 0.180  loss_box_reg: 0.403  loss_rpn_cls: 0.069  loss_rpn_loc: 0.041  time: 0.2536  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:15 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 2439  total_loss: 0.701  loss_cls: 0.203  loss_box_reg: 0.358  loss_rpn_cls: 0.058  loss_rpn_loc: 0.041  time: 0.2535  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:20 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 2459  total_loss: 0.733  loss_cls: 0.166  loss_box_reg: 0.358  loss_rpn_cls: 0.083  loss_rpn_loc: 0.051  time: 0.2535  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:25 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 2479  total_loss: 0.642  loss_cls: 0.141  loss_box_reg: 0.337  loss_rpn_cls: 0.057  loss_rpn_loc: 0.061  time: 0.2535  data_time: 0.0120  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:30 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2499  total_loss: 0.802  loss_cls: 0.252  loss_box_reg: 0.425  loss_rpn_cls: 0.079  loss_rpn_loc: 0.054  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:35 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 2519  total_loss: 0.516  loss_cls: 0.153  loss_box_reg: 0.327  loss_rpn_cls: 0.047  loss_rpn_loc: 0.032  time: 0.2534  data_time: 0.0089  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:40 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 2539  total_loss: 0.844  loss_cls: 0.212  loss_box_reg: 0.434  loss_rpn_cls: 0.071  loss_rpn_loc: 0.039  time: 0.2535  data_time: 0.0203  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:45 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2559  total_loss: 0.582  loss_cls: 0.146  loss_box_reg: 0.344  loss_rpn_cls: 0.048  loss_rpn_loc: 0.024  time: 0.2534  data_time: 0.0053  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:50 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 2579  total_loss: 0.703  loss_cls: 0.231  loss_box_reg: 0.365  loss_rpn_cls: 0.048  loss_rpn_loc: 0.044  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:41:55 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 2599  total_loss: 0.698  loss_cls: 0.203  loss_box_reg: 0.354  loss_rpn_cls: 0.051  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:01 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 2619  total_loss: 0.695  loss_cls: 0.186  loss_box_reg: 0.329  loss_rpn_cls: 0.056  loss_rpn_loc: 0.048  time: 0.2534  data_time: 0.0192  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:06 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 2639  total_loss: 0.701  loss_cls: 0.188  loss_box_reg: 0.341  loss_rpn_cls: 0.065  loss_rpn_loc: 0.048  time: 0.2534  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:11 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 2659  total_loss: 0.601  loss_cls: 0.169  loss_box_reg: 0.344  loss_rpn_cls: 0.047  loss_rpn_loc: 0.040  time: 0.2534  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:15 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2679  total_loss: 0.722  loss_cls: 0.160  loss_box_reg: 0.327  loss_rpn_cls: 0.070  loss_rpn_loc: 0.068  time: 0.2533  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:21 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 2699  total_loss: 0.711  loss_cls: 0.283  loss_box_reg: 0.339  loss_rpn_cls: 0.058  loss_rpn_loc: 0.048  time: 0.2533  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:26 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 2719  total_loss: 0.607  loss_cls: 0.176  loss_box_reg: 0.328  loss_rpn_cls: 0.044  loss_rpn_loc: 0.050  time: 0.2533  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:31 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 2739  total_loss: 0.678  loss_cls: 0.199  loss_box_reg: 0.365  loss_rpn_cls: 0.048  loss_rpn_loc: 0.036  time: 0.2533  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:36 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 2759  total_loss: 0.717  loss_cls: 0.172  loss_box_reg: 0.365  loss_rpn_cls: 0.061  loss_rpn_loc: 0.050  time: 0.2534  data_time: 0.0138  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:41 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 2779  total_loss: 0.558  loss_cls: 0.157  loss_box_reg: 0.313  loss_rpn_cls: 0.028  loss_rpn_loc: 0.023  time: 0.2535  data_time: 0.0237  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:46 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 2799  total_loss: 0.760  loss_cls: 0.236  loss_box_reg: 0.371  loss_rpn_cls: 0.060  loss_rpn_loc: 0.027  time: 0.2535  data_time: 0.0123  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:51 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2819  total_loss: 0.780  loss_cls: 0.242  loss_box_reg: 0.370  loss_rpn_cls: 0.083  loss_rpn_loc: 0.067  time: 0.2534  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:42:57 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 2839  total_loss: 0.716  loss_cls: 0.224  loss_box_reg: 0.342  loss_rpn_cls: 0.067  loss_rpn_loc: 0.046  time: 0.2534  data_time: 0.0187  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:01 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 2859  total_loss: 0.657  loss_cls: 0.194  loss_box_reg: 0.369  loss_rpn_cls: 0.042  loss_rpn_loc: 0.027  time: 0.2534  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:06 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2879  total_loss: 0.642  loss_cls: 0.133  loss_box_reg: 0.330  loss_rpn_cls: 0.070  loss_rpn_loc: 0.044  time: 0.2533  data_time: 0.0081  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:12 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2899  total_loss: 0.692  loss_cls: 0.226  loss_box_reg: 0.358  loss_rpn_cls: 0.050  loss_rpn_loc: 0.036  time: 0.2533  data_time: 0.0128  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:16 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 2919  total_loss: 0.746  loss_cls: 0.214  loss_box_reg: 0.394  loss_rpn_cls: 0.059  loss_rpn_loc: 0.057  time: 0.2533  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:22 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 2939  total_loss: 0.590  loss_cls: 0.122  loss_box_reg: 0.314  loss_rpn_cls: 0.039  loss_rpn_loc: 0.027  time: 0.2533  data_time: 0.0107  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:26 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2959  total_loss: 0.586  loss_cls: 0.121  loss_box_reg: 0.354  loss_rpn_cls: 0.051  loss_rpn_loc: 0.035  time: 0.2532  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:32 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 2979  total_loss: 0.723  loss_cls: 0.183  loss_box_reg: 0.355  loss_rpn_cls: 0.068  loss_rpn_loc: 0.064  time: 0.2532  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:37 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 2999  total_loss: 0.551  loss_cls: 0.164  loss_box_reg: 0.281  loss_rpn_cls: 0.035  loss_rpn_loc: 0.028  time: 0.2532  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:42 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 3019  total_loss: 0.662  loss_cls: 0.187  loss_box_reg: 0.369  loss_rpn_cls: 0.045  loss_rpn_loc: 0.044  time: 0.2532  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:47 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 3039  total_loss: 0.611  loss_cls: 0.157  loss_box_reg: 0.329  loss_rpn_cls: 0.040  loss_rpn_loc: 0.043  time: 0.2532  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:51 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 3059  total_loss: 0.531  loss_cls: 0.150  loss_box_reg: 0.278  loss_rpn_cls: 0.039  loss_rpn_loc: 0.043  time: 0.2531  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:43:57 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 3079  total_loss: 0.624  loss_cls: 0.198  loss_box_reg: 0.296  loss_rpn_cls: 0.039  loss_rpn_loc: 0.031  time: 0.2531  data_time: 0.0118  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:02 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 3099  total_loss: 0.632  loss_cls: 0.161  loss_box_reg: 0.330  loss_rpn_cls: 0.059  loss_rpn_loc: 0.052  time: 0.2533  data_time: 0.0476  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:07 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 3119  total_loss: 0.777  loss_cls: 0.206  loss_box_reg: 0.350  loss_rpn_cls: 0.067  loss_rpn_loc: 0.059  time: 0.2533  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:13 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 3139  total_loss: 0.782  loss_cls: 0.235  loss_box_reg: 0.417  loss_rpn_cls: 0.046  loss_rpn_loc: 0.040  time: 0.2533  data_time: 0.0151  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:17 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 3159  total_loss: 0.617  loss_cls: 0.159  loss_box_reg: 0.334  loss_rpn_cls: 0.038  loss_rpn_loc: 0.041  time: 0.2533  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:23 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 3179  total_loss: 0.500  loss_cls: 0.144  loss_box_reg: 0.312  loss_rpn_cls: 0.034  loss_rpn_loc: 0.024  time: 0.2533  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:28 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 3199  total_loss: 0.526  loss_cls: 0.111  loss_box_reg: 0.337  loss_rpn_cls: 0.025  loss_rpn_loc: 0.035  time: 0.2533  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:33 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 3219  total_loss: 0.632  loss_cls: 0.146  loss_box_reg: 0.325  loss_rpn_cls: 0.057  loss_rpn_loc: 0.035  time: 0.2533  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:38 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 3239  total_loss: 0.589  loss_cls: 0.139  loss_box_reg: 0.348  loss_rpn_cls: 0.041  loss_rpn_loc: 0.031  time: 0.2533  data_time: 0.0168  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:43 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 3259  total_loss: 0.648  loss_cls: 0.154  loss_box_reg: 0.342  loss_rpn_cls: 0.043  loss_rpn_loc: 0.049  time: 0.2533  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:48 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 3279  total_loss: 0.606  loss_cls: 0.144  loss_box_reg: 0.330  loss_rpn_cls: 0.048  loss_rpn_loc: 0.028  time: 0.2533  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:53 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 3299  total_loss: 0.666  loss_cls: 0.210  loss_box_reg: 0.363  loss_rpn_cls: 0.074  loss_rpn_loc: 0.073  time: 0.2532  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:44:58 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 3319  total_loss: 0.654  loss_cls: 0.153  loss_box_reg: 0.358  loss_rpn_cls: 0.049  loss_rpn_loc: 0.041  time: 0.2532  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:03 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 3339  total_loss: 0.675  loss_cls: 0.206  loss_box_reg: 0.327  loss_rpn_cls: 0.056  loss_rpn_loc: 0.044  time: 0.2532  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:08 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 3359  total_loss: 0.684  loss_cls: 0.197  loss_box_reg: 0.313  loss_rpn_cls: 0.045  loss_rpn_loc: 0.038  time: 0.2532  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:13 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 3379  total_loss: 0.660  loss_cls: 0.155  loss_box_reg: 0.328  loss_rpn_cls: 0.052  loss_rpn_loc: 0.039  time: 0.2531  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:18 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 3399  total_loss: 0.722  loss_cls: 0.185  loss_box_reg: 0.356  loss_rpn_cls: 0.062  loss_rpn_loc: 0.031  time: 0.2533  data_time: 0.0442  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:23 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 3419  total_loss: 0.661  loss_cls: 0.156  loss_box_reg: 0.363  loss_rpn_cls: 0.068  loss_rpn_loc: 0.028  time: 0.2533  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:29 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 3439  total_loss: 0.722  loss_cls: 0.198  loss_box_reg: 0.379  loss_rpn_cls: 0.058  loss_rpn_loc: 0.054  time: 0.2533  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:33 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 3459  total_loss: 0.605  loss_cls: 0.158  loss_box_reg: 0.364  loss_rpn_cls: 0.046  loss_rpn_loc: 0.029  time: 0.2532  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:39 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3479  total_loss: 0.804  loss_cls: 0.268  loss_box_reg: 0.380  loss_rpn_cls: 0.056  loss_rpn_loc: 0.045  time: 0.2534  data_time: 0.0483  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:44 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 3499  total_loss: 0.550  loss_cls: 0.176  loss_box_reg: 0.294  loss_rpn_cls: 0.046  loss_rpn_loc: 0.021  time: 0.2533  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:49 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 3519  total_loss: 0.550  loss_cls: 0.102  loss_box_reg: 0.299  loss_rpn_cls: 0.042  loss_rpn_loc: 0.030  time: 0.2534  data_time: 0.0120  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:54 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 3539  total_loss: 0.540  loss_cls: 0.146  loss_box_reg: 0.280  loss_rpn_cls: 0.056  loss_rpn_loc: 0.034  time: 0.2533  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:45:59 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3559  total_loss: 0.503  loss_cls: 0.122  loss_box_reg: 0.298  loss_rpn_cls: 0.032  loss_rpn_loc: 0.038  time: 0.2533  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:04 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 3579  total_loss: 0.419  loss_cls: 0.073  loss_box_reg: 0.288  loss_rpn_cls: 0.035  loss_rpn_loc: 0.024  time: 0.2534  data_time: 0.0125  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:10 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 3599  total_loss: 0.666  loss_cls: 0.124  loss_box_reg: 0.383  loss_rpn_cls: 0.050  loss_rpn_loc: 0.058  time: 0.2534  data_time: 0.0325  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:15 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 3619  total_loss: 0.579  loss_cls: 0.137  loss_box_reg: 0.339  loss_rpn_cls: 0.043  loss_rpn_loc: 0.049  time: 0.2534  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:20 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3639  total_loss: 0.612  loss_cls: 0.211  loss_box_reg: 0.301  loss_rpn_cls: 0.046  loss_rpn_loc: 0.033  time: 0.2534  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:25 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 3659  total_loss: 0.631  loss_cls: 0.115  loss_box_reg: 0.313  loss_rpn_cls: 0.037  loss_rpn_loc: 0.027  time: 0.2534  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:30 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3679  total_loss: 0.599  loss_cls: 0.182  loss_box_reg: 0.337  loss_rpn_cls: 0.057  loss_rpn_loc: 0.027  time: 0.2534  data_time: 0.0166  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:35 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 3699  total_loss: 0.583  loss_cls: 0.162  loss_box_reg: 0.328  loss_rpn_cls: 0.057  loss_rpn_loc: 0.029  time: 0.2534  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:40 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 3719  total_loss: 0.531  loss_cls: 0.099  loss_box_reg: 0.314  loss_rpn_cls: 0.041  loss_rpn_loc: 0.036  time: 0.2534  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:45 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3739  total_loss: 0.626  loss_cls: 0.149  loss_box_reg: 0.313  loss_rpn_cls: 0.033  loss_rpn_loc: 0.033  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:50 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 3759  total_loss: 0.545  loss_cls: 0.122  loss_box_reg: 0.339  loss_rpn_cls: 0.035  loss_rpn_loc: 0.022  time: 0.2534  data_time: 0.0085  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:46:56 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 3779  total_loss: 0.551  loss_cls: 0.116  loss_box_reg: 0.305  loss_rpn_cls: 0.050  loss_rpn_loc: 0.038  time: 0.2535  data_time: 0.0360  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:01 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 3799  total_loss: 0.626  loss_cls: 0.196  loss_box_reg: 0.341  loss_rpn_cls: 0.040  loss_rpn_loc: 0.042  time: 0.2535  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:06 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 3819  total_loss: 0.571  loss_cls: 0.145  loss_box_reg: 0.334  loss_rpn_cls: 0.031  loss_rpn_loc: 0.030  time: 0.2535  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:11 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 3839  total_loss: 0.605  loss_cls: 0.180  loss_box_reg: 0.323  loss_rpn_cls: 0.056  loss_rpn_loc: 0.047  time: 0.2535  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:16 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 3859  total_loss: 0.566  loss_cls: 0.134  loss_box_reg: 0.306  loss_rpn_cls: 0.056  loss_rpn_loc: 0.032  time: 0.2535  data_time: 0.0207  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:21 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 3879  total_loss: 0.475  loss_cls: 0.139  loss_box_reg: 0.286  loss_rpn_cls: 0.038  loss_rpn_loc: 0.031  time: 0.2535  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:26 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 3899  total_loss: 0.559  loss_cls: 0.154  loss_box_reg: 0.307  loss_rpn_cls: 0.059  loss_rpn_loc: 0.043  time: 0.2535  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:31 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3919  total_loss: 0.551  loss_cls: 0.128  loss_box_reg: 0.320  loss_rpn_cls: 0.038  loss_rpn_loc: 0.033  time: 0.2534  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:36 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 3939  total_loss: 0.597  loss_cls: 0.165  loss_box_reg: 0.337  loss_rpn_cls: 0.055  loss_rpn_loc: 0.035  time: 0.2534  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:41 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 3959  total_loss: 0.746  loss_cls: 0.194  loss_box_reg: 0.379  loss_rpn_cls: 0.072  loss_rpn_loc: 0.076  time: 0.2534  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:46 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 3979  total_loss: 0.578  loss_cls: 0.129  loss_box_reg: 0.307  loss_rpn_cls: 0.053  loss_rpn_loc: 0.033  time: 0.2534  data_time: 0.0142  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.619  loss_cls: 0.160  loss_box_reg: 0.279  loss_rpn_cls: 0.043  loss_rpn_loc: 0.029  time: 0.2534  data_time: 0.0205  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.655  loss_cls: 0.175  loss_box_reg: 0.291  loss_rpn_cls: 0.038  loss_rpn_loc: 0.029  time: 0.2534  data_time: 0.0206  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:47:52 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:16:53 (0.2535 s / it)\n",
            "\u001b[32m[05/04 02:47:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:57 (0:00:03 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:47:53 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:47:53 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 02:47:53 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:47:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 02:47:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 02:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1313 s / img. ETA=0:00:25\n",
            "\u001b[32m[05/04 02:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 44/206. 0.1517 s / img. ETA=0:00:24\n",
            "\u001b[32m[05/04 02:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 69/206. 0.1704 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 02:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 100/206. 0.1686 s / img. ETA=0:00:18\n",
            "\u001b[32m[05/04 02:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 131/206. 0.1667 s / img. ETA=0:00:12\n",
            "\u001b[32m[05/04 02:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 163/206. 0.1655 s / img. ETA=0:00:07\n",
            "\u001b[32m[05/04 02:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 198/206. 0.1616 s / img. ETA=0:00:01\n",
            "\u001b[32m[05/04 02:48:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.808365 (0.163226 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:48:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:32 (0.160919 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 02:48:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 02:48:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64/coco_instances_results.json\n",
            "\u001b[32m[05/04 02:48:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.85s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.23s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.389\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.496\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
            "\u001b[32m[05/04 02:48:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.414 | 61.594 | 43.522 | 19.391 | 33.584 | 46.960 |\n",
            "\u001b[32m[05/04 02:48:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 39.240 | tomato_fruit       | 24.861 | tomato_seedling          | 31.404 |\n",
            "| tomato_young_plant      | 51.838 | tomato_flower      | 37.384 | bell_pepper_fruit        | 58.687 |\n",
            "| bell_pepper_young_plant | 26.562 | bell_pepper_flower | 43.754 | bell_pepper_fruit_unripe | 33.060 |\n",
            "| bell_pepper_seedling    | 18.612 | cucumber_flower    | 57.354 | cucumber_plant           | 17.789 |\n",
            "| cucumber_seedling       | 30.836 | cucumber_fruit     | 63.356 | cucumber_fruit_unripe    | 41.473 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_64___2.png\n",
            "\u001b[32m[05/04 02:48:29 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): Res5ROIHeads(\n",
            "    (pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=2048, out_features=16, bias=True)\n",
            "      (bbox_pred): Linear(in_features=2048, out_features=60, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 02:48:30 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 02:48:30 d2.data.datasets.coco]: \u001b[0mLoaded 1166 images in COCO format from greenthumbs/data/v01/train_85%_coco.json\n",
            "\u001b[32m[05/04 02:48:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1166 images left.\n",
            "\u001b[32m[05/04 02:48:30 d2.data.common]: \u001b[0mSerializing 1166 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 02:48:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[05/04 02:48:30 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/04 02:48:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "**********************************************\n",
            "\t\t Begin train v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128\n",
            "**********************************************\n",
            "\u001b[32m[05/04 02:48:30 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/04 02:48:37 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 19  total_loss: 3.719  loss_cls: 2.719  loss_box_reg: 0.751  loss_rpn_cls: 0.199  loss_rpn_loc: 0.049  time: 0.3298  data_time: 0.0251  lr: 0.000010  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:48:43 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 39  total_loss: 3.466  loss_cls: 2.450  loss_box_reg: 0.761  loss_rpn_cls: 0.214  loss_rpn_loc: 0.071  time: 0.3265  data_time: 0.0065  lr: 0.000020  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:48:51 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 59  total_loss: 2.688  loss_cls: 1.834  loss_box_reg: 0.642  loss_rpn_cls: 0.186  loss_rpn_loc: 0.040  time: 0.3411  data_time: 0.0508  lr: 0.000030  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:48:57 d2.utils.events]: \u001b[0m eta: 0:21:11  iter: 79  total_loss: 2.055  loss_cls: 1.080  loss_box_reg: 0.725  loss_rpn_cls: 0.182  loss_rpn_loc: 0.060  time: 0.3368  data_time: 0.0064  lr: 0.000040  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:04 d2.utils.events]: \u001b[0m eta: 0:21:09  iter: 99  total_loss: 2.181  loss_cls: 1.041  loss_box_reg: 0.843  loss_rpn_cls: 0.162  loss_rpn_loc: 0.045  time: 0.3351  data_time: 0.0068  lr: 0.000050  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:10 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 119  total_loss: 1.937  loss_cls: 0.959  loss_box_reg: 0.749  loss_rpn_cls: 0.191  loss_rpn_loc: 0.084  time: 0.3328  data_time: 0.0060  lr: 0.000060  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:17 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 139  total_loss: 2.060  loss_cls: 0.957  loss_box_reg: 0.789  loss_rpn_cls: 0.151  loss_rpn_loc: 0.042  time: 0.3314  data_time: 0.0067  lr: 0.000070  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:23 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 159  total_loss: 1.889  loss_cls: 0.834  loss_box_reg: 0.776  loss_rpn_cls: 0.168  loss_rpn_loc: 0.079  time: 0.3320  data_time: 0.0112  lr: 0.000080  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:30 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 179  total_loss: 1.844  loss_cls: 0.839  loss_box_reg: 0.746  loss_rpn_cls: 0.183  loss_rpn_loc: 0.071  time: 0.3314  data_time: 0.0057  lr: 0.000090  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:37 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 199  total_loss: 1.719  loss_cls: 0.688  loss_box_reg: 0.692  loss_rpn_cls: 0.148  loss_rpn_loc: 0.042  time: 0.3315  data_time: 0.0065  lr: 0.000100  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:43 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 219  total_loss: 1.832  loss_cls: 0.809  loss_box_reg: 0.863  loss_rpn_cls: 0.142  loss_rpn_loc: 0.048  time: 0.3309  data_time: 0.0069  lr: 0.000110  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:50 d2.utils.events]: \u001b[0m eta: 0:20:27  iter: 239  total_loss: 1.860  loss_cls: 0.746  loss_box_reg: 0.701  loss_rpn_cls: 0.158  loss_rpn_loc: 0.059  time: 0.3342  data_time: 0.0547  lr: 0.000120  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:49:57 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 259  total_loss: 1.845  loss_cls: 0.753  loss_box_reg: 0.802  loss_rpn_cls: 0.164  loss_rpn_loc: 0.041  time: 0.3341  data_time: 0.0120  lr: 0.000130  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:03 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 279  total_loss: 1.694  loss_cls: 0.757  loss_box_reg: 0.817  loss_rpn_cls: 0.127  loss_rpn_loc: 0.036  time: 0.3322  data_time: 0.0061  lr: 0.000140  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:10 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 299  total_loss: 1.779  loss_cls: 0.721  loss_box_reg: 0.816  loss_rpn_cls: 0.154  loss_rpn_loc: 0.067  time: 0.3317  data_time: 0.0059  lr: 0.000150  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:16 d2.utils.events]: \u001b[0m eta: 0:19:58  iter: 319  total_loss: 1.596  loss_cls: 0.648  loss_box_reg: 0.760  loss_rpn_cls: 0.106  loss_rpn_loc: 0.044  time: 0.3311  data_time: 0.0100  lr: 0.000160  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:23 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 339  total_loss: 1.620  loss_cls: 0.604  loss_box_reg: 0.786  loss_rpn_cls: 0.141  loss_rpn_loc: 0.085  time: 0.3307  data_time: 0.0061  lr: 0.000170  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:29 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 359  total_loss: 1.538  loss_cls: 0.620  loss_box_reg: 0.796  loss_rpn_cls: 0.105  loss_rpn_loc: 0.053  time: 0.3308  data_time: 0.0063  lr: 0.000180  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:36 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 379  total_loss: 1.460  loss_cls: 0.533  loss_box_reg: 0.766  loss_rpn_cls: 0.104  loss_rpn_loc: 0.045  time: 0.3307  data_time: 0.0103  lr: 0.000190  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:43 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 399  total_loss: 1.664  loss_cls: 0.682  loss_box_reg: 0.783  loss_rpn_cls: 0.150  loss_rpn_loc: 0.077  time: 0.3304  data_time: 0.0065  lr: 0.000200  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:49 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 419  total_loss: 1.487  loss_cls: 0.551  loss_box_reg: 0.726  loss_rpn_cls: 0.143  loss_rpn_loc: 0.045  time: 0.3302  data_time: 0.0060  lr: 0.000210  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:50:56 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 439  total_loss: 1.168  loss_cls: 0.466  loss_box_reg: 0.615  loss_rpn_cls: 0.133  loss_rpn_loc: 0.035  time: 0.3301  data_time: 0.0062  lr: 0.000220  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:02 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 459  total_loss: 1.520  loss_cls: 0.575  loss_box_reg: 0.732  loss_rpn_cls: 0.139  loss_rpn_loc: 0.057  time: 0.3300  data_time: 0.0123  lr: 0.000230  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:09 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 479  total_loss: 1.146  loss_cls: 0.408  loss_box_reg: 0.632  loss_rpn_cls: 0.123  loss_rpn_loc: 0.052  time: 0.3299  data_time: 0.0064  lr: 0.000240  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:15 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 499  total_loss: 1.355  loss_cls: 0.500  loss_box_reg: 0.687  loss_rpn_cls: 0.109  loss_rpn_loc: 0.048  time: 0.3298  data_time: 0.0085  lr: 0.000250  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:22 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 519  total_loss: 1.269  loss_cls: 0.395  loss_box_reg: 0.646  loss_rpn_cls: 0.129  loss_rpn_loc: 0.051  time: 0.3296  data_time: 0.0062  lr: 0.000260  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:28 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 539  total_loss: 1.348  loss_cls: 0.518  loss_box_reg: 0.661  loss_rpn_cls: 0.117  loss_rpn_loc: 0.045  time: 0.3292  data_time: 0.0061  lr: 0.000270  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:35 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 559  total_loss: 1.350  loss_cls: 0.482  loss_box_reg: 0.595  loss_rpn_cls: 0.118  loss_rpn_loc: 0.034  time: 0.3290  data_time: 0.0059  lr: 0.000280  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:41 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 579  total_loss: 1.291  loss_cls: 0.482  loss_box_reg: 0.568  loss_rpn_cls: 0.128  loss_rpn_loc: 0.053  time: 0.3290  data_time: 0.0068  lr: 0.000290  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:48 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 599  total_loss: 1.040  loss_cls: 0.356  loss_box_reg: 0.521  loss_rpn_cls: 0.096  loss_rpn_loc: 0.044  time: 0.3288  data_time: 0.0065  lr: 0.000300  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:51:54 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 619  total_loss: 1.267  loss_cls: 0.480  loss_box_reg: 0.596  loss_rpn_cls: 0.116  loss_rpn_loc: 0.051  time: 0.3284  data_time: 0.0062  lr: 0.000310  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:01 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 639  total_loss: 1.155  loss_cls: 0.390  loss_box_reg: 0.563  loss_rpn_cls: 0.091  loss_rpn_loc: 0.057  time: 0.3282  data_time: 0.0058  lr: 0.000320  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:07 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 659  total_loss: 1.185  loss_cls: 0.410  loss_box_reg: 0.567  loss_rpn_cls: 0.099  loss_rpn_loc: 0.042  time: 0.3280  data_time: 0.0059  lr: 0.000330  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:14 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 679  total_loss: 1.003  loss_cls: 0.414  loss_box_reg: 0.463  loss_rpn_cls: 0.077  loss_rpn_loc: 0.048  time: 0.3280  data_time: 0.0059  lr: 0.000340  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:20 d2.utils.events]: \u001b[0m eta: 0:17:53  iter: 699  total_loss: 1.001  loss_cls: 0.410  loss_box_reg: 0.483  loss_rpn_cls: 0.107  loss_rpn_loc: 0.047  time: 0.3279  data_time: 0.0070  lr: 0.000350  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:27 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 719  total_loss: 0.968  loss_cls: 0.317  loss_box_reg: 0.463  loss_rpn_cls: 0.097  loss_rpn_loc: 0.035  time: 0.3278  data_time: 0.0061  lr: 0.000360  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:33 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 739  total_loss: 1.049  loss_cls: 0.429  loss_box_reg: 0.462  loss_rpn_cls: 0.092  loss_rpn_loc: 0.055  time: 0.3280  data_time: 0.0249  lr: 0.000370  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:40 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 759  total_loss: 1.003  loss_cls: 0.426  loss_box_reg: 0.463  loss_rpn_cls: 0.092  loss_rpn_loc: 0.053  time: 0.3283  data_time: 0.0168  lr: 0.000380  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:47 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 779  total_loss: 0.974  loss_cls: 0.288  loss_box_reg: 0.440  loss_rpn_cls: 0.104  loss_rpn_loc: 0.053  time: 0.3281  data_time: 0.0058  lr: 0.000390  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:53 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 799  total_loss: 1.005  loss_cls: 0.341  loss_box_reg: 0.506  loss_rpn_cls: 0.098  loss_rpn_loc: 0.051  time: 0.3279  data_time: 0.0058  lr: 0.000400  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:52:59 d2.utils.events]: \u001b[0m eta: 0:17:14  iter: 819  total_loss: 1.005  loss_cls: 0.359  loss_box_reg: 0.432  loss_rpn_cls: 0.097  loss_rpn_loc: 0.036  time: 0.3278  data_time: 0.0066  lr: 0.000410  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:06 d2.utils.events]: \u001b[0m eta: 0:17:07  iter: 839  total_loss: 0.907  loss_cls: 0.354  loss_box_reg: 0.421  loss_rpn_cls: 0.081  loss_rpn_loc: 0.040  time: 0.3276  data_time: 0.0055  lr: 0.000420  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:12 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 859  total_loss: 1.065  loss_cls: 0.377  loss_box_reg: 0.424  loss_rpn_cls: 0.103  loss_rpn_loc: 0.055  time: 0.3275  data_time: 0.0061  lr: 0.000430  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:19 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 879  total_loss: 1.045  loss_cls: 0.375  loss_box_reg: 0.536  loss_rpn_cls: 0.077  loss_rpn_loc: 0.045  time: 0.3275  data_time: 0.0075  lr: 0.000440  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:25 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 899  total_loss: 1.229  loss_cls: 0.439  loss_box_reg: 0.481  loss_rpn_cls: 0.102  loss_rpn_loc: 0.035  time: 0.3273  data_time: 0.0089  lr: 0.000450  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:32 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 919  total_loss: 0.901  loss_cls: 0.367  loss_box_reg: 0.366  loss_rpn_cls: 0.099  loss_rpn_loc: 0.047  time: 0.3272  data_time: 0.0063  lr: 0.000460  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:38 d2.utils.events]: \u001b[0m eta: 0:16:35  iter: 939  total_loss: 0.894  loss_cls: 0.361  loss_box_reg: 0.418  loss_rpn_cls: 0.062  loss_rpn_loc: 0.027  time: 0.3271  data_time: 0.0064  lr: 0.000470  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:45 d2.utils.events]: \u001b[0m eta: 0:16:28  iter: 959  total_loss: 0.810  loss_cls: 0.252  loss_box_reg: 0.422  loss_rpn_cls: 0.089  loss_rpn_loc: 0.042  time: 0.3269  data_time: 0.0059  lr: 0.000480  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:51 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 979  total_loss: 0.803  loss_cls: 0.250  loss_box_reg: 0.411  loss_rpn_cls: 0.099  loss_rpn_loc: 0.044  time: 0.3270  data_time: 0.0056  lr: 0.000490  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:53:58 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 999  total_loss: 0.896  loss_cls: 0.358  loss_box_reg: 0.405  loss_rpn_cls: 0.085  loss_rpn_loc: 0.056  time: 0.3269  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:04 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 1019  total_loss: 0.833  loss_cls: 0.301  loss_box_reg: 0.431  loss_rpn_cls: 0.082  loss_rpn_loc: 0.050  time: 0.3268  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:11 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 1039  total_loss: 0.988  loss_cls: 0.278  loss_box_reg: 0.379  loss_rpn_cls: 0.112  loss_rpn_loc: 0.052  time: 0.3267  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:17 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 1059  total_loss: 0.903  loss_cls: 0.283  loss_box_reg: 0.438  loss_rpn_cls: 0.092  loss_rpn_loc: 0.053  time: 0.3267  data_time: 0.0155  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:24 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 1079  total_loss: 0.825  loss_cls: 0.314  loss_box_reg: 0.431  loss_rpn_cls: 0.078  loss_rpn_loc: 0.043  time: 0.3269  data_time: 0.0237  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:30 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 1099  total_loss: 0.994  loss_cls: 0.287  loss_box_reg: 0.475  loss_rpn_cls: 0.071  loss_rpn_loc: 0.068  time: 0.3268  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:37 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 1119  total_loss: 0.857  loss_cls: 0.295  loss_box_reg: 0.411  loss_rpn_cls: 0.062  loss_rpn_loc: 0.043  time: 0.3268  data_time: 0.0097  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:43 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 1139  total_loss: 0.821  loss_cls: 0.265  loss_box_reg: 0.400  loss_rpn_cls: 0.092  loss_rpn_loc: 0.029  time: 0.3266  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:50 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 1159  total_loss: 0.690  loss_cls: 0.235  loss_box_reg: 0.347  loss_rpn_cls: 0.086  loss_rpn_loc: 0.052  time: 0.3265  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:54:56 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 1179  total_loss: 0.674  loss_cls: 0.177  loss_box_reg: 0.346  loss_rpn_cls: 0.063  loss_rpn_loc: 0.024  time: 0.3266  data_time: 0.0079  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:03 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 1199  total_loss: 0.683  loss_cls: 0.231  loss_box_reg: 0.404  loss_rpn_cls: 0.063  loss_rpn_loc: 0.044  time: 0.3268  data_time: 0.0209  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:09 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 1219  total_loss: 0.939  loss_cls: 0.277  loss_box_reg: 0.442  loss_rpn_cls: 0.093  loss_rpn_loc: 0.040  time: 0.3265  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:16 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 1239  total_loss: 0.903  loss_cls: 0.253  loss_box_reg: 0.414  loss_rpn_cls: 0.127  loss_rpn_loc: 0.080  time: 0.3264  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:22 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 1259  total_loss: 0.763  loss_cls: 0.268  loss_box_reg: 0.316  loss_rpn_cls: 0.083  loss_rpn_loc: 0.045  time: 0.3264  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:29 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 1279  total_loss: 0.804  loss_cls: 0.272  loss_box_reg: 0.339  loss_rpn_cls: 0.082  loss_rpn_loc: 0.037  time: 0.3264  data_time: 0.0107  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:35 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 1299  total_loss: 0.730  loss_cls: 0.256  loss_box_reg: 0.393  loss_rpn_cls: 0.059  loss_rpn_loc: 0.036  time: 0.3264  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:42 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 1319  total_loss: 0.756  loss_cls: 0.245  loss_box_reg: 0.385  loss_rpn_cls: 0.075  loss_rpn_loc: 0.042  time: 0.3263  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:48 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 1339  total_loss: 0.698  loss_cls: 0.194  loss_box_reg: 0.354  loss_rpn_cls: 0.074  loss_rpn_loc: 0.047  time: 0.3261  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:55:55 d2.utils.events]: \u001b[0m eta: 0:14:14  iter: 1359  total_loss: 0.557  loss_cls: 0.172  loss_box_reg: 0.316  loss_rpn_cls: 0.054  loss_rpn_loc: 0.031  time: 0.3260  data_time: 0.0103  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:01 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 1379  total_loss: 0.772  loss_cls: 0.196  loss_box_reg: 0.347  loss_rpn_cls: 0.091  loss_rpn_loc: 0.052  time: 0.3261  data_time: 0.0146  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:08 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 1399  total_loss: 0.808  loss_cls: 0.261  loss_box_reg: 0.384  loss_rpn_cls: 0.054  loss_rpn_loc: 0.037  time: 0.3261  data_time: 0.0086  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:14 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 1419  total_loss: 0.826  loss_cls: 0.287  loss_box_reg: 0.382  loss_rpn_cls: 0.049  loss_rpn_loc: 0.043  time: 0.3260  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:21 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 1439  total_loss: 0.938  loss_cls: 0.352  loss_box_reg: 0.431  loss_rpn_cls: 0.075  loss_rpn_loc: 0.035  time: 0.3259  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:27 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 1459  total_loss: 0.935  loss_cls: 0.327  loss_box_reg: 0.348  loss_rpn_cls: 0.073  loss_rpn_loc: 0.079  time: 0.3258  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:33 d2.utils.events]: \u001b[0m eta: 0:13:34  iter: 1479  total_loss: 0.741  loss_cls: 0.257  loss_box_reg: 0.372  loss_rpn_cls: 0.066  loss_rpn_loc: 0.032  time: 0.3258  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:40 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 1499  total_loss: 0.567  loss_cls: 0.186  loss_box_reg: 0.290  loss_rpn_cls: 0.050  loss_rpn_loc: 0.037  time: 0.3258  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:47 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 1519  total_loss: 0.640  loss_cls: 0.176  loss_box_reg: 0.300  loss_rpn_cls: 0.079  loss_rpn_loc: 0.047  time: 0.3259  data_time: 0.0115  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:56:53 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 1539  total_loss: 0.816  loss_cls: 0.279  loss_box_reg: 0.399  loss_rpn_cls: 0.062  loss_rpn_loc: 0.042  time: 0.3259  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:00 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 1559  total_loss: 0.721  loss_cls: 0.252  loss_box_reg: 0.331  loss_rpn_cls: 0.070  loss_rpn_loc: 0.022  time: 0.3260  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:07 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1579  total_loss: 0.696  loss_cls: 0.216  loss_box_reg: 0.330  loss_rpn_cls: 0.068  loss_rpn_loc: 0.037  time: 0.3262  data_time: 0.0228  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:13 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 1599  total_loss: 0.781  loss_cls: 0.228  loss_box_reg: 0.418  loss_rpn_cls: 0.057  loss_rpn_loc: 0.060  time: 0.3263  data_time: 0.0122  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:20 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 1619  total_loss: 0.724  loss_cls: 0.293  loss_box_reg: 0.330  loss_rpn_cls: 0.079  loss_rpn_loc: 0.056  time: 0.3261  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:26 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 1639  total_loss: 0.669  loss_cls: 0.208  loss_box_reg: 0.367  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 0.3262  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:33 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 1659  total_loss: 0.961  loss_cls: 0.337  loss_box_reg: 0.375  loss_rpn_cls: 0.095  loss_rpn_loc: 0.102  time: 0.3262  data_time: 0.0075  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:39 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 1679  total_loss: 0.715  loss_cls: 0.223  loss_box_reg: 0.346  loss_rpn_cls: 0.058  loss_rpn_loc: 0.040  time: 0.3262  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:46 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 1699  total_loss: 0.934  loss_cls: 0.279  loss_box_reg: 0.461  loss_rpn_cls: 0.075  loss_rpn_loc: 0.071  time: 0.3263  data_time: 0.0257  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:53 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 1719  total_loss: 0.924  loss_cls: 0.278  loss_box_reg: 0.440  loss_rpn_cls: 0.071  loss_rpn_loc: 0.051  time: 0.3263  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:57:59 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1739  total_loss: 0.664  loss_cls: 0.195  loss_box_reg: 0.311  loss_rpn_cls: 0.068  loss_rpn_loc: 0.035  time: 0.3263  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:06 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 1759  total_loss: 0.758  loss_cls: 0.259  loss_box_reg: 0.344  loss_rpn_cls: 0.074  loss_rpn_loc: 0.031  time: 0.3263  data_time: 0.0106  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:12 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 1779  total_loss: 0.755  loss_cls: 0.216  loss_box_reg: 0.352  loss_rpn_cls: 0.063  loss_rpn_loc: 0.032  time: 0.3262  data_time: 0.0091  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:19 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 1799  total_loss: 0.710  loss_cls: 0.231  loss_box_reg: 0.330  loss_rpn_cls: 0.053  loss_rpn_loc: 0.041  time: 0.3262  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:26 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 1819  total_loss: 0.779  loss_cls: 0.191  loss_box_reg: 0.339  loss_rpn_cls: 0.075  loss_rpn_loc: 0.050  time: 0.3264  data_time: 0.0287  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:32 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 1839  total_loss: 0.700  loss_cls: 0.168  loss_box_reg: 0.341  loss_rpn_cls: 0.059  loss_rpn_loc: 0.026  time: 0.3265  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:39 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 1859  total_loss: 0.654  loss_cls: 0.192  loss_box_reg: 0.329  loss_rpn_cls: 0.044  loss_rpn_loc: 0.025  time: 0.3264  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:45 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 1879  total_loss: 0.569  loss_cls: 0.189  loss_box_reg: 0.332  loss_rpn_cls: 0.046  loss_rpn_loc: 0.029  time: 0.3264  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:52 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1899  total_loss: 0.637  loss_cls: 0.179  loss_box_reg: 0.311  loss_rpn_cls: 0.050  loss_rpn_loc: 0.044  time: 0.3263  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:58:58 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 1919  total_loss: 0.634  loss_cls: 0.163  loss_box_reg: 0.337  loss_rpn_cls: 0.067  loss_rpn_loc: 0.044  time: 0.3263  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:04 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 1939  total_loss: 0.776  loss_cls: 0.212  loss_box_reg: 0.340  loss_rpn_cls: 0.092  loss_rpn_loc: 0.072  time: 0.3262  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:11 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1959  total_loss: 0.586  loss_cls: 0.181  loss_box_reg: 0.304  loss_rpn_cls: 0.056  loss_rpn_loc: 0.040  time: 0.3262  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:18 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 1979  total_loss: 0.676  loss_cls: 0.175  loss_box_reg: 0.307  loss_rpn_cls: 0.051  loss_rpn_loc: 0.054  time: 0.3262  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:24 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 1999  total_loss: 0.626  loss_cls: 0.123  loss_box_reg: 0.347  loss_rpn_cls: 0.051  loss_rpn_loc: 0.046  time: 0.3262  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:31 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 2019  total_loss: 0.698  loss_cls: 0.206  loss_box_reg: 0.310  loss_rpn_cls: 0.052  loss_rpn_loc: 0.054  time: 0.3262  data_time: 0.0097  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:37 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 2039  total_loss: 0.641  loss_cls: 0.148  loss_box_reg: 0.347  loss_rpn_cls: 0.050  loss_rpn_loc: 0.060  time: 0.3262  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:44 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 2059  total_loss: 0.621  loss_cls: 0.185  loss_box_reg: 0.317  loss_rpn_cls: 0.059  loss_rpn_loc: 0.030  time: 0.3262  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:50 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 2079  total_loss: 0.585  loss_cls: 0.229  loss_box_reg: 0.314  loss_rpn_cls: 0.049  loss_rpn_loc: 0.062  time: 0.3262  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 02:59:57 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 2099  total_loss: 0.664  loss_cls: 0.211  loss_box_reg: 0.316  loss_rpn_cls: 0.069  loss_rpn_loc: 0.057  time: 0.3262  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:03 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 2119  total_loss: 0.742  loss_cls: 0.245  loss_box_reg: 0.344  loss_rpn_cls: 0.047  loss_rpn_loc: 0.039  time: 0.3262  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:10 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 2139  total_loss: 0.657  loss_cls: 0.222  loss_box_reg: 0.367  loss_rpn_cls: 0.056  loss_rpn_loc: 0.034  time: 0.3263  data_time: 0.0272  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:16 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 2159  total_loss: 0.696  loss_cls: 0.220  loss_box_reg: 0.343  loss_rpn_cls: 0.069  loss_rpn_loc: 0.040  time: 0.3262  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:23 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 2179  total_loss: 0.647  loss_cls: 0.185  loss_box_reg: 0.325  loss_rpn_cls: 0.070  loss_rpn_loc: 0.039  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:29 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 2199  total_loss: 0.561  loss_cls: 0.169  loss_box_reg: 0.292  loss_rpn_cls: 0.059  loss_rpn_loc: 0.037  time: 0.3261  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:36 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 2219  total_loss: 0.690  loss_cls: 0.187  loss_box_reg: 0.323  loss_rpn_cls: 0.055  loss_rpn_loc: 0.053  time: 0.3262  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:42 d2.utils.events]: \u001b[0m eta: 0:09:32  iter: 2239  total_loss: 0.902  loss_cls: 0.323  loss_box_reg: 0.371  loss_rpn_cls: 0.070  loss_rpn_loc: 0.054  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:49 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 2259  total_loss: 0.808  loss_cls: 0.250  loss_box_reg: 0.388  loss_rpn_cls: 0.069  loss_rpn_loc: 0.030  time: 0.3262  data_time: 0.0225  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:00:56 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 2279  total_loss: 0.606  loss_cls: 0.173  loss_box_reg: 0.318  loss_rpn_cls: 0.065  loss_rpn_loc: 0.052  time: 0.3263  data_time: 0.0142  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:02 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 2299  total_loss: 0.720  loss_cls: 0.198  loss_box_reg: 0.360  loss_rpn_cls: 0.075  loss_rpn_loc: 0.066  time: 0.3263  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:09 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 2319  total_loss: 0.667  loss_cls: 0.195  loss_box_reg: 0.323  loss_rpn_cls: 0.044  loss_rpn_loc: 0.025  time: 0.3262  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:15 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 2339  total_loss: 0.681  loss_cls: 0.197  loss_box_reg: 0.346  loss_rpn_cls: 0.046  loss_rpn_loc: 0.050  time: 0.3262  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:22 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 2359  total_loss: 0.571  loss_cls: 0.148  loss_box_reg: 0.313  loss_rpn_cls: 0.049  loss_rpn_loc: 0.036  time: 0.3261  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:28 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 2379  total_loss: 0.712  loss_cls: 0.193  loss_box_reg: 0.327  loss_rpn_cls: 0.076  loss_rpn_loc: 0.058  time: 0.3261  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:34 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 2399  total_loss: 0.569  loss_cls: 0.169  loss_box_reg: 0.315  loss_rpn_cls: 0.050  loss_rpn_loc: 0.047  time: 0.3260  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:41 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 2419  total_loss: 0.572  loss_cls: 0.160  loss_box_reg: 0.296  loss_rpn_cls: 0.055  loss_rpn_loc: 0.046  time: 0.3260  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:48 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 2439  total_loss: 0.637  loss_cls: 0.221  loss_box_reg: 0.303  loss_rpn_cls: 0.063  loss_rpn_loc: 0.040  time: 0.3260  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:01:54 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 2459  total_loss: 0.602  loss_cls: 0.205  loss_box_reg: 0.321  loss_rpn_cls: 0.045  loss_rpn_loc: 0.029  time: 0.3260  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:00 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 2479  total_loss: 0.651  loss_cls: 0.195  loss_box_reg: 0.352  loss_rpn_cls: 0.051  loss_rpn_loc: 0.038  time: 0.3260  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:07 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 2499  total_loss: 0.588  loss_cls: 0.200  loss_box_reg: 0.293  loss_rpn_cls: 0.060  loss_rpn_loc: 0.051  time: 0.3260  data_time: 0.0244  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:14 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 2519  total_loss: 0.577  loss_cls: 0.201  loss_box_reg: 0.285  loss_rpn_cls: 0.044  loss_rpn_loc: 0.029  time: 0.3260  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:20 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 2539  total_loss: 0.632  loss_cls: 0.153  loss_box_reg: 0.331  loss_rpn_cls: 0.051  loss_rpn_loc: 0.039  time: 0.3261  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:27 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 2559  total_loss: 0.745  loss_cls: 0.221  loss_box_reg: 0.403  loss_rpn_cls: 0.071  loss_rpn_loc: 0.051  time: 0.3261  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:33 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 2579  total_loss: 0.628  loss_cls: 0.161  loss_box_reg: 0.317  loss_rpn_cls: 0.056  loss_rpn_loc: 0.034  time: 0.3261  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:40 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2599  total_loss: 0.494  loss_cls: 0.127  loss_box_reg: 0.263  loss_rpn_cls: 0.036  loss_rpn_loc: 0.036  time: 0.3261  data_time: 0.0072  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:46 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 2619  total_loss: 0.584  loss_cls: 0.169  loss_box_reg: 0.297  loss_rpn_cls: 0.051  loss_rpn_loc: 0.044  time: 0.3260  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:53 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 2639  total_loss: 0.633  loss_cls: 0.157  loss_box_reg: 0.291  loss_rpn_cls: 0.042  loss_rpn_loc: 0.031  time: 0.3260  data_time: 0.0105  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:02:59 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 2659  total_loss: 0.686  loss_cls: 0.231  loss_box_reg: 0.372  loss_rpn_cls: 0.039  loss_rpn_loc: 0.047  time: 0.3260  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:06 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 2679  total_loss: 0.752  loss_cls: 0.173  loss_box_reg: 0.344  loss_rpn_cls: 0.063  loss_rpn_loc: 0.052  time: 0.3260  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:12 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 2699  total_loss: 0.594  loss_cls: 0.163  loss_box_reg: 0.297  loss_rpn_cls: 0.054  loss_rpn_loc: 0.053  time: 0.3260  data_time: 0.0070  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:19 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 2719  total_loss: 0.628  loss_cls: 0.149  loss_box_reg: 0.255  loss_rpn_cls: 0.059  loss_rpn_loc: 0.030  time: 0.3260  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:25 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2739  total_loss: 0.627  loss_cls: 0.183  loss_box_reg: 0.352  loss_rpn_cls: 0.060  loss_rpn_loc: 0.044  time: 0.3260  data_time: 0.0095  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:32 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 2759  total_loss: 0.671  loss_cls: 0.205  loss_box_reg: 0.323  loss_rpn_cls: 0.060  loss_rpn_loc: 0.036  time: 0.3260  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:39 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2779  total_loss: 0.700  loss_cls: 0.194  loss_box_reg: 0.316  loss_rpn_cls: 0.047  loss_rpn_loc: 0.046  time: 0.3261  data_time: 0.0151  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:45 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 2799  total_loss: 0.626  loss_cls: 0.175  loss_box_reg: 0.279  loss_rpn_cls: 0.071  loss_rpn_loc: 0.038  time: 0.3261  data_time: 0.0057  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:52 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 2819  total_loss: 0.655  loss_cls: 0.176  loss_box_reg: 0.279  loss_rpn_cls: 0.050  loss_rpn_loc: 0.074  time: 0.3261  data_time: 0.0096  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:03:58 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 2839  total_loss: 0.694  loss_cls: 0.175  loss_box_reg: 0.332  loss_rpn_cls: 0.068  loss_rpn_loc: 0.048  time: 0.3261  data_time: 0.0083  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:05 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 2859  total_loss: 0.573  loss_cls: 0.167  loss_box_reg: 0.280  loss_rpn_cls: 0.033  loss_rpn_loc: 0.034  time: 0.3261  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:12 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2879  total_loss: 0.568  loss_cls: 0.144  loss_box_reg: 0.294  loss_rpn_cls: 0.047  loss_rpn_loc: 0.053  time: 0.3263  data_time: 0.0426  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:19 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 2899  total_loss: 0.531  loss_cls: 0.137  loss_box_reg: 0.288  loss_rpn_cls: 0.064  loss_rpn_loc: 0.031  time: 0.3263  data_time: 0.0096  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:25 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 2919  total_loss: 0.518  loss_cls: 0.128  loss_box_reg: 0.289  loss_rpn_cls: 0.035  loss_rpn_loc: 0.035  time: 0.3264  data_time: 0.0232  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:32 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 2939  total_loss: 0.527  loss_cls: 0.130  loss_box_reg: 0.306  loss_rpn_cls: 0.055  loss_rpn_loc: 0.038  time: 0.3264  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:39 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 2959  total_loss: 0.442  loss_cls: 0.089  loss_box_reg: 0.262  loss_rpn_cls: 0.032  loss_rpn_loc: 0.029  time: 0.3264  data_time: 0.0143  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:45 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 2979  total_loss: 0.602  loss_cls: 0.148  loss_box_reg: 0.312  loss_rpn_cls: 0.060  loss_rpn_loc: 0.037  time: 0.3263  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:51 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2999  total_loss: 0.413  loss_cls: 0.120  loss_box_reg: 0.228  loss_rpn_cls: 0.040  loss_rpn_loc: 0.042  time: 0.3263  data_time: 0.0102  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:04:58 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 3019  total_loss: 0.531  loss_cls: 0.140  loss_box_reg: 0.285  loss_rpn_cls: 0.036  loss_rpn_loc: 0.031  time: 0.3263  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:04 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 3039  total_loss: 0.669  loss_cls: 0.191  loss_box_reg: 0.326  loss_rpn_cls: 0.070  loss_rpn_loc: 0.064  time: 0.3263  data_time: 0.0085  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:11 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 3059  total_loss: 0.533  loss_cls: 0.141  loss_box_reg: 0.266  loss_rpn_cls: 0.035  loss_rpn_loc: 0.040  time: 0.3263  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:18 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 3079  total_loss: 0.627  loss_cls: 0.171  loss_box_reg: 0.327  loss_rpn_cls: 0.063  loss_rpn_loc: 0.048  time: 0.3263  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:24 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 3099  total_loss: 0.504  loss_cls: 0.133  loss_box_reg: 0.262  loss_rpn_cls: 0.068  loss_rpn_loc: 0.034  time: 0.3263  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:30 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 3119  total_loss: 0.597  loss_cls: 0.150  loss_box_reg: 0.317  loss_rpn_cls: 0.051  loss_rpn_loc: 0.067  time: 0.3262  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:37 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 3139  total_loss: 0.563  loss_cls: 0.156  loss_box_reg: 0.298  loss_rpn_cls: 0.052  loss_rpn_loc: 0.038  time: 0.3262  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:43 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 3159  total_loss: 0.549  loss_cls: 0.160  loss_box_reg: 0.306  loss_rpn_cls: 0.033  loss_rpn_loc: 0.032  time: 0.3262  data_time: 0.0074  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:50 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 3179  total_loss: 0.593  loss_cls: 0.149  loss_box_reg: 0.279  loss_rpn_cls: 0.041  loss_rpn_loc: 0.042  time: 0.3262  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:05:56 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 3199  total_loss: 0.748  loss_cls: 0.224  loss_box_reg: 0.324  loss_rpn_cls: 0.086  loss_rpn_loc: 0.036  time: 0.3262  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:03 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 3219  total_loss: 0.672  loss_cls: 0.176  loss_box_reg: 0.330  loss_rpn_cls: 0.039  loss_rpn_loc: 0.029  time: 0.3262  data_time: 0.0107  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:09 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 3239  total_loss: 0.541  loss_cls: 0.127  loss_box_reg: 0.293  loss_rpn_cls: 0.051  loss_rpn_loc: 0.038  time: 0.3261  data_time: 0.0056  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:16 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 3259  total_loss: 0.662  loss_cls: 0.171  loss_box_reg: 0.327  loss_rpn_cls: 0.052  loss_rpn_loc: 0.051  time: 0.3261  data_time: 0.0068  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:22 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 3279  total_loss: 0.577  loss_cls: 0.136  loss_box_reg: 0.310  loss_rpn_cls: 0.048  loss_rpn_loc: 0.034  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:29 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 3299  total_loss: 0.506  loss_cls: 0.127  loss_box_reg: 0.270  loss_rpn_cls: 0.040  loss_rpn_loc: 0.042  time: 0.3260  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:35 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 3319  total_loss: 0.635  loss_cls: 0.196  loss_box_reg: 0.328  loss_rpn_cls: 0.038  loss_rpn_loc: 0.031  time: 0.3261  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:42 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 3339  total_loss: 0.591  loss_cls: 0.182  loss_box_reg: 0.290  loss_rpn_cls: 0.040  loss_rpn_loc: 0.037  time: 0.3262  data_time: 0.0290  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:48 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 3359  total_loss: 0.463  loss_cls: 0.142  loss_box_reg: 0.260  loss_rpn_cls: 0.042  loss_rpn_loc: 0.021  time: 0.3261  data_time: 0.0074  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:06:55 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 3379  total_loss: 0.509  loss_cls: 0.126  loss_box_reg: 0.321  loss_rpn_cls: 0.028  loss_rpn_loc: 0.027  time: 0.3261  data_time: 0.0170  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:01 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 3399  total_loss: 0.549  loss_cls: 0.157  loss_box_reg: 0.297  loss_rpn_cls: 0.051  loss_rpn_loc: 0.032  time: 0.3261  data_time: 0.0108  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:08 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 3419  total_loss: 0.599  loss_cls: 0.183  loss_box_reg: 0.286  loss_rpn_cls: 0.050  loss_rpn_loc: 0.050  time: 0.3261  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:15 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 3439  total_loss: 0.641  loss_cls: 0.178  loss_box_reg: 0.335  loss_rpn_cls: 0.038  loss_rpn_loc: 0.041  time: 0.3261  data_time: 0.0209  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:21 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 3459  total_loss: 0.544  loss_cls: 0.126  loss_box_reg: 0.302  loss_rpn_cls: 0.051  loss_rpn_loc: 0.035  time: 0.3262  data_time: 0.0158  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:28 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 3479  total_loss: 0.593  loss_cls: 0.218  loss_box_reg: 0.306  loss_rpn_cls: 0.065  loss_rpn_loc: 0.055  time: 0.3261  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:34 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 3499  total_loss: 0.666  loss_cls: 0.176  loss_box_reg: 0.308  loss_rpn_cls: 0.056  loss_rpn_loc: 0.048  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:41 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 3519  total_loss: 0.582  loss_cls: 0.137  loss_box_reg: 0.295  loss_rpn_cls: 0.053  loss_rpn_loc: 0.041  time: 0.3261  data_time: 0.0089  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:47 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3539  total_loss: 0.453  loss_cls: 0.078  loss_box_reg: 0.284  loss_rpn_cls: 0.032  loss_rpn_loc: 0.030  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:07:54 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 3559  total_loss: 0.587  loss_cls: 0.147  loss_box_reg: 0.288  loss_rpn_cls: 0.046  loss_rpn_loc: 0.060  time: 0.3262  data_time: 0.0315  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:01 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3579  total_loss: 0.539  loss_cls: 0.143  loss_box_reg: 0.271  loss_rpn_cls: 0.050  loss_rpn_loc: 0.031  time: 0.3262  data_time: 0.0141  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:07 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 3599  total_loss: 0.603  loss_cls: 0.156  loss_box_reg: 0.282  loss_rpn_cls: 0.042  loss_rpn_loc: 0.037  time: 0.3262  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:14 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3619  total_loss: 0.591  loss_cls: 0.173  loss_box_reg: 0.287  loss_rpn_cls: 0.068  loss_rpn_loc: 0.027  time: 0.3262  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:20 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 3639  total_loss: 0.508  loss_cls: 0.119  loss_box_reg: 0.297  loss_rpn_cls: 0.039  loss_rpn_loc: 0.049  time: 0.3261  data_time: 0.0059  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:27 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3659  total_loss: 0.499  loss_cls: 0.105  loss_box_reg: 0.290  loss_rpn_cls: 0.027  loss_rpn_loc: 0.044  time: 0.3261  data_time: 0.0069  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:33 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 3679  total_loss: 0.528  loss_cls: 0.150  loss_box_reg: 0.286  loss_rpn_cls: 0.046  loss_rpn_loc: 0.051  time: 0.3261  data_time: 0.0062  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:40 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3699  total_loss: 0.517  loss_cls: 0.124  loss_box_reg: 0.276  loss_rpn_cls: 0.033  loss_rpn_loc: 0.053  time: 0.3261  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:46 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 3719  total_loss: 0.494  loss_cls: 0.128  loss_box_reg: 0.259  loss_rpn_cls: 0.035  loss_rpn_loc: 0.037  time: 0.3261  data_time: 0.0064  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:53 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3739  total_loss: 0.646  loss_cls: 0.144  loss_box_reg: 0.317  loss_rpn_cls: 0.040  loss_rpn_loc: 0.053  time: 0.3261  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:08:59 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 3759  total_loss: 0.576  loss_cls: 0.154  loss_box_reg: 0.328  loss_rpn_cls: 0.037  loss_rpn_loc: 0.036  time: 0.3260  data_time: 0.0063  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:06 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 3779  total_loss: 0.570  loss_cls: 0.150  loss_box_reg: 0.299  loss_rpn_cls: 0.069  loss_rpn_loc: 0.067  time: 0.3261  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:12 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 3799  total_loss: 0.575  loss_cls: 0.186  loss_box_reg: 0.310  loss_rpn_cls: 0.054  loss_rpn_loc: 0.065  time: 0.3261  data_time: 0.0060  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:19 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 3819  total_loss: 0.550  loss_cls: 0.143  loss_box_reg: 0.309  loss_rpn_cls: 0.056  loss_rpn_loc: 0.035  time: 0.3262  data_time: 0.0274  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:26 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 3839  total_loss: 0.468  loss_cls: 0.118  loss_box_reg: 0.261  loss_rpn_cls: 0.033  loss_rpn_loc: 0.034  time: 0.3262  data_time: 0.0058  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:32 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 3859  total_loss: 0.544  loss_cls: 0.106  loss_box_reg: 0.243  loss_rpn_cls: 0.040  loss_rpn_loc: 0.027  time: 0.3261  data_time: 0.0067  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:39 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 3879  total_loss: 0.561  loss_cls: 0.135  loss_box_reg: 0.283  loss_rpn_cls: 0.068  loss_rpn_loc: 0.039  time: 0.3261  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:45 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 3899  total_loss: 0.516  loss_cls: 0.131  loss_box_reg: 0.242  loss_rpn_cls: 0.053  loss_rpn_loc: 0.033  time: 0.3261  data_time: 0.0065  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:52 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 3919  total_loss: 0.522  loss_cls: 0.161  loss_box_reg: 0.261  loss_rpn_cls: 0.040  loss_rpn_loc: 0.037  time: 0.3261  data_time: 0.0066  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:09:58 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 3939  total_loss: 0.609  loss_cls: 0.159  loss_box_reg: 0.326  loss_rpn_cls: 0.055  loss_rpn_loc: 0.041  time: 0.3262  data_time: 0.0120  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:10:05 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 3959  total_loss: 0.524  loss_cls: 0.162  loss_box_reg: 0.332  loss_rpn_cls: 0.051  loss_rpn_loc: 0.037  time: 0.3262  data_time: 0.0061  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:10:11 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 3979  total_loss: 0.576  loss_cls: 0.166  loss_box_reg: 0.303  loss_rpn_cls: 0.046  loss_rpn_loc: 0.046  time: 0.3261  data_time: 0.0129  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:10:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3999  total_loss: 0.490  loss_cls: 0.160  loss_box_reg: 0.252  loss_rpn_cls: 0.054  loss_rpn_loc: 0.047  time: 0.3261  data_time: 0.0129  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:10:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4000  total_loss: 0.487  loss_cls: 0.151  loss_box_reg: 0.252  loss_rpn_cls: 0.046  loss_rpn_loc: 0.047  time: 0.3261  data_time: 0.0133  lr: 0.000500  max_mem: 2688M\n",
            "\u001b[32m[05/04 03:10:19 d2.engine.hooks]: \u001b[0mOverall training speed: 3998 iterations in 0:21:44 (0.3262 s / it)\n",
            "\u001b[32m[05/04 03:10:19 d2.engine.hooks]: \u001b[0mTotal training time: 0:21:48 (0:00:04 on hooks)\n",
            "**********************************************\n",
            "\t\t Test v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128\n",
            "**********************************************\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/04 03:10:20 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[05/04 03:10:20 d2.data.datasets.coco]: \u001b[0mLoaded 206 images in COCO format from greenthumbs/data/v01/test_85%_coco.json\n",
            "\u001b[32m[05/04 03:10:20 d2.data.common]: \u001b[0mSerializing 206 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/04 03:10:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
            "\u001b[32m[05/04 03:10:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 206 images\n",
            "\u001b[32m[05/04 03:10:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/206. 0.1309 s / img. ETA=0:00:25\n",
            "\u001b[32m[05/04 03:10:27 d2.evaluation.evaluator]: \u001b[0mInference done 43/206. 0.1509 s / img. ETA=0:00:24\n",
            "\u001b[32m[05/04 03:10:32 d2.evaluation.evaluator]: \u001b[0mInference done 69/206. 0.1691 s / img. ETA=0:00:23\n",
            "\u001b[32m[05/04 03:10:37 d2.evaluation.evaluator]: \u001b[0mInference done 100/206. 0.1673 s / img. ETA=0:00:17\n",
            "\u001b[32m[05/04 03:10:42 d2.evaluation.evaluator]: \u001b[0mInference done 132/206. 0.1641 s / img. ETA=0:00:12\n",
            "\u001b[32m[05/04 03:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 163/206. 0.1639 s / img. ETA=0:00:07\n",
            "\u001b[32m[05/04 03:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 198/206. 0.1595 s / img. ETA=0:00:01\n",
            "\u001b[32m[05/04 03:10:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.456147 (0.161473 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 03:10:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.158837 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/04 03:10:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/04 03:10:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./outputs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128/coco_instances_results.json\n",
            "\u001b[32m[05/04 03:10:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.63s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.600\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.430\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.348\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.504\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
            "\u001b[32m[05/04 03:10:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.419 | 60.000 | 43.012 | 19.713 | 35.456 | 46.819 |\n",
            "\u001b[32m[05/04 03:10:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category                | AP     | category           | AP     | category                 | AP     |\n",
            "|:------------------------|:-------|:-------------------|:-------|:-------------------------|:-------|\n",
            "| tomato_fruit_unripe     | 42.072 | tomato_fruit       | 17.666 | tomato_seedling          | 34.950 |\n",
            "| tomato_young_plant      | 50.220 | tomato_flower      | 41.046 | bell_pepper_fruit        | 59.533 |\n",
            "| bell_pepper_young_plant | 32.806 | bell_pepper_flower | 39.218 | bell_pepper_fruit_unripe | 30.845 |\n",
            "| bell_pepper_seedling    | 19.199 | cucumber_flower    | 61.035 | cucumber_plant           | 6.794  |\n",
            "| cucumber_seedling       | 34.378 | cucumber_fruit     | 63.227 | cucumber_fruit_unripe    | 43.301 |\n",
            "Saving images...\n",
            "Saved 1 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128___1.png\n",
            "Saved 2 image /content/drive/My Drive/Green Thumbs/out_imgs/v01/v01_85%_faster_rcnn_R_50_C4_3x.yaml_4001_0.0005_128___2.png\n",
            "Saving results...\n",
            "Saved /content/drive/My Drive/Green Thumbs/v01_85%_faster_rcnn_R_50_C4_3x.yaml_05-03-2020_21:04.json\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}